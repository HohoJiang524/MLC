{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from pomegranate import BayesianNetwork\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob)\n",
    "\n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i, :], y_pred.iloc[i, :])  # jaccard_similarity_score\n",
    "    acc = acc / y_true.shape[0]\n",
    "\n",
    "    zero_one = zero_one_loss(y_true, y_pred)  # 0-1 error\n",
    "\n",
    "    performance = {\"coverage_error\": coverage,\n",
    "                   \"ranking_loss\": ranking_loss,\n",
    "                   \"hamming_loss\": hamming,\n",
    "                   \"f1_macro\": f1_macro,\n",
    "                   \"f1_micro\": f1_micro,\n",
    "                   \"Jaccard_Index\": acc,\n",
    "                   \"zero_one_error\": zero_one}\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to represent a graph\n",
    "class Graph:\n",
    "    def __init__(self, vertices):\n",
    "        self.graph = defaultdict(list)  # dictionary containing adjacency List\n",
    "        self.V = vertices  # No. of vertices\n",
    "\n",
    "    # function to add an edge to graph\n",
    "    def addEdge(self, u, v):\n",
    "        self.graph[u].extend(v)\n",
    "\n",
    "        # A recursive function used by topologicalSort\n",
    "\n",
    "    def topologicalSortUtil(self, v, visited, stack):\n",
    "\n",
    "        # Mark the current node as visited.\n",
    "        visited[v] = True\n",
    "\n",
    "        # Recur for all the vertices adjacent to this vertex\n",
    "        for i in self.graph[v]:\n",
    "            if visited[i] == False:\n",
    "                self.topologicalSortUtil(i, visited, stack)\n",
    "\n",
    "                # Push current vertex to stack which stores result\n",
    "        stack.insert(0, v)\n",
    "\n",
    "        # The function to do Topological Sort. It uses recursive\n",
    "\n",
    "    # topologicalSortUtil()\n",
    "    def topologicalSort(self):\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * self.V\n",
    "        stack = []\n",
    "\n",
    "        # Call the recursive helper function to store Topological\n",
    "        # Sort starting from all vertices one by one\n",
    "        for i in range(self.V):\n",
    "            if visited[i] == False:\n",
    "                self.topologicalSortUtil(i, visited, stack)\n",
    "\n",
    "                # Print contents of the stack\n",
    "        return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BR for getting error matrix\n",
    "def naiveBayes_multi_label_training_BR(X_train, y_train):\n",
    "    start = time.time()\n",
    "\n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train, y_train.iloc[:, i])\n",
    "\n",
    "    end = time.time()\n",
    "    training_time = end - start\n",
    "\n",
    "    return classifier_list, training_time\n",
    "\n",
    "\n",
    "def naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)], axis=1)\n",
    "\n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:, 1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)], axis=1)\n",
    "\n",
    "    end = time.time()\n",
    "    testing_time = end - start\n",
    "\n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    # split training and test data set\n",
    "    X_train, y_train, X_test, y_test = iterative_train_test_split(np.matrix(data), np.matrix(label), test_size=0.5)\n",
    "\n",
    "    X_train = pd.DataFrame(X_train, columns=data.columns)\n",
    "    X_test = pd.DataFrame(X_test, columns=data.columns)\n",
    "\n",
    "    y_train = pd.DataFrame(y_train, columns=label.columns)\n",
    "    y_test = pd.DataFrame(y_test, columns=label.columns)\n",
    "\n",
    "\n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training_BR(X_train, y_train)\n",
    "\n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list)\n",
    "\n",
    "    y_predict.columns = label.columns\n",
    "    return y_predict, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "def csv_to_arff(X, label_i, savePath, isTrain=True):\n",
    "    # get attributes\n",
    "    attributes=[(X.columns[i],u\"REAL\") for i in range(len(X.columns))]\n",
    "    attributes.append(('label_'+label_i.name,['0', '1']))\n",
    "\n",
    "    data=[]\n",
    "    i = 0\n",
    "    while i < len(label_i):\n",
    "        attr_data = [j for j in list(X.iloc[i,:])]\n",
    "        label_data = [str(label_i[i])]\n",
    "        row_data = attr_data+label_data\n",
    "        data.append(row_data) \n",
    "        i+=1\n",
    "    # set obj\n",
    "    obj = {\n",
    "       'description': u'',\n",
    "       'relation': 'relation',\n",
    "       'attributes': attributes,\n",
    "       'data': data,\n",
    "    }\n",
    "    arff_data = arff.dumps(obj)\n",
    "    if isTrain:\n",
    "        #w_file = open(savePath+label_i.name+\"_train.arff\", \"w\")\n",
    "        w_file = open(savePath+\"train.arff\", \"w\")\n",
    "        w_file.write(arff_data)\n",
    "        w_file.close()\n",
    "    elif not isTrain:\n",
    "        w_file = open(savePath+\"test.arff\", \"w\")\n",
    "        w_file.write(arff_data)\n",
    "        w_file.close()\n",
    "    else:\n",
    "        raise(ValueError,\"what type of dataset?\")\n",
    "\n",
    "def run_eskdb(train, test, resultFile):\n",
    "    command = \"\"\"cd ../../programme/ESKDB-on-numerical-data/\n",
    "    java -classpath ./bin/:./lib/weka.jar:./lib/commons-math3-3.6.1.jar:./lib/MLTools.jar MemorySolvedESKDBR.IndependentTest -t %s -T %s -K -S SKDB_R -I 1000 -L 2 -E 10 > %s\n",
    "    \"\"\" % (train, test, resultFile)\n",
    "    return subprocess.call(command, shell=True)\n",
    "\n",
    "def get_result(resultFile):\n",
    "    # get result \n",
    "    pred = []\n",
    "    prob = []\n",
    "    with open(savePath+\"result_temp.txt\", 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if line.startswith(\"test example\"):\n",
    "                r = re.findall('\\t\\s?([0-9.]*)', line)\n",
    "                prob.append(float(r[1]))\n",
    "                pred.append(int(r[2]))\n",
    "    return pred, prob\n",
    "\n",
    "def predict_ESKDB(X_train, X_test, y_train_i, y_test_i, savePath):\n",
    "    \n",
    "    # make a temp directory for temperate results.\n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "        \n",
    "    # get arff file\n",
    "    csv_to_arff(X_train, y_train_i, savePath, isTrain=True) # train\n",
    "    csv_to_arff(X_test, y_test_i, savePath, isTrain=False) # test\n",
    "    \n",
    "    # run eskdb\n",
    "    run_eskdb(savePath+\"train.arff\", savePath+\"test.arff\", savePath+\"result_temp.txt\")\n",
    "    \n",
    "    # get prediction and probability of being positive.\n",
    "    pred, prob = get_result(savePath+\"result_temp.txt\")\n",
    "    \n",
    "    return pred, prob\n",
    "\n",
    "def build_bayes_net(trainLabelFile, labelName, savePath):\n",
    "    cmd = \"\"\"cd ../../programme/Chordalysis/ \n",
    "    java -Xmx1g -classpath bin:lib/core/commons-math3-3.2.jar:lib/core/jayes.jar:lib/core/jgrapht-jdk1.6.jar:lib/extra/jgraphx.jar:lib/loader/weka.jar demo.Run %s 0.05 %s false\n",
    "    \"\"\" % (trainLabelFile,savePath+\"bayes_net.png\")\n",
    "\n",
    "    p = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE)\n",
    "    out,err = p.communicate()\n",
    "    for line in out.splitlines():\n",
    "        if line.decode(\"utf-8\").startswith('['):\n",
    "            graph_set = [i for i in map(lambda x: x.split(','), line.decode(\"utf-8\").replace(' ',',').strip('[[\\,]]').split(',]['))]\n",
    "\n",
    "    dic = {}\n",
    "    for l in labelName:\n",
    "        s = set()\n",
    "        for i in map(lambda x: set(x) if l in x else None, graph_set):\n",
    "            if i != None:\n",
    "                s.update(i)\n",
    "        s.remove(l)\n",
    "        dic[l] = s\n",
    "\n",
    "    return dic\n",
    "\n",
    "## function for tree structure\n",
    "def get_structure(model, labels):\n",
    "    dic = {}\n",
    "    for item, attr in zip(model.structure, labels):\n",
    "        if item == ():\n",
    "            dic[attr] = {}\n",
    "        else:\n",
    "            dic[attr] = set(labels[list(item)])\n",
    "    return dic\n",
    "\n",
    "\n",
    "def get_order(model, labels):\n",
    "    g = Graph(len(labels))\n",
    "    for item, i in zip(model.structure, range(len(labels))):\n",
    "        if item == ():\n",
    "            pass\n",
    "        else:\n",
    "            g.addEdge(i, list(item))\n",
    "\n",
    "    # get order\n",
    "    a = g.topologicalSort()\n",
    "    a.reverse()\n",
    "\n",
    "    return labels[a]\n",
    "\n",
    "def get_order_bayesnet(bayes_net, root):\n",
    "    for key,value in bayes_net.items():\n",
    "        if value == {}:\n",
    "            visited.append(key)\n",
    "            \n",
    "    visited = []\n",
    "    open_l = [root]\n",
    "    while open_l != []:\n",
    "        root = open_l.pop(0)\n",
    "        if root not in visited:\n",
    "            visited.append(root)\n",
    "            open_l.extend(list(bayes_net[root]))\n",
    "            \n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierChain_ESKDB(data_train, data_test, label_train, label_test, savePath, ensemble=1):\n",
    "    n_label = label_train.shape[1]\n",
    "    # for storing ensemble results\n",
    "    pred_ensemble = pd.DataFrame(np.zeros(label_test.shape), columns=label_test.columns)\n",
    "    prob_ensemble = pd.DataFrame(np.zeros(label_test.shape), columns=label_test.columns)\n",
    "    \n",
    "    # for loop for ensembling.\n",
    "    for i in range(ensemble):\n",
    "        X_train, X_test, y_train, y_test = data_train, data_test, label_train, label_test\n",
    "        \n",
    "        # create a random order.\n",
    "        order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "        for index in order:\n",
    "            label = y_train.columns[index] # the label to be fitted.\n",
    "            y_train_i = y_train.loc[:,label]\n",
    "            y_test_i = y_test.loc[:,label]\n",
    "            \n",
    "            pred, prob = predict_ESKDB(X_train, X_test, y_train_i, y_test_i, savePath)\n",
    "            pred = pd.Series(pred, name=y_train_i.name)\n",
    "            prob = pd.Series(prob, name=y_train_i.name)\n",
    "            pred_ensemble.loc[:,label] += pred\n",
    "            prob_ensemble.loc[:,label] += prob\n",
    "            \n",
    "            # add the prediction to the attribute matrix.\n",
    "            X_train = pd.concat([X_train, y_train_i], axis=1)\n",
    "            X_test = pd.concat([X_test, pred], axis=1)\n",
    "    \n",
    "    pred_ensemble = (((pred_ensemble / ensemble) >= 0.5) * 1).astype('int')\n",
    "    prob_ensemble = prob_ensemble / ensemble\n",
    "    pred_ensemble = pred_ensemble.fillna(0)\n",
    "    prob_ensemble = prob_ensemble.fillna(0)\n",
    "    \n",
    "    return pred_ensemble, prob_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BayesianClassifierChain_ESKDB(data_train, data_test, label_train, label_test, savePath, \n",
    "                                  ensemble=1, ordering=\"random\", structure=\"bayes_net\", lead=False):\n",
    "    n_label = label_train.shape[1]\n",
    "    # for storing ensemble results\n",
    "    pred_ensemble = pd.DataFrame(np.zeros(label_test.shape), columns=label_test.columns)\n",
    "    prob_ensemble = pd.DataFrame(np.zeros(label_test.shape), columns=label_test.columns)\n",
    "    \n",
    "    if ensemble==1:\n",
    "        # bayes_net structure\n",
    "        if structure==\"bayes_net\":\n",
    "            if lead:\n",
    "                y_predict, y_true = BR_test(data_train, label_train, dataPath, 123456)\n",
    "                error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_true), columns=label_test.columns)\n",
    "                error_matrix.to_csv(savePath+\"y_train.csv\", index=False) # for learning bayes_net structure\n",
    "                \n",
    "            else:\n",
    "                label_train.to_csv(savePath+\"y_train.csv\", index=False) # for learning bayes_net structure\n",
    "                \n",
    "            bayes_net = build_bayes_net(savePath+\"y_train.csv\", label_train.columns, savePath)\n",
    "\n",
    "            # ordering \n",
    "            if ordering==\"best_prediction\":\n",
    "                y_pred, y_test = BR_test(data, label, dataPath, random.seed())\n",
    "                acc = (y_pred.values == y_test.values).mean(axis=0)\n",
    "                order = list(label.columns[np.argsort(-acc)])\n",
    "\n",
    "            elif ordering==\"most_edges\":\n",
    "                a = [(x, len(y)) for x, y in bayes_net.items()]\n",
    "                a_sort = sorted(a, key=lambda x: x[1], reverse=True)\n",
    "                root = [x[0] for x in a_sort]\n",
    "                order = get_order_bayesnet(bayes_net, root)\n",
    "\n",
    "            elif ordering==\"random\":\n",
    "                root = label_train.columns[random.randint(0, len(label_train.columns)-1)]\n",
    "                order = get_order_bayesnet(bayes_net, root)\n",
    "            \n",
    "            else:\n",
    "                raise(ValueError,\"ordering should be one of {random, best_prediction, most_edges}\")\n",
    "              \n",
    "        # tree structure\n",
    "        elif structure==\"tree\":\n",
    "            if ordering==\"random\":\n",
    "                root = random.randint(0, len(label_train.columns)-1)\n",
    "                model = BayesianNetwork.from_samples(label_train, algorithm='chow-liu', root=root)\n",
    "                bayes_net = get_structure(model, label_train.columns)\n",
    "                order = get_order(model, label_train.columns)\n",
    "            else:\n",
    "                raise ValueError(\"in tree structure, only random ordering is applied.\")\n",
    "                                                     \n",
    "        else:\n",
    "            raise ValueError(\"structure should be one of {bayes_net, tree}\")\n",
    "            \n",
    "        # BayesianClassifierChain without ensemble.\n",
    "        X_train, X_test, y_train, y_test = data_train, data_test, label_train, label_test\n",
    "        learned_label = []\n",
    "        for label in order:\n",
    "            \n",
    "            par = [x for x in bayes_net[label] if x in learned_label]\n",
    "            \n",
    "            X_tr = pd.concat([X_train, y_train.loc[:,par]], axis=1)\n",
    "            X_te = pd.concat([X_test, pred_ensemble.loc[:,par]], axis=1)\n",
    "            \n",
    "            y_train_i = y_train.loc[:,label]\n",
    "            y_test_i = y_test.loc[:,label]\n",
    "            \n",
    "            pred, prob = predict_ESKDB(X_tr, X_te, y_train_i, y_test_i, savePath)\n",
    "            \n",
    "            pred = pd.Series(pred, name=y_train_i.name)\n",
    "            prob = pd.Series(prob, name=y_train_i.name)\n",
    "            pred_ensemble.loc[:,label] += pred\n",
    "            prob_ensemble.loc[:,label] += prob\n",
    "            \n",
    "            learned_label.append(label)\n",
    "    \n",
    "        pred_ensemble = pred_ensemble.fillna(0)\n",
    "        prob_ensemble = prob_ensemble.fillna(0)\n",
    "\n",
    "        return pred_ensemble, prob_ensemble\n",
    "    \n",
    "    else:\n",
    "        # for loop for ensembling.\n",
    "        for i in range(ensemble):\n",
    "                # get bayesian network structure with Chordalysis.\n",
    "            if structure==\"bayes_net\":\n",
    "                if lead:\n",
    "                    y_predict, y_true = BR_test(data_train, label_train, dataPath, 123456)\n",
    "                    error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_true), columns=label_test.columns)\n",
    "                    error_matrix.to_csv(savePath+\"y_train.csv\", index=False) # for learning bayes_net structure\n",
    "                else:\n",
    "                    label_train.to_csv(savePath+\"y_train.csv\", index=False) # for learning bayes_net structure\n",
    "                bayes_net = build_bayes_net(savePath+\"y_train.csv\", label_train.columns, savePath)\n",
    "                \n",
    "                if ordering==\"random\":\n",
    "                    root = label_train.columns[random.randint(0, len(label_train.columns)-1)]\n",
    "                    order = get_order_bayesnet(bayes_net, root)\n",
    "                else:\n",
    "                    raise ValueError(\"random!\")\n",
    "\n",
    "            elif structure==\"tree\":\n",
    "                if ordering==\"random\":\n",
    "                    root = random.randint(0, len(label_train.columns)-1)\n",
    "                    model = BayesianNetwork.from_samples(label_train, algorithm='chow-liu', root=root)\n",
    "                    bayes_net = get_structure(model, label_train.columns)\n",
    "                    order = get_order(model, label_train.columns)\n",
    "                else:\n",
    "                    raise ValueError(\"in tree structure, only random ordering is applied.\")\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"structure should be one of {bayes_net, tree}\")\n",
    "\n",
    "            # BayesianClassifierChain with ensemble.\n",
    "            X_train, X_test, y_train, y_test = data_train, data_test, label_train, label_test\n",
    "            learned_label = []\n",
    "            for label in order:\n",
    "\n",
    "                par = [x for x in bayes_net[label] if x in learned_label]\n",
    "\n",
    "                X_tr = pd.concat([X_train, y_train.loc[:,par]], axis=1)\n",
    "                X_te = pd.concat([X_test, pred_ensemble.loc[:,par]], axis=1)\n",
    "\n",
    "                y_train_i = y_train.loc[:,label]\n",
    "                y_test_i = y_test.loc[:,label]\n",
    "\n",
    "                pred, prob = predict_ESKDB(X_tr, X_te, y_train_i, y_test_i, savePath)\n",
    "\n",
    "                pred = pd.Series(pred, name=y_train_i.name)\n",
    "                prob = pd.Series(prob, name=y_train_i.name)\n",
    "                pred_ensemble.loc[:,label] += pred\n",
    "                prob_ensemble.loc[:,label] += prob\n",
    "\n",
    "                learned_label.append(label)\n",
    "\n",
    "\n",
    "        pred_ensemble = (((pred_ensemble / ensemble) >= 0.5) * 1).astype('int')\n",
    "        prob_ensemble = prob_ensemble / ensemble\n",
    "        pred_ensemble = pred_ensemble.fillna(0)\n",
    "        prob_ensemble = prob_ensemble.fillna(0)\n",
    "        return pred_ensemble, prob_ensemble\n",
    "\n",
    "def two_fold(methods, data, label, dataset, ensemble=1, ordering=\"random\", structure=\"bayes_net\", lead=False):\n",
    "    # setup\n",
    "    savePath = \"../../code/temp/\"\n",
    "    print(\"running\",methods.__name__)\n",
    "    print(\"setting:\",ensemble, ordering, structure, lead)\n",
    "    performance_df_all = pd.DataFrame()\n",
    "    for j in range(1):\n",
    "        print(\"time:\",j)\n",
    "        X_train, y_train, X_test, y_test = iterative_train_test_split(np.matrix(data), np.matrix(label), test_size=0.5)\n",
    "        X_train = pd.DataFrame(X_train, columns=data.columns)\n",
    "        X_test = pd.DataFrame(X_test, columns=data.columns)\n",
    "        y_train = pd.DataFrame(y_train, columns=label.columns)\n",
    "        y_test = pd.DataFrame(y_test, columns=label.columns)\n",
    "    \n",
    "        for i in range(2):\n",
    "            X_test, X_train = X_train, X_test\n",
    "            y_test, y_train = y_train, y_test\n",
    "\n",
    "            # test\n",
    "            if methods.__name__ == \"BayesianClassifierChain_ESKDB\":\n",
    "                print(j*i+i)\n",
    "                pred_ensemble, prob_ensemble = BayesianClassifierChain_ESKDB(X_train, X_test, y_train, y_test, \n",
    "                                                                             savePath, ensemble=ensemble, \n",
    "                                                                             ordering=ordering, structure=structure,\n",
    "                                                                             lead=lead)\n",
    "            elif methods.__name__ == \"ClassifierChain_ESKDB\":\n",
    "                pred_ensemble, prob_ensemble = ClassifierChain_ESKDB(X_train, X_test, y_train, y_test, \n",
    "                                                                     savePath, ensemble=ensemble)\n",
    "\n",
    "            else:\n",
    "                raise BaseException(\"no such a function\")\n",
    "\n",
    "            performance = evaluation(pred_ensemble, prob_ensemble, y_test)\n",
    "            performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "            print(performance_df)\n",
    "            performance_df_all = pd.concat([performance_df_all, performance_df],axis=1)\n",
    "            print(performance_df_all)\n",
    "    performance_df_all.columns = list(range(2))\n",
    "    \n",
    "    return performance_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"emotions\"\n",
    "\n",
    "# setup\n",
    "savePath = \"/Users/jiangjunhao/Desktop/\"\n",
    "dataPath = os.path.abspath(\"../../data/\" + dataset + \"/\")\n",
    "X_file = \"X_scale.csv\"\n",
    "y_file = \"y.csv\"\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(os.path.join(dataPath, X_file))\n",
    "label = pd.read_csv(os.path.join(dataPath, y_file))\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(np.matrix(data), np.matrix(label), test_size=0.5)\n",
    "X_train = pd.DataFrame(X_train, columns=data.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=data.columns)\n",
    "y_train = pd.DataFrame(y_train, columns=label.columns)\n",
    "y_test = pd.DataFrame(y_test, columns=label.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running BayesianClassifierChain_ESKDB\n",
      "setting: 1 random bayes_net False\n",
      "time: 0\n",
      "                       0\n",
      "coverage_error  6.000000\n",
      "ranking_loss    1.000000\n",
      "hamming_loss    0.384615\n",
      "f1_macro        0.262983\n",
      "f1_micro        0.264392\n",
      "Jaccard_Index   0.615385\n",
      "zero_one_error  1.000000\n",
      "                       0\n",
      "coverage_error  6.000000\n",
      "ranking_loss    1.000000\n",
      "hamming_loss    0.391156\n",
      "f1_macro        0.261767\n",
      "f1_micro        0.264392\n",
      "Jaccard_Index   0.608844\n",
      "zero_one_error  1.000000\n",
      "                       0\n",
      "coverage_error  6.000000\n",
      "ranking_loss    1.000000\n",
      "hamming_loss    0.391156\n",
      "f1_macro        0.261767\n",
      "f1_micro        0.264392\n",
      "Jaccard_Index   0.608844\n",
      "zero_one_error  1.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-7863feface28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperformance_df_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bayes_net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-71d9c3a30422>\u001b[0m in \u001b[0;36mtwo_fold\u001b[0;34m(methods, data, label, dataset, ensemble, ordering, structure, lead)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"BayesianClassifierChain_ESKDB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 pred_ensemble, prob_ensemble = BayesianClassifierChain_ESKDB(X_train, X_test, y_train, y_test, savePath, \n\u001b[0;32m--> 168\u001b[0;31m                                                                   ensemble=ensemble, ordering='random', structure='bayes_net', lead=True)\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ClassifierChain_ESKDB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 pred_ensemble, prob_ensemble = ClassifierChain_ESKDB(X_train, X_test, y_train, y_test, \n",
      "\u001b[0;32m<ipython-input-82-71d9c3a30422>\u001b[0m in \u001b[0;36mBayesianClassifierChain_ESKDB\u001b[0;34m(data_train, data_test, label_train, label_test, savePath, ensemble, ordering, structure, lead)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mlabel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavePath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"y_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for learning bayes_net structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mbayes_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavePath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"y_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# ordering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-aa537972879c>\u001b[0m in \u001b[0;36mbuild_bayes_net\u001b[0;34m(trainLabelFile, labelName, savePath)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "performance_df_all = two_fold(methods, data, label, dataset, ensemble=1, ordering=\"random\", structure=\"bayes_net\", lead=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running BayesianClassifierChain_ESKDB\n",
      "setting: 1 random bayes_net False\n",
      "time: 0\n"
     ]
    }
   ],
   "source": [
    "def two_fold(methods, data, label, dataset, datatype, ensemble=1, ordering=\"random\", structure=\"bayes_net\", lead=False):\n",
    "    \n",
    "    print(\"running\",methods.__name__)\n",
    "    print(\"setting:\",ensemble, ordering, structure, lead)\n",
    "    performance_df_all = pd.DataFrame()\n",
    "    for j in range(1):\n",
    "        print(\"time:\",j)\n",
    "        X_train, y_train, X_test, y_test = iterative_train_test_split(np.matrix(data), np.matrix(label), test_size=0.5)\n",
    "        X_train = pd.DataFrame(X_train, columns=data.columns)\n",
    "        X_test = pd.DataFrame(X_test, columns=data.columns)\n",
    "        y_train = pd.DataFrame(y_train, columns=label.columns)\n",
    "        y_test = pd.DataFrame(y_test, columns=label.columns)\n",
    "\n",
    "        for i in range(2):\n",
    "            X_test, X_train = X_train, X_test\n",
    "            y_test, y_train = y_train, y_test\n",
    "\n",
    "            # test\n",
    "            if methods.__name__ == \"BayesianClassifierChain_ESKDB\":\n",
    "                pred_ensemble, prob_ensemble = BayesianClassifierChain_ESKDB(X_train, X_test, y_train, y_test, savePath,\n",
    "                                                                  ensemble=ensemble, ordering=ordering, structure=structure, lead=lead)\n",
    "            elif methods.__name__ == \"ClassifierChain_ESKDB\":\n",
    "                pred_ensemble, prob_ensemble = ClassifierChain_ESKDB(X_train, X_test, y_train, y_test,\n",
    "                                                                     ensemble=ensemble, ordering=ordering, structure=structure, lead=lead)\n",
    "\n",
    "            else:\n",
    "                raise BaseException(\"no such a function\")\n",
    "\n",
    "            performance = evaluation(pred_ensemble, prob_ensemble, y_test)\n",
    "            performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "            print(performance_df)\n",
    "            performance_df_all = pd.concat([performance_df_all, performance_df],axis=1)\n",
    "            print(performance_df_all)\n",
    "    performance_df_all.columns = list(range(2))\n",
    "    \n",
    "    return performance_df_all\n",
    "\n",
    "savePath = \"../../code/temp/\"\n",
    "methods = BayesianClassifierChain_ESKDB\n",
    "ensemble=1\n",
    "ordering='random'\n",
    "structure='bayes_net'\n",
    "lead=False\n",
    "\n",
    "two_fold(methods, data, label, dataset, datatype, ensemble, ordering, structure, lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"medical\"\n",
    "\n",
    "# setup\n",
    "savePath = \"/Users/jiangjunhao/Desktop/\"\n",
    "dataPath = os.path.abspath(\"../../data/\" + dataset + \"/\")\n",
    "X_file = \"X_scale.csv\"\n",
    "y_file = \"y.csv\"\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(os.path.join(dataPath, X_file))\n",
    "label = pd.read_csv(os.path.join(dataPath, y_file))\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(np.matrix(data), np.matrix(label), test_size=0.5)\n",
    "X_train = pd.DataFrame(X_train, columns=data.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=data.columns)\n",
    "y_train = pd.DataFrame(y_train, columns=label.columns)\n",
    "y_test = pd.DataFrame(y_test, columns=label.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "two_fold() takes from 4 to 8 positional arguments but 9 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f6e9ef711889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nominal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtwo_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: two_fold() takes from 4 to 8 positional arguments but 9 were given"
     ]
    }
   ],
   "source": [
    "savePath = \"../../code/temp/\"\n",
    "methods = BayesianClassifierChain_ESKDB\n",
    "ensemble=1\n",
    "ordering='random'\n",
    "structure='bayes_net'\n",
    "lead=False\n",
    "datatype = \"nominal\"\n",
    "\n",
    "two_fold(methods, data, label, dataset, datatype, ensemble, ordering, structure, lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
