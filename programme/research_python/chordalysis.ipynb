{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,'X.csv'))\n",
    "    label = pd.read_csv(os.path.join(dataPath,'Y.csv'))\n",
    "    return data,label\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = round(acc / y_true.shape[0],2)\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    f1_each = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one,\n",
    "                   \"f1_each_label\":f1_each}\n",
    "    return performance\n",
    "\n",
    "def get_confusion_matrix(y_pred, y_test, column_names):\n",
    "    \"\"\"confusion matrix \"\"\"\n",
    "    confusion_matrix = pd.DataFrame(np.array(y_pred) - np.array(y_test), columns=column_names)\n",
    "    pos = pd.DataFrame((np.array(y_pred) == np.array(y_test)) & (np.array(y_pred) == 1), columns=y_test.columns).sum(axis=0)\n",
    "    neg = pd.DataFrame((np.array(y_pred) == np.array(y_test)) & (np.array(y_pred) == 0), columns=y_test.columns).sum(axis=0)\n",
    "    for i in range(confusion_matrix.shape[1]): \n",
    "        name = confusion_matrix.iloc[:,i].name\n",
    "        temp = confusion_matrix.iloc[:,i].value_counts()\n",
    "        TP = pos[name]\n",
    "        TN = neg[name]\n",
    "        if 1 in temp.index:\n",
    "            FP = temp[1]\n",
    "        else:\n",
    "            FP = 0\n",
    "        if -1 in temp.index:\n",
    "            FN = temp[-1]\n",
    "        else:\n",
    "            FN = 0\n",
    "\n",
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    print(\"-- test index --\")\n",
    "    print(X_test.index)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_predict, y_prob, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # get confusion matrix\n",
    "    get_confusion_matrix(y_predict, y_test, y_test.columns)\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))\n",
    "    \n",
    "    return y_predict, y_test\n",
    "\n",
    "# two fold cross-validation\n",
    "def two_fold_BR_test(data, label, dataPath, n_iter=5, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # 2-fold cross validatiom\n",
    "    KF=KFold(n_splits=2, shuffle=True, random_state=random_state)\n",
    "    i = 0\n",
    "    \n",
    "    performance = {}\n",
    "    for train_index,test_index in KF.split(data):\n",
    "        i += 1\n",
    "        \n",
    "        X_train,X_test=data.iloc[train_index,:],data.iloc[test_index,:]\n",
    "        y_train,y_test=label.iloc[train_index,:],label.iloc[test_index,:]\n",
    "        \n",
    "        print(\"--- kfold time=\"+str(i)+\" ---\")\n",
    "        # training\n",
    "        classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "        # testing\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "        \n",
    "        # evaluation\n",
    "        if performance == {}:\n",
    "            performance = evaluation(y_predict, y_prob, y_test)\n",
    "        else:\n",
    "            performance_i = evaluation(y_predict, y_prob, y_test)\n",
    "            for key, value in performance_i.items():\n",
    "                performance[key] = (performance[key] + value)/2\n",
    "            else:\n",
    "                performance[key] = value\n",
    "    \n",
    "    # print data information\n",
    "    print(\"\\n--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- 2 fold cross-validation Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            continue\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593\n",
      "avgerage number of labels for an instance: 1.8684654300168635\n",
      "avgerage number of positive instances for a label: 184.66666666666666 the std: 41.03494445794543 \n",
      "\n",
      "-- number of positive instances --\n",
      "amazed-suprised    173\n",
      "happy-pleased      166\n",
      "relaxing-calm      264\n",
      "quiet-still        148\n",
      "sad-lonely         168\n",
      "angry-aggresive    189\n",
      "dtype: int64\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([305,  40, 469, 422, 166,  29, 537, 285,  57, 112,\n",
      "            ...\n",
      "            317,  27, 249, 551, 591,  36, 334, 480, 494, 511],\n",
      "           dtype='int64', length=297)\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.83 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.17\n",
      "hamming_loss = 0.24\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.65\n",
      "Jaccard_Index = 0.76\n",
      "zero_one_error = 0.76\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.66\n",
      "label_happy-pleased = 0.33\n",
      "label_relaxing-calm = 0.77\n",
      "label_quiet-still = 0.75\n",
      "label_sad-lonely = 0.56\n",
      "label_angry-aggresive = 0.69\n"
     ]
    }
   ],
   "source": [
    "dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/emotions/'\n",
    "dataset = 'emotions'\n",
    "data, label = read_data(dataPath) # read data\n",
    "\n",
    "# get data information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "avg_instance_per_label = label.sum(axis=0).mean()\n",
    "# print data information\n",
    "print(\"\\n--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance)\n",
    "print(\"avgerage number of labels for an instance:\",avg_label_per_instance)\n",
    "print(\"avgerage number of positive instances for a label:\",avg_instance_per_label,\"the std:\",sqrt(label.sum(axis=0).var()),\"\\n\")\n",
    "\n",
    "print(\"-- number of positive instances --\")\n",
    "print(label.sum(axis=0))\n",
    "\n",
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "y_predict, y_test = BR_test(data, label, dataPath,3071980)\n",
    "\n",
    "error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_test), columns=y_test.columns)\n",
    "error_matrix.to_csv(\"/Users/jiangjunhao/Desktop/error_matrix.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_BN(labelFile, labelName, savePng):\n",
    "    cmd = \"\"\"cd /Volumes/Samsung_T5/research/programme/Chordalysis/ \n",
    "    java -Xmx1g -classpath bin:lib/core/commons-math3-3.2.jar:lib/core/jayes.jar:lib/core/jgrapht-jdk1.6.jar:lib/extra/jgraphx.jar:lib/loader/weka.jar demo.Run %s 0.05 %s false\n",
    "    \"\"\" % (labelFile,savePng)\n",
    "\n",
    "    p = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE)\n",
    "    out,err = p.communicate()  \n",
    "    for line in out.splitlines():  \n",
    "        if line.decode(\"utf-8\").startswith('['):\n",
    "            graph_set = [i for i in map(lambda x: x.split(','), line.decode(\"utf-8\").replace(' ',',').strip('[[\\,]]').split(',]['))]\n",
    "\n",
    "    dic = {}\n",
    "    for l in labelName:\n",
    "        s = set()\n",
    "        for i in map(lambda x: set(x) if l in x else None, graph_set):\n",
    "            if i != None:\n",
    "                s.update(i)\n",
    "        s.remove(l)       \n",
    "        dic[l] = s\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593\n",
      "avgerage number of labels for an instance: 1.8684654300168635\n",
      "avgerage number of positive instances for a label: 184.66666666666666 the std: 41.03494445794543 \n",
      "\n",
      "-- number of positive instances --\n",
      "amazed-suprised    173\n",
      "happy-pleased      166\n",
      "relaxing-calm      264\n",
      "quiet-still        148\n",
      "sad-lonely         168\n",
      "angry-aggresive    189\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data, label = read_data(dataPath) # read data\n",
    "\n",
    "# get data information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "avg_instance_per_label = label.sum(axis=0).mean()\n",
    "# print data information\n",
    "print(\"\\n--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance)\n",
    "print(\"avgerage number of labels for an instance:\",avg_label_per_instance)\n",
    "print(\"avgerage number of positive instances for a label:\",avg_instance_per_label,\"the std:\",sqrt(label.sum(axis=0).var()),\"\\n\")\n",
    "\n",
    "print(\"-- number of positive instances --\")\n",
    "print(label.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-calm</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazed-suprised</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy-pleased</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxing-calm</th>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiet-still</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad-lonely</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry-aggresive</th>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 amazed-suprised  happy-pleased  relaxing-calm  quiet-still  \\\n",
       "amazed-suprised                0             56             13            0   \n",
       "happy-pleased                 56              0             91            7   \n",
       "relaxing-calm                 13             91              0          104   \n",
       "quiet-still                    0              7            104            0   \n",
       "sad-lonely                    10              1             95          105   \n",
       "angry-aggresive               92             12              7            2   \n",
       "\n",
       "                 sad-lonely  angry-aggresive  \n",
       "amazed-suprised          10               92  \n",
       "happy-pleased             1               12  \n",
       "relaxing-calm            95                7  \n",
       "quiet-still             105                2  \n",
       "sad-lonely                0               20  \n",
       "angry-aggresive          20                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix = label.T.dot(label)\n",
    "np.fill_diagonal(cooccurrence_matrix.values, 0)\n",
    "#cooccurrence_matrix.to_csv('/Users/jiangjunhao/Desktop/cooccurrence_matrix.csv', index=False)\n",
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-calm</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazed-suprised</th>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-16</td>\n",
       "      <td>-9</td>\n",
       "      <td>-17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy-pleased</th>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6</td>\n",
       "      <td>-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxing-calm</th>\n",
       "      <td>-16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiet-still</th>\n",
       "      <td>-9</td>\n",
       "      <td>-7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad-lonely</th>\n",
       "      <td>-17</td>\n",
       "      <td>-6</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry-aggresive</th>\n",
       "      <td>11</td>\n",
       "      <td>-18</td>\n",
       "      <td>-15</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 amazed-suprised  happy-pleased  relaxing-calm  quiet-still  \\\n",
       "amazed-suprised                0             -4            -16           -9   \n",
       "happy-pleased                 -4              0             13           -7   \n",
       "relaxing-calm                -16             13              0           12   \n",
       "quiet-still                   -9             -7             12            0   \n",
       "sad-lonely                   -17             -6             19           39   \n",
       "angry-aggresive               11            -18            -15           -6   \n",
       "\n",
       "                 sad-lonely  angry-aggresive  \n",
       "amazed-suprised         -17               11  \n",
       "happy-pleased            -6              -18  \n",
       "relaxing-calm            19              -15  \n",
       "quiet-still              39               -6  \n",
       "sad-lonely                0               -6  \n",
       "angry-aggresive          -6                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix = error_matrix.T.dot(error_matrix)\n",
    "np.fill_diagonal(cooccurrence_matrix.values, 0)\n",
    "#cooccurrence_matrix.to_csv('/Users/jiangjunhao/Desktop/cooccurrence_matrix.csv', index=False)\n",
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amazed-suprised': {'quiet-still', 'relaxing-calm'},\n",
       " 'angry-aggresive': {'relaxing-calm'},\n",
       " 'happy-pleased': {'sad-lonely'},\n",
       " 'quiet-still': {'amazed-suprised', 'sad-lonely'},\n",
       " 'relaxing-calm': {'amazed-suprised', 'angry-aggresive'},\n",
       " 'sad-lonely': {'happy-pleased', 'quiet-still'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelFile = \"/Volumes/Samsung_T5/research/data/small_datasets/emotions/y.csv\"\n",
    "savePng = \"/Users/jiangjunhao/Desktop/1.png\"\n",
    "label = pd.read_csv(labelFile)\n",
    "dic = build_BN(labelFile, label.columns, savePng)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amazed-suprised': {'relaxing-calm', 'sad-lonely'},\n",
       " 'angry-aggresive': {'happy-pleased', 'sad-lonely'},\n",
       " 'happy-pleased': {'angry-aggresive'},\n",
       " 'quiet-still': {'sad-lonely'},\n",
       " 'relaxing-calm': {'amazed-suprised'},\n",
       " 'sad-lonely': {'amazed-suprised', 'angry-aggresive', 'quiet-still'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
