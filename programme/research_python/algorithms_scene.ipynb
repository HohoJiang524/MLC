{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,'X.csv'))\n",
    "    label = pd.read_csv(os.path.join(dataPath,'Y.csv'))\n",
    "    return data,label\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = round(acc / y_true.shape[0],2)\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    f1_each = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one,\n",
    "                   \"f1_each_label\":f1_each}\n",
    "    return performance\n",
    "\n",
    "def get_confusion_matrix(y_pred, y_test, column_names):\n",
    "    \"\"\"confusion matrix \"\"\"\n",
    "    confusion_matrix = pd.DataFrame(np.array(y_pred) - np.array(y_test), columns=column_names)\n",
    "    pos = pd.DataFrame((np.array(y_pred) == np.array(y_test)) & (np.array(y_pred) == 1), columns=y_test.columns).sum(axis=0)\n",
    "    neg = pd.DataFrame((np.array(y_pred) == np.array(y_test)) & (np.array(y_pred) == 0), columns=y_test.columns).sum(axis=0)\n",
    "    for i in range(confusion_matrix.shape[1]): \n",
    "        name = confusion_matrix.iloc[:,i].name\n",
    "        temp = confusion_matrix.iloc[:,i].value_counts()\n",
    "        TP = pos[name]\n",
    "        TN = neg[name]\n",
    "        if 1 in temp.index:\n",
    "            FP = temp[1]\n",
    "        else:\n",
    "            FP = 0\n",
    "        if -1 in temp.index:\n",
    "            FN = temp[-1]\n",
    "        else:\n",
    "            FN = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407\n",
      "avgerage number of labels for an instance: 1.0739509763190693\n",
      "avgerage number of positive instances for a label: 430.8333333333333 the std: 56.690093196842305 \n",
      "\n",
      "-- number of positive instances --\n",
      "Beach          427\n",
      "Sunset         364\n",
      "FallFoliage    397\n",
      "Field          433\n",
      "Mountain       533\n",
      "Urban          431\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/scene/'\n",
    "dataset = 'scene'\n",
    "data, label = read_data(dataPath) # read data\n",
    "\n",
    "# get data information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "avg_instance_per_label = label.sum(axis=0).mean()\n",
    "# print data information\n",
    "print(\"\\n--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance)\n",
    "print(\"avgerage number of labels for an instance:\",avg_label_per_instance)\n",
    "print(\"avgerage number of positive instances for a label:\",avg_instance_per_label,\"the std:\",sqrt(label.sum(axis=0).var()),\"\\n\")\n",
    "\n",
    "print(\"-- number of positive instances --\")\n",
    "print(label.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Field</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunset</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FallFoliage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mountain</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urban</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Beach  Sunset  FallFoliage  Field  Mountain  Urban\n",
       "Beach            0       0            0      1        38     19\n",
       "Sunset           0       0            0      0         0      0\n",
       "FallFoliage      0       0            0     24        14      0\n",
       "Field            1       0           24      0        76      6\n",
       "Mountain        38       0           14     76         0      1\n",
       "Urban           19       0            0      6         1      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix = label.T.dot(label)\n",
    "np.fill_diagonal(cooccurrence_matrix.values, 0)\n",
    "#cooccurrence_matrix.to_csv('/Users/jiangjunhao/Desktop/cooccurrence_matrix.csv', index=False)\n",
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Relevance \n",
    "\n",
    "## BR using naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    print(\"-- test index --\")\n",
    "    print(X_test.index)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_predict, y_prob, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # get confusion matrix\n",
    "    get_confusion_matrix(y_predict, y_test, y_test.columns)\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))\n",
    "            \n",
    "# two fold cross-validation\n",
    "def two_fold_BR_test(data, label, dataPath, n_iter=5, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # 2-fold cross validatiom\n",
    "    KF=KFold(n_splits=2, shuffle=True, random_state=random_state)\n",
    "    i = 0\n",
    "    \n",
    "    performance = {}\n",
    "    for train_index,test_index in KF.split(data):\n",
    "        i += 1\n",
    "        \n",
    "        X_train,X_test=data.iloc[train_index,:],data.iloc[test_index,:]\n",
    "        y_train,y_test=label.iloc[train_index,:],label.iloc[test_index,:]\n",
    "        \n",
    "        print(\"--- kfold time=\"+str(i)+\" ---\")\n",
    "        # training\n",
    "        classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "        # testing\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "        \n",
    "        # evaluation\n",
    "        if performance == {}:\n",
    "            performance = evaluation(y_predict, y_prob, y_test)\n",
    "        else:\n",
    "            performance_i = evaluation(y_predict, y_prob, y_test)\n",
    "            for key, value in performance_i.items():\n",
    "                performance[key] = (performance[key] + value)/2\n",
    "            else:\n",
    "                performance[key] = value\n",
    "    \n",
    "    # print data information\n",
    "    print(\"\\n--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- 2 fold cross-validation Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            continue\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([1513, 1617,   69, 1114, 1663, 1219, 2343,   20, 1041, 1589,\n",
      "            ...\n",
      "            1596,  303,  178, 1755,  308,  872, 2318,  403, 1782, 1255],\n",
      "           dtype='int64', length=1204)\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.51 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.08\n",
      "hamming_loss = 0.21\n",
      "f1_macro = 0.62\n",
      "f1_micro = 0.6\n",
      "Jaccard_Index = 0.79\n",
      "zero_one_error = 0.8\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.54\n",
      "label_Sunset = 0.73\n",
      "label_FallFoliage = 0.62\n",
      "label_Field = 0.76\n",
      "label_Mountain = 0.54\n",
      "label_Urban = 0.53\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "BR_test(data, label, dataPath,3071980)\n",
    "\n",
    "#print(\"\")\n",
    "#print(\"------ two_fold Binary Relevance using Naive Bayes ------\")\n",
    "#two_fold_BR_test(data, label, dataPath,3071980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([   5,    7,    8,   11,   15,   16,   17,   21,   23,   24,\n",
      "            ...\n",
      "            2386, 2389, 2391, 2392, 2393, 2395, 2396, 2400, 2401, 2406],\n",
      "           dtype='int64', length=1204)\n",
      "--- start training ---\n",
      "\n",
      "--- start testing ---\n",
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.59 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.1\n",
      "hamming_loss = 0.21\n",
      "f1_macro = 0.62\n",
      "f1_micro = 0.6\n",
      "Jaccard_Index = 0.79\n",
      "zero_one_error = 0.81\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.54\n",
      "label_Sunset = 0.7\n",
      "label_FallFoliage = 0.63\n",
      "label_Field = 0.76\n",
      "label_Mountain = 0.54\n",
      "label_Urban = 0.54\n"
     ]
    }
   ],
   "source": [
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# split training and test data set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# training\n",
    "print(\"--- start training ---\\n\")\n",
    "classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "# testing\n",
    "print(\"--- start testing ---\\n\")\n",
    "y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "\n",
    "# get confusion matrix\n",
    "get_confusion_matrix(y_predict, y_test, y_test.columns)\n",
    "    \n",
    "# evaluation\n",
    "performance = evaluation(y_predict, y_prob, y_test)\n",
    "\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR using ESKDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arff(word_occurrence, label_matrix, savePath): # get attributes\n",
    "    for z in range(len(label_matrix.columns)):\n",
    "        attributes=[(word_occurrence.columns[i],list(map(str,sorted(word_occurrence.iloc[:,i].unique())))) for i in range(len(word_occurrence.columns))]\n",
    "        attributes.append(('label_'+label_matrix.columns[z],['0', '1']))\n",
    "\n",
    "        data=[]\n",
    "        i = 0\n",
    "        while i < label_matrix.shape[0]:\n",
    "            attr_data = [str(j) for j in list(word_occurrence.iloc[i,:])]\n",
    "            label_data = [str(label_matrix.iloc[i,z])]\n",
    "            row_data = attr_data+label_data\n",
    "            data.append(row_data) \n",
    "            i+=1\n",
    "        # set obj\n",
    "        obj = {\n",
    "           'description': u'',\n",
    "           'relation': 'relation',\n",
    "           'attributes': attributes,\n",
    "           'data': data,\n",
    "        }\n",
    "        arff_data = arff.dumps(obj)\n",
    "        w_file = open(savePath+label_matrix.columns[z]+\".arff\", \"w\")\n",
    "        w_file.write(arff_data)\n",
    "        w_file.close()\n",
    "\n",
    "def run_eskdb(dataPath, resultFile, k, l, e, i):\n",
    "    command = \"./run_eskdb.sh \"+resultFile+\" \"+k+\" \"+i+\" \"+l+\" \"+e+\" \"+dataPath\n",
    "    subprocess.call(\"cd /Volumes/Samsung_T5/research/programme/research_python/\", shell=True)\n",
    "    print(command)\n",
    "    return subprocess.call(command, shell=True)\n",
    "\n",
    "def get_result(resultPath):\n",
    "\n",
    "    y_pred = pd.DataFrame()\n",
    "    y_true = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    names = []\n",
    "    for file in os.listdir(resultPath):\n",
    "        with open(os.path.join(resultPath,file), 'r') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(file)\n",
    "            else:\n",
    "                names.append(file[:-4])\n",
    "                pred = []\n",
    "                true = []\n",
    "                prob = []\n",
    "                train_time_total = 0\n",
    "                test_time_total = 0\n",
    "                error_marco = 0\n",
    "                for line in lines:\n",
    "                    if line.startswith('pred'):\n",
    "                        pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                        true.append(int(re.search('true :\\t(.)',line).group(1)))\n",
    "                        prob.append(float(re.search('prob :\\t(.*)',line).group(1)))\n",
    "                    elif line.startswith('RSME'):\n",
    "                        rsme = float(re.search('RSME :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith('Error'):\n",
    "                        error = float(re.search('Error :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith(\"Training time\"):\n",
    "                        train_time = float(re.search('Training time :\\s{1,}(.*)',line).group(1))\n",
    "                        train_time_total = train_time_total + train_time\n",
    "                    elif line.startswith(\"Testing time\"):\n",
    "                        test_time = float(re.search('Testing time :\\s{1,}(.*)',line).group(1))\n",
    "                        test_time_total = test_time_total + test_time\n",
    "                    elif line.startswith(\"[\"):\n",
    "                        para = line\n",
    "                    elif line.startswith(\"test0Indexes\"):\n",
    "                        index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "                y_pred = pd.concat([y_pred,pd.DataFrame(pred)],axis=1)\n",
    "                y_true = pd.concat([y_true,pd.DataFrame(true)],axis=1)\n",
    "                y_prob = pd.concat([y_prob,pd.DataFrame(prob)],axis=1)\n",
    "    y_pred.columns = names\n",
    "    y_true.columns = names\n",
    "    y_pred.index = index\n",
    "    y_true.index = index\n",
    "    print(para)\n",
    "    print(\"number of label:\", y_pred.shape[1])\n",
    "    print(\"training time:\",train_time_total)\n",
    "    print(\"testing time:\",test_time_total)\n",
    "    return y_pred,y_true,y_prob,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_eskdb.sh scene_k5_e20_i5000 5 5000 2 20 /Users/jiangjunhao/Desktop/test/scene/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# get arff files\n",
    "\n",
    "savePath = \"/Users/jiangjunhao/Desktop/test/\"+dataset+'/'\n",
    "if not os.path.exists(savePath):\n",
    "    os.mkdir(savePath)\n",
    "get_arff(data,label,savePath)\n",
    "\n",
    "resultFile = dataset+'_k5_e20_i5000'\n",
    "k = '5'\n",
    "i = '5000'\n",
    "l = '2'\n",
    "e = '20'\n",
    "\n",
    "run_eskdb(savePath, resultFile, k, l, e, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-t, /Users/jiangjunhao/Desktop/test/scene//Urban.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 5561.0\n",
      "testing time: 9004.0\n",
      "--- Performance ---\n",
      "coverage_error = 1.45 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.07\n",
      "hamming_loss = 0.09\n",
      "f1_macro = 0.74\n",
      "f1_micro = 0.73\n",
      "Jaccard_Index = 0.91\n",
      "zero_one_error = 0.41\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.65\n",
      "label_Sunset = 0.86\n",
      "label_FallFoliage = 0.84\n",
      "label_Field = 0.55\n",
      "label_Mountain = 0.89\n",
      "label_Urban = 0.62\n"
     ]
    }
   ],
   "source": [
    "resultPath = '/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result/'+resultFile\n",
    "y_pred,y_true,y_prob,index = get_result(resultPath)\n",
    "\n",
    "performance = evaluation(y_pred=y_pred, y_true=y_true, y_prob=y_prob)\n",
    "    \n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Chain\n",
    "\n",
    "## CC using naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    \n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "    \n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)] # create a classifier chain\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            classifier_list[i].fit(X_train,y_train.iloc[:, order[i]])\n",
    "        else:\n",
    "            X_train = pd.concat([X_train, y_train.iloc[:,order[i-1]]],axis=1) # put the previous label into attribute space\n",
    "            classifier_list[i].fit(X_train,y_train.iloc[:,order[i]])\n",
    "\n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time, order\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order):\n",
    "    y_predict = pd.DataFrame(index=X_test.index)\n",
    "    y_prob = pd.DataFrame(index=X_test.index)\n",
    "    y_true = pd.DataFrame(index=X_test.index)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index)],axis=1)\n",
    "\n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index)],axis=1)\n",
    "\n",
    "        X_test = pd.concat([X_test, pd.DataFrame(y_predict_i,index=X_test.index)],axis=1,ignore_index=True) # put the previous label into attribute space\n",
    "\n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def CC_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # training\n",
    "    print(\"--- start training ---\\n\")\n",
    "    classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    print(\"--- start testing ---\\n\")\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "    \n",
    "    # evaluation\n",
    "    y_test = y_test.iloc[:,order]\n",
    "    performance = evaluation(y_predict, y_prob, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print orders\n",
    "    print(\"\\n--- Order of the chain ---\")\n",
    "    print(label.columns[order])\n",
    "    print(\"\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))\n",
    "            \n",
    "def ECC_test(data, label, dataPath, random_state=3071980, ensemble = 5):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # ensemble\n",
    "    y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    for i in range(ensemble):\n",
    "        # training\n",
    "        #print(\"--- start training ---\\n\")\n",
    "        classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "        # print orders\n",
    "        print(\"Order of the chain:\",label.columns[order])\n",
    "\n",
    "        # testing\n",
    "        #print(\"--- start testing ---\\n\")\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "        y_predict.columns = label.columns[order]\n",
    "        y_prob.columns = label.columns[order]\n",
    "        y_predict = y_predict[label.columns]\n",
    "        y_prob = y_prob[label.columns]\n",
    "\n",
    "        y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "        y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "    y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "    y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print orders\n",
    "    print(\"\\n--- Order of the chain ---\")\n",
    "    print(label.columns[order])\n",
    "    print(\"\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "Order of the chain: Index(['Field', 'Urban', 'Sunset', 'FallFoliage', 'Beach', 'Mountain'], dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['Field', 'Urban', 'Sunset', 'FallFoliage', 'Beach', 'Mountain'], dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.54 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.09\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.62\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.79\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.57\n",
      "label_Sunset = 0.73\n",
      "label_FallFoliage = 0.65\n",
      "label_Field = 0.76\n",
      "label_Mountain = 0.55\n",
      "label_Urban = 0.54\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "ECC_test(data, label, dataPath, 3071980, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([   5,    7,    8,   11,   15,   16,   17,   21,   23,   24,\n",
      "            ...\n",
      "            2386, 2389, 2391, 2392, 2393, 2395, 2396, 2400, 2401, 2406],\n",
      "           dtype='int64', length=1204)\n",
      "--- start training ---\n",
      "\n",
      "--- start testing ---\n",
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['Field', 'FallFoliage', 'Beach', 'Mountain', 'Urban', 'Sunset'], dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.57 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.1\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.62\n",
      "f1_micro = 0.61\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.8\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.76\n",
      "label_Sunset = 0.64\n",
      "label_FallFoliage = 0.54\n",
      "label_Field = 0.54\n",
      "label_Mountain = 0.56\n",
      "label_Urban = 0.71\n"
     ]
    }
   ],
   "source": [
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# split training and test data set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# training\n",
    "print(\"--- start training ---\\n\")\n",
    "classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "# testing\n",
    "print(\"--- start testing ---\\n\")\n",
    "y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "# evaluation\n",
    "y_test = y_test.iloc[:,order]\n",
    "performance = evaluation(y_predict, y_prob, y_test)\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print orders\n",
    "print(\"\\n--- Order of the chain ---\")\n",
    "print(label.columns[order])\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble CC using naive Bayes (E = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "Order of the chain: Index(['Urban', 'Beach', 'Field', 'FallFoliage', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'FallFoliage', 'Field', 'Mountain', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Beach', 'FallFoliage', 'Sunset', 'Field', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Sunset', 'Mountain', 'Urban', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'FallFoliage', 'Urban', 'Mountain', 'Field', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Sunset', 'Field', 'Mountain', 'FallFoliage', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Field', 'Mountain', 'Sunset', 'FallFoliage', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Field', 'Urban', 'FallFoliage', 'Beach', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Urban', 'Field', 'Sunset', 'FallFoliage', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Mountain', 'Sunset', 'Field', 'FallFoliage', 'Beach'], dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['Urban', 'Mountain', 'Sunset', 'Field', 'FallFoliage', 'Beach'], dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.51 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.08\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.64\n",
      "f1_micro = 0.62\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.79\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.54\n",
      "label_Sunset = 0.73\n",
      "label_FallFoliage = 0.65\n",
      "label_Field = 0.8\n",
      "label_Mountain = 0.54\n",
      "label_Urban = 0.56\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "ECC_test(data, label, dataPath, random_state=3071980, ensemble=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([   5,    7,    8,   11,   15,   16,   17,   21,   23,   24,\n",
      "            ...\n",
      "            2386, 2389, 2391, 2392, 2393, 2395, 2396, 2400, 2401, 2406],\n",
      "           dtype='int64', length=1204)\n",
      "Order of the chain: Index(['Field', 'Beach', 'FallFoliage', 'Urban', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Urban', 'Mountain', 'Sunset', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Beach', 'Mountain', 'FallFoliage', 'Sunset', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Mountain', 'Beach', 'Urban', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'FallFoliage', 'Urban', 'Mountain', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Field', 'Sunset', 'Urban', 'FallFoliage', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Mountain', 'Sunset', 'Beach', 'Urban', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Field', 'Beach', 'FallFoliage', 'Urban', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Field', 'FallFoliage', 'Mountain', 'Urban', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Beach', 'Mountain', 'Urban', 'Field'], dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['FallFoliage', 'Sunset', 'Beach', 'Mountain', 'Urban', 'Field'], dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.58 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.1\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.61\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.8\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.54\n",
      "label_Sunset = 0.7\n",
      "label_FallFoliage = 0.64\n",
      "label_Field = 0.78\n",
      "label_Mountain = 0.55\n",
      "label_Urban = 0.54\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "ensemble=10\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# ensemble\n",
    "y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "for i in range(ensemble):\n",
    "    # training\n",
    "    #print(\"--- start training ---\\n\")\n",
    "    classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "    # print orders\n",
    "    print(\"Order of the chain:\",label.columns[order])\n",
    "\n",
    "    # testing\n",
    "    #print(\"--- start testing ---\\n\")\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "    y_predict.columns = label.columns[order]\n",
    "    y_prob.columns = label.columns[order]\n",
    "    y_predict = y_predict[label.columns]\n",
    "    y_prob = y_prob[label.columns]\n",
    "\n",
    "    y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "\n",
    "# evaluation\n",
    "performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print orders\n",
    "print(\"\\n--- Order of the chain ---\")\n",
    "print(label.columns[order])\n",
    "print(\"\")\n",
    "\n",
    "# get confusion matrix\n",
    "get_confusion_matrix(y_pred_ensemble, y_test, y_test.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble CC using naive Bayes (E = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "Order of the chain: Index(['Field', 'Sunset', 'FallFoliage', 'Urban', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'FallFoliage', 'Mountain', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Urban', 'Beach', 'Mountain', 'FallFoliage', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Mountain', 'Sunset', 'FallFoliage', 'Beach', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Mountain', 'Beach', 'Sunset', 'FallFoliage', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Beach', 'Urban', 'FallFoliage', 'Field', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'Field', 'FallFoliage', 'Urban', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Field', 'Urban', 'Mountain', 'Beach', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Beach', 'Field', 'Urban', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Sunset', 'Field', 'FallFoliage', 'Mountain', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Beach', 'Field', 'Mountain', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Sunset', 'Field', 'Mountain', 'Beach', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'FallFoliage', 'Urban', 'Beach', 'Sunset', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Mountain', 'Sunset', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Field', 'Mountain', 'Beach', 'Urban', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Mountain', 'Field', 'Sunset', 'Beach', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Urban', 'Sunset', 'Mountain', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Mountain', 'Field', 'Beach', 'Sunset', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'Mountain', 'FallFoliage', 'Field', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Mountain', 'FallFoliage', 'Sunset', 'Urban', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Beach', 'Urban', 'Field', 'FallFoliage', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Beach', 'Urban', 'FallFoliage', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Sunset', 'Mountain', 'Field', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Beach', 'FallFoliage', 'Urban', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Sunset', 'Urban', 'FallFoliage', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Mountain', 'Field', 'Sunset', 'Beach', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Field', 'Beach', 'Mountain', 'Sunset', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'Mountain', 'Beach', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Mountain', 'FallFoliage', 'Beach', 'Urban', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Sunset', 'Field', 'Urban', 'Mountain', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Mountain', 'Sunset', 'Urban', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Mountain', 'Field', 'Sunset', 'Beach', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Mountain', 'Urban', 'Sunset', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'FallFoliage', 'Urban', 'Mountain', 'Sunset', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'FallFoliage', 'Field', 'Sunset', 'Urban', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Mountain', 'Field', 'Sunset', 'Beach', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Urban', 'Sunset', 'Field', 'FallFoliage', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Beach', 'Field', 'Sunset', 'Mountain', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Mountain', 'Urban', 'Beach', 'FallFoliage', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Sunset', 'Mountain', 'FallFoliage', 'Urban', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'FallFoliage', 'Field', 'Urban', 'Sunset', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'Mountain', 'FallFoliage', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Field', 'Urban', 'FallFoliage', 'Beach', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Urban', 'Beach', 'FallFoliage', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'FallFoliage', 'Urban', 'Beach', 'Sunset', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Mountain', 'Beach', 'Urban', 'Sunset', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Field', 'Urban', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Mountain', 'FallFoliage', 'Urban', 'Beach', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Urban', 'FallFoliage', 'Sunset', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'FallFoliage', 'Urban', 'Mountain', 'Field'], dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['Sunset', 'Beach', 'FallFoliage', 'Urban', 'Mountain', 'Field'], dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.51 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.08\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.61\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.79\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.56\n",
      "label_Sunset = 0.74\n",
      "label_FallFoliage = 0.62\n",
      "label_Field = 0.8\n",
      "label_Mountain = 0.54\n",
      "label_Urban = 0.54\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "ECC_test(data, label, dataPath, random_state=3071980, ensemble=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([   5,    7,    8,   11,   15,   16,   17,   21,   23,   24,\n",
      "            ...\n",
      "            2386, 2389, 2391, 2392, 2393, 2395, 2396, 2400, 2401, 2406],\n",
      "           dtype='int64', length=1204)\n",
      "Order of the chain: Index(['Field', 'FallFoliage', 'Urban', 'Mountain', 'Beach', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Mountain', 'Urban', 'FallFoliage', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Mountain', 'Urban', 'FallFoliage', 'Field', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Mountain', 'Field', 'Sunset', 'Beach', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Urban', 'Field', 'Sunset', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Mountain', 'Sunset', 'Field', 'Beach', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Mountain', 'Urban', 'Field', 'Beach', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Beach', 'Sunset', 'Mountain', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'FallFoliage', 'Mountain', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Beach', 'Urban', 'Field', 'Sunset', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Field', 'Beach', 'FallFoliage', 'Sunset', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'Urban', 'FallFoliage', 'Field', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Beach', 'Sunset', 'Urban', 'Field', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Beach', 'Urban', 'Mountain', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Urban', 'Mountain', 'Field', 'Sunset', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'Urban', 'Mountain', 'FallFoliage', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Beach', 'Urban', 'FallFoliage', 'Field', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Field', 'Beach', 'Sunset', 'FallFoliage', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Urban', 'Field', 'Beach', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Beach', 'Sunset', 'Field', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Beach', 'Field', 'Mountain', 'FallFoliage', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Beach', 'Field', 'Mountain', 'Urban', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'FallFoliage', 'Urban', 'Field', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Sunset', 'Beach', 'Mountain', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Field', 'FallFoliage', 'Mountain', 'Beach', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'Beach', 'Mountain', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Urban', 'Mountain', 'Sunset', 'FallFoliage', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Sunset', 'FallFoliage', 'Urban', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Field', 'Sunset', 'Mountain', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Mountain', 'FallFoliage', 'Field', 'Urban', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'Beach', 'Field', 'FallFoliage', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Beach', 'FallFoliage', 'Field', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'FallFoliage', 'Field', 'Beach', 'Urban', 'Mountain'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Sunset', 'Field', 'Beach', 'FallFoliage', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Urban', 'Sunset', 'Mountain', 'Beach', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Mountain', 'FallFoliage', 'Sunset', 'Beach', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Sunset', 'Field', 'Mountain', 'Beach', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Field', 'Mountain', 'Sunset', 'FallFoliage', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Field', 'FallFoliage', 'Urban', 'Beach', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Mountain', 'Field', 'Sunset', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'Beach', 'Mountain', 'FallFoliage', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Sunset', 'Urban', 'Beach', 'FallFoliage', 'Mountain', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['FallFoliage', 'Beach', 'Mountain', 'Urban', 'Field', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'Mountain', 'Sunset', 'Beach', 'Field', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Beach', 'Field', 'Mountain', 'Sunset'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Urban', 'Beach', 'Sunset', 'Mountain', 'FallFoliage'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'FallFoliage', 'Urban', 'Beach', 'Sunset', 'Field'], dtype='object')\n",
      "Order of the chain: Index(['Field', 'Beach', 'FallFoliage', 'Mountain', 'Sunset', 'Urban'], dtype='object')\n",
      "Order of the chain: Index(['Urban', 'FallFoliage', 'Mountain', 'Field', 'Sunset', 'Beach'], dtype='object')\n",
      "Order of the chain: Index(['Mountain', 'Urban', 'Beach', 'Sunset', 'Field', 'FallFoliage'], dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/scene/\n",
      "number of label: 6\n",
      "number of attribute: 294\n",
      "number of instance: 2407 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['Mountain', 'Urban', 'Beach', 'Sunset', 'Field', 'FallFoliage'], dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 1.58 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.1\n",
      "hamming_loss = 0.19\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.61\n",
      "Jaccard_Index = 0.81\n",
      "zero_one_error = 0.8\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.57\n",
      "label_Sunset = 0.7\n",
      "label_FallFoliage = 0.64\n",
      "label_Field = 0.78\n",
      "label_Mountain = 0.55\n",
      "label_Urban = 0.54\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "ensemble=50\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# ensemble\n",
    "y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "for i in range(ensemble):\n",
    "    # training\n",
    "    #print(\"--- start training ---\\n\")\n",
    "    classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "    # print orders\n",
    "    print(\"Order of the chain:\",label.columns[order])\n",
    "\n",
    "    # testing\n",
    "    #print(\"--- start testing ---\\n\")\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "    y_predict.columns = label.columns[order]\n",
    "    y_prob.columns = label.columns[order]\n",
    "    y_predict = y_predict[label.columns]\n",
    "    y_prob = y_prob[label.columns]\n",
    "\n",
    "    y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "\n",
    "# evaluation\n",
    "performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print orders\n",
    "print(\"\\n--- Order of the chain ---\")\n",
    "print(label.columns[order])\n",
    "print(\"\")\n",
    "\n",
    "# get confusion matrix\n",
    "get_confusion_matrix(y_pred_ensemble, y_test, y_test.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CC using ESKDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "def csv_to_arff(X, label_i, savePath):\n",
    "    # get attributes\n",
    "    attributes=[(X.columns[i],['0', '1']) for i in range(len(X.columns))]\n",
    "    attributes.append(('label_'+label_i.name,['0', '1']))\n",
    "\n",
    "    data=[]\n",
    "    i = 0\n",
    "    while i < len(label_i):\n",
    "        attr_data = [str(j) for j in list(X.iloc[i,:])]\n",
    "        label_data = [str(label_i[i])]\n",
    "        row_data = attr_data+label_data\n",
    "        data.append(row_data) \n",
    "        i+=1\n",
    "    # set obj\n",
    "    obj = {\n",
    "       'description': u'',\n",
    "       'relation': 'relation',\n",
    "       'attributes': attributes,\n",
    "       'data': data,\n",
    "    }\n",
    "    arff_data = arff.dumps(obj)\n",
    "    w_file = open(savePath+label_i.name+\".arff\", \"w\")\n",
    "    w_file.write(arff_data)\n",
    "    w_file.close()\n",
    "\n",
    "def get_arff(X, label, savePath):\n",
    "    \n",
    "    n_label = label.shape[1]\n",
    "    # get orders\n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "    \n",
    "    #  get all arff files, one for each label\n",
    "    for i in range(n_label):\n",
    "        label_i = label.iloc[:,order[i]]\n",
    "        print(\"--Running label:\",label_i.name)\n",
    "        csv_to_arff(X, label_i, savePath)\n",
    "        \n",
    "        label_i.name = 'label_' + label_i.name\n",
    "        X = pd.concat([X, label_i], axis=1)\n",
    "    print(\"--finished getting arff files\")\n",
    "    return order\n",
    "\n",
    "def run_eskdb(label_arff, resultFile, k, l, e, i):\n",
    "    command = \"./run_ECC.sh \"+resultFile+\" \"+k+\" \"+i+\" \"+l+\" \"+e+\" \"+label_arff\n",
    "    subprocess.call(\"cd /Volumes/Samsung_T5/research/programme/research_python/\", shell=True)\n",
    "    #print(command)\n",
    "    return subprocess.call(command, shell=True)\n",
    "\n",
    "def get_result(resultPath):\n",
    "\n",
    "    y_pred = pd.DataFrame()\n",
    "    y_true = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    names = []\n",
    "    for file in os.listdir(resultPath):\n",
    "        with open(os.path.join(resultPath,file), 'r') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(file)\n",
    "            else:\n",
    "                names.append(file[:-4])\n",
    "                pred = []\n",
    "                true = []\n",
    "                prob = []\n",
    "                train_time_total = 0\n",
    "                test_time_total = 0\n",
    "                error_marco = 0\n",
    "                for line in lines:\n",
    "                    if line.startswith('pred'):\n",
    "                        pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                        true.append(int(re.search('true :\\t(.)',line).group(1)))\n",
    "                        prob.append(float(re.search('prob :\\t(.*)',line).group(1)))\n",
    "                    elif line.startswith('RSME'):\n",
    "                        rsme = float(re.search('RSME :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith('Error'):\n",
    "                        error = float(re.search('Error :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith(\"Training time\"):\n",
    "                        train_time = float(re.search('Training time :\\s{1,}(.*)',line).group(1))\n",
    "                        train_time_total = train_time_total + train_time\n",
    "                    elif line.startswith(\"Testing time\"):\n",
    "                        test_time = float(re.search('Testing time :\\s{1,}(.*)',line).group(1))\n",
    "                        test_time_total = test_time_total + test_time\n",
    "                    elif line.startswith(\"[\"):\n",
    "                        para = line\n",
    "                    elif line.startswith(\"test0Indexes\"):\n",
    "                        index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "                y_pred = pd.concat([y_pred,pd.DataFrame(pred)],axis=1)\n",
    "                y_true = pd.concat([y_true,pd.DataFrame(true)],axis=1)\n",
    "                y_prob = pd.concat([y_prob,pd.DataFrame(prob)],axis=1)\n",
    "    y_pred.columns = names\n",
    "    y_true.columns = names\n",
    "    y_prob.columns = names\n",
    "    print(para)\n",
    "    print(\"number of label:\", y_pred.shape[1])\n",
    "    print(\"training time:\",train_time_total)\n",
    "    print(\"testing time:\",test_time_total)\n",
    "    return y_pred,y_true,y_prob,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4303.0\n",
      "testing time: 3263.0\n",
      "Index(['Field', 'Mountain', 'Sunset', 'Urban', 'FallFoliage', 'Beach'], dtype='object')\n",
      "\n",
      "--- Confusion matrix ---\n",
      "--- Performance ---\n",
      "coverage_error = 1.45 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.08\n",
      "hamming_loss = 0.09\n",
      "f1_macro = 0.74\n",
      "f1_micro = 0.73\n",
      "Jaccard_Index = 0.91\n",
      "zero_one_error = 0.36\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.84\n",
      "label_Sunset = 0.53\n",
      "label_FallFoliage = 0.9\n",
      "label_Field = 0.62\n",
      "label_Mountain = 0.85\n",
      "label_Urban = 0.68\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "n_label = label.shape[1]\n",
    "\n",
    "resultFile = dataset+'_k5_e20_i5000_CC'\n",
    "\n",
    "# train and test on the first label\n",
    "savePath = \"/Users/jiangjunhao/Desktop/test/\"+dataset+'/'\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# get orders\n",
    "order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "\n",
    "\n",
    "## prepare data, get the arff file\n",
    "for i in range(n_label):\n",
    "    label_i = label.iloc[:,order[i]]\n",
    "    #print(\"--Running label:\",label_i.name)\n",
    "    csv_to_arff(data, label_i, savePath)\n",
    "\n",
    "    # run eskdb\n",
    "    label_arff = os.path.join(savePath,label_i.name+'.arff')\n",
    "    k = '5'\n",
    "    i = '5000'\n",
    "    l = '2'\n",
    "    e = '20'\n",
    "\n",
    "    run_eskdb(label_arff, resultFile, k, l, e, i)\n",
    "\n",
    "    result = os.path.join(\"/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result\",resultFile, label_i.name+'.txt')\n",
    "    with open(result, 'r') as f:\n",
    "        try:\n",
    "            lines = f.readlines()\n",
    "        except:\n",
    "            print(file)\n",
    "        else:\n",
    "            pred = []\n",
    "            for line in lines:\n",
    "                if line.startswith('pred'):\n",
    "                    pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                elif line.startswith(\"test0Indexes\"):\n",
    "                    index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "            label.loc[index,label_i.name] = pred\n",
    "            temp = label.loc[:,label_i.name]\n",
    "            temp.name = 'label_'+label_i.name\n",
    "            data = pd.concat([data, label.loc[:,label_i.name]],axis=1)\n",
    "\n",
    "# get result\n",
    "resultPath = '/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result/'+resultFile+'/'\n",
    "y_pred,y_true,y_prob,index = get_result(resultPath)\n",
    "performance = evaluation(y_pred=y_pred, y_true=y_true, y_prob=y_prob)\n",
    "\n",
    "# print orders:\n",
    "print(label.columns[order])\n",
    "\n",
    "# get confusion matrix\n",
    "print(\"\\n--- Confusion matrix ---\")\n",
    "get_confusion_matrix(y_pred, y_true, y_pred.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble CC using ESKDB(E=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Running label: Urban\n",
      "--Running label: Mountain\n",
      "--Running label: FallFoliage\n",
      "--Running label: Beach\n",
      "--Running label: Field\n",
      "--Running label: Sunset\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4648.0\n",
      "testing time: 4080.0\n",
      "--Running label: FallFoliage\n",
      "--Running label: Field\n",
      "--Running label: Mountain\n",
      "--Running label: Beach\n",
      "--Running label: Urban\n",
      "--Running label: Sunset\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4306.0\n",
      "testing time: 3526.0\n",
      "--Running label: FallFoliage\n",
      "--Running label: Urban\n",
      "--Running label: Mountain\n",
      "--Running label: Beach\n",
      "--Running label: Field\n",
      "--Running label: Sunset\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4416.0\n",
      "testing time: 3499.0\n",
      "--Running label: Field\n",
      "--Running label: FallFoliage\n",
      "--Running label: Mountain\n",
      "--Running label: Beach\n",
      "--Running label: Sunset\n",
      "--Running label: Urban\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4355.0\n",
      "testing time: 3137.0\n",
      "--Running label: Field\n",
      "--Running label: Beach\n",
      "--Running label: Mountain\n",
      "--Running label: Urban\n",
      "--Running label: Sunset\n",
      "--Running label: FallFoliage\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4381.0\n",
      "testing time: 3161.0\n",
      "--Running label: Beach\n",
      "--Running label: Mountain\n",
      "--Running label: Sunset\n",
      "--Running label: Field\n",
      "--Running label: Urban\n",
      "--Running label: FallFoliage\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4197.0\n",
      "testing time: 2876.0\n",
      "--Running label: Field\n",
      "--Running label: Mountain\n",
      "--Running label: Urban\n",
      "--Running label: Beach\n",
      "--Running label: Sunset\n",
      "--Running label: FallFoliage\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4212.0\n",
      "testing time: 3566.0\n",
      "--Running label: Beach\n",
      "--Running label: Urban\n",
      "--Running label: FallFoliage\n",
      "--Running label: Mountain\n",
      "--Running label: Field\n",
      "--Running label: Sunset\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4170.0\n",
      "testing time: 2653.0\n",
      "--Running label: Urban\n",
      "--Running label: Field\n",
      "--Running label: Mountain\n",
      "--Running label: FallFoliage\n",
      "--Running label: Beach\n",
      "--Running label: Sunset\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4502.0\n",
      "testing time: 3962.0\n",
      "--Running label: Sunset\n",
      "--Running label: Beach\n",
      "--Running label: Urban\n",
      "--Running label: Field\n",
      "--Running label: Mountain\n",
      "--Running label: FallFoliage\n",
      "[-t, /Users/jiangjunhao/Desktop/test/scene/Beach.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 4311.0\n",
      "testing time: 3357.0\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "n_label = label.shape[1]\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# ensemble\n",
    "ensemble = 10\n",
    "\n",
    "y_pred_ensemble = pd.DataFrame(np.zeros((int(label.shape[0]/2+1),label.shape[1])),columns=label.columns)\n",
    "y_prob_ensemble = pd.DataFrame(np.zeros((int(label.shape[0]/2+1),label.shape[1])),columns=label.columns)\n",
    "    \n",
    "    \n",
    "for i in range(ensemble):\n",
    "\n",
    "    # read data\n",
    "    data, label = read_data(dataPath)\n",
    "    n_label = label.shape[1]\n",
    "\n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "    # get orders\n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "\n",
    "    # train and test on the first label\n",
    "    savePath = \"/Users/jiangjunhao/Desktop/test/\"+dataset+'/'\n",
    "\n",
    "    ## prepare data, get the arff file\n",
    "    for i in range(n_label):\n",
    "        label_i = label.iloc[:,order[i]]\n",
    "        print(\"--Running label:\",label_i.name)\n",
    "        csv_to_arff(data, label_i, savePath)\n",
    "\n",
    "        # run eskdb\n",
    "        label_arff = os.path.join(savePath,label_i.name+'.arff')\n",
    "        k = '5'\n",
    "        i = '5000'\n",
    "        l = '2'\n",
    "        e = '20'\n",
    "\n",
    "        run_eskdb(label_arff, resultFile, k, l, e, i)\n",
    "\n",
    "        result = os.path.join(\"/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result\",resultFile, label_i.name+'.txt')\n",
    "        with open(result, 'r') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(file)\n",
    "            else:\n",
    "                pred = []\n",
    "                for line in lines:\n",
    "                    if line.startswith('pred'):\n",
    "                        pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                    elif line.startswith(\"test0Indexes\"):\n",
    "                        index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "                label.loc[index,label_i.name] = pred\n",
    "                temp = label.loc[:,label_i.name]\n",
    "                temp.name = 'label_'+label_i.name\n",
    "                data = pd.concat([data, label.loc[:,label_i.name]],axis=1)\n",
    "\n",
    "    # get result\n",
    "    resultPath = '/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result/'+resultFile+'/'\n",
    "    y_pred,y_true,y_prob,index = get_result(resultPath)\n",
    "    y_pred.columns = label.columns\n",
    "    y_prob.columns = label.columns\n",
    "    \n",
    "    y_pred_ensemble = y_pred_ensemble + y_pred\n",
    "    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "    \n",
    "    \n",
    "y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "y_prob_ensemble = y_prob_ensemble / ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sunset', 'Beach', 'Urban', 'Field', 'Mountain', 'FallFoliage'], dtype='object')\n",
      "\n",
      "--- Confusion matrix ---\n",
      "--- Performance ---\n",
      "coverage_error = 1.42 ( avg_label_per_instance = 1.07 )\n",
      "ranking_loss = 0.07\n",
      "hamming_loss = 0.09\n",
      "f1_macro = 0.75\n",
      "f1_micro = 0.74\n",
      "Jaccard_Index = 0.91\n",
      "zero_one_error = 0.36\n",
      "\n",
      "- f1 for each label -\n",
      "label_Beach = 0.84\n",
      "label_Sunset = 0.58\n",
      "label_FallFoliage = 0.91\n",
      "label_Field = 0.64\n",
      "label_Mountain = 0.87\n",
      "label_Urban = 0.66\n"
     ]
    }
   ],
   "source": [
    "performance = evaluation(y_pred=y_pred_ensemble, y_true=y_true, y_prob=y_prob_ensemble)\n",
    "\n",
    "# print orders:\n",
    "print(label.columns[order])\n",
    "\n",
    "# get confusion matrix\n",
    "print(\"\\n--- Confusion matrix ---\")\n",
    "get_confusion_matrix(y_pred, y_true, y_pred.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "**Performance of BR_naive Bayes**\n",
    "coverage_error = 13.6 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.13\n",
    "hamming_loss = 0.1\n",
    "f1_macro = 0.26\n",
    "f1_micro = 0.4\n",
    "Jaccard_Index = 0.26\n",
    "zero_one_error = 0.98\n",
    "`\n",
    "\n",
    "`\n",
    "**Performance of BR_ESKDB**\n",
    "coverage_error = 14.76 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.15\n",
    "hamming_loss = 0.08\n",
    "f1_macro = 0.15\n",
    "f1_micro = 0.33\n",
    "jaccard_index = 0.23\n",
    "zero_one_error = 0.94\n",
    "`\n",
    "\n",
    "`\n",
    "**Performance of Ensemble Classifier Chain using naive Bayes**\n",
    "coverage_error = 13.63 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.13\n",
    "hamming_loss = 0.11\n",
    "f1_macro = 0.26\n",
    "f1_micro = 0.38\n",
    "Jaccard_Index = 0.25\n",
    "zero_one_error = 0.97\n",
    "`\n",
    "\n",
    "`\n",
    "**Performance of Ensemble Classifier Chain using ESKDB(E=2)**\n",
    "coverage_error = 15.87 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.16\n",
    "hamming_loss = 0.08\n",
    "f1_macro = 0.22\n",
    "f1_micro = 0.38\n",
    "Jaccard_Index = 0.25\n",
    "zero_one_error = 0.95\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall 体现了分类模型H对正样本的识别能力，recall 越高，说明模型对正样本的识别能力越强.\n",
    "\n",
    "precision 体现了模型对负样本的区分能力，precision越高，说明模型对负样本的区分能力越强。F1-score 是两者的综合。F1-score 越高，说明分类模型越稳健。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
