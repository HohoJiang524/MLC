{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,'X.csv'))\n",
    "    label = pd.read_csv(os.path.join(dataPath,'Y.csv'))\n",
    "    return data,label\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = round(acc / y_true.shape[0],2)\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    f1_each = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one,\n",
    "                   \"f1_each_label\":f1_each}\n",
    "    return performance\n",
    "\n",
    "def get_confusion_matrix(y_pred, y_test, column_names):\n",
    "    \"\"\"confusion matrix \"\"\"\n",
    "    confusion_matrix = pd.DataFrame(np.array(y_pred) - np.array(y_test), columns=column_names)\n",
    "    pos = pd.DataFrame((np.array(y_pred) == np.array(y_test)) & (np.array(y_pred) == 1), columns=y_test.columns).sum(axis=0)\n",
    "    neg = pd.DataFrame((np.array(y_pred) == np.array(y_test)) & (np.array(y_pred) == 0), columns=y_test.columns).sum(axis=0)\n",
    "    for i in range(confusion_matrix.shape[1]): \n",
    "        name = confusion_matrix.iloc[:,i].name\n",
    "        temp = confusion_matrix.iloc[:,i].value_counts()\n",
    "        TP = pos[name]\n",
    "        TN = neg[name]\n",
    "        if 1 in temp.index:\n",
    "            FP = temp[1]\n",
    "        else:\n",
    "            FP = 0\n",
    "        if -1 in temp.index:\n",
    "            FN = temp[-1]\n",
    "        else:\n",
    "            FN = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593\n",
      "avgerage number of labels for an instance: 1.8684654300168635\n",
      "avgerage number of positive instances for a label: 184.66666666666666 the std: 41.03494445794543 \n",
      "\n",
      "-- number of positive instances --\n",
      "amazed-suprised    173\n",
      "happy-pleased      166\n",
      "relaxing-calm      264\n",
      "quiet-still        148\n",
      "sad-lonely         168\n",
      "angry-aggresive    189\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/emotions/'\n",
    "dataset = 'emotions'\n",
    "data, label = read_data(dataPath) # read data\n",
    "\n",
    "# get data information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "avg_instance_per_label = label.sum(axis=0).mean()\n",
    "# print data information\n",
    "print(\"\\n--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance)\n",
    "print(\"avgerage number of labels for an instance:\",avg_label_per_instance)\n",
    "print(\"avgerage number of positive instances for a label:\",avg_instance_per_label,\"the std:\",sqrt(label.sum(axis=0).var()),\"\\n\")\n",
    "\n",
    "print(\"-- number of positive instances --\")\n",
    "print(label.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-calm</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazed-suprised</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy-pleased</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxing-calm</th>\n",
       "      <td>13</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiet-still</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad-lonely</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry-aggresive</th>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 amazed-suprised  happy-pleased  relaxing-calm  quiet-still  \\\n",
       "amazed-suprised                0             56             13            0   \n",
       "happy-pleased                 56              0             91            7   \n",
       "relaxing-calm                 13             91              0          104   \n",
       "quiet-still                    0              7            104            0   \n",
       "sad-lonely                    10              1             95          105   \n",
       "angry-aggresive               92             12              7            2   \n",
       "\n",
       "                 sad-lonely  angry-aggresive  \n",
       "amazed-suprised          10               92  \n",
       "happy-pleased             1               12  \n",
       "relaxing-calm            95                7  \n",
       "quiet-still             105                2  \n",
       "sad-lonely                0               20  \n",
       "angry-aggresive          20                0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix = label.T.dot(label)\n",
    "np.fill_diagonal(cooccurrence_matrix.values, 0)\n",
    "#cooccurrence_matrix.to_csv('/Users/jiangjunhao/Desktop/cooccurrence_matrix.csv', index=False)\n",
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Relevance \n",
    "\n",
    "## BR using naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    print(\"-- test index --\")\n",
    "    print(X_test.index)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_predict, y_prob, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # get confusion matrix\n",
    "    get_confusion_matrix(y_predict, y_test, y_test.columns)\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))\n",
    "     \n",
    "    \n",
    "# two fold cross-validation\n",
    "def two_fold_BR_test(data, label, dataPath, n_iter=5, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # 2-fold cross validatiom\n",
    "    KF=KFold(n_splits=2, shuffle=True, random_state=random_state)\n",
    "    i = 0\n",
    "    \n",
    "    performance = {}\n",
    "    for train_index,test_index in KF.split(data):\n",
    "        i += 1\n",
    "        \n",
    "        X_train,X_test=data.iloc[train_index,:],data.iloc[test_index,:]\n",
    "        y_train,y_test=label.iloc[train_index,:],label.iloc[test_index,:]\n",
    "        \n",
    "        print(\"--- kfold time=\"+str(i)+\" ---\")\n",
    "        # training\n",
    "        classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "        # testing\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "        \n",
    "        # evaluation\n",
    "        if performance == {}:\n",
    "            performance = evaluation(y_predict, y_prob, y_test)\n",
    "        else:\n",
    "            performance_i = evaluation(y_predict, y_prob, y_test)\n",
    "            for key, value in performance_i.items():\n",
    "                performance[key] = (performance[key] + value)/2\n",
    "            else:\n",
    "                performance[key] = value\n",
    "    \n",
    "    # print data information\n",
    "    print(\"\\n--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- 2 fold cross-validation Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            continue\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([305,  40, 469, 422, 166,  29, 537, 285,  57, 112,\n",
      "            ...\n",
      "            317,  27, 249, 551, 591,  36, 334, 480, 494, 511],\n",
      "           dtype='int64', length=297)\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.83 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.17\n",
      "hamming_loss = 0.24\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.65\n",
      "Jaccard_Index = 0.76\n",
      "zero_one_error = 0.76\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.66\n",
      "label_happy-pleased = 0.33\n",
      "label_relaxing-calm = 0.77\n",
      "label_quiet-still = 0.75\n",
      "label_sad-lonely = 0.56\n",
      "label_angry-aggresive = 0.69\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "BR_test(data, label, dataPath,3071980)\n",
    "\n",
    "#print(\"\")\n",
    "#print(\"------ two_fold Binary Relevance using Naive Bayes ------\")\n",
    "#two_fold_BR_test(data, label, dataPath,3071980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([  5,   7,   8,  15,  16,  17,  21,  23,  24,  31,\n",
      "            ...\n",
      "            569, 572, 573, 574, 575, 576, 580, 584, 587, 592],\n",
      "           dtype='int64', length=297)\n",
      "--- start training ---\n",
      "\n",
      "--- start testing ---\n",
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.76 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.17\n",
      "hamming_loss = 0.23\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.65\n",
      "Jaccard_Index = 0.77\n",
      "zero_one_error = 0.73\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.57\n",
      "label_happy-pleased = 0.38\n",
      "label_relaxing-calm = 0.75\n",
      "label_quiet-still = 0.76\n",
      "label_sad-lonely = 0.55\n",
      "label_angry-aggresive = 0.74\n"
     ]
    }
   ],
   "source": [
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# split training and test data set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# training\n",
    "print(\"--- start training ---\\n\")\n",
    "classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "# testing\n",
    "print(\"--- start testing ---\\n\")\n",
    "y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "\n",
    "# get confusion matrix\n",
    "get_confusion_matrix(y_predict, y_test, y_test.columns)\n",
    "    \n",
    "# evaluation\n",
    "performance = evaluation(y_predict, y_prob, y_test)\n",
    "\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR using ESKDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arff(word_occurrence, label_matrix, savePath): # get attributes\n",
    "    for z in range(len(label_matrix.columns)):\n",
    "        attributes=[(word_occurrence.columns[i],list(map(str,sorted(word_occurrence.iloc[:,i].unique())))) for i in range(len(word_occurrence.columns))]\n",
    "        attributes.append(('label_'+label_matrix.columns[z],['0', '1']))\n",
    "\n",
    "        data=[]\n",
    "        i = 0\n",
    "        while i < label_matrix.shape[0]:\n",
    "            attr_data = [str(j) for j in list(word_occurrence.iloc[i,:])]\n",
    "            label_data = [str(label_matrix.iloc[i,z])]\n",
    "            row_data = attr_data+label_data\n",
    "            data.append(row_data) \n",
    "            i+=1\n",
    "        # set obj\n",
    "        obj = {\n",
    "           'description': u'',\n",
    "           'relation': 'relation',\n",
    "           'attributes': attributes,\n",
    "           'data': data,\n",
    "        }\n",
    "        arff_data = arff.dumps(obj)\n",
    "        w_file = open(savePath+label_matrix.columns[z]+\".arff\", \"w\")\n",
    "        w_file.write(arff_data)\n",
    "        w_file.close()\n",
    "\n",
    "def run_eskdb(dataPath, resultFile, k, l, e, i):\n",
    "    command = \"./run_eskdb.sh \"+resultFile+\" \"+k+\" \"+i+\" \"+l+\" \"+e+\" \"+dataPath\n",
    "    subprocess.call(\"cd /Volumes/Samsung_T5/research/programme/research_python/\", shell=True)\n",
    "    print(command)\n",
    "    return subprocess.call(command, shell=True)\n",
    "\n",
    "def get_result(resultPath):\n",
    "\n",
    "    y_pred = pd.DataFrame()\n",
    "    y_true = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    names = []\n",
    "    for file in os.listdir(resultPath):\n",
    "        with open(os.path.join(resultPath,file), 'r') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(file)\n",
    "            else:\n",
    "                names.append(file[:-4])\n",
    "                pred = []\n",
    "                true = []\n",
    "                prob = []\n",
    "                train_time_total = 0\n",
    "                test_time_total = 0\n",
    "                error_marco = 0\n",
    "                for line in lines:\n",
    "                    if line.startswith('pred'):\n",
    "                        pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                        true.append(int(re.search('true :\\t(.)',line).group(1)))\n",
    "                        prob.append(float(re.search('prob :\\t(.*)',line).group(1)))\n",
    "                    elif line.startswith('RSME'):\n",
    "                        rsme = float(re.search('RSME :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith('Error'):\n",
    "                        error = float(re.search('Error :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith(\"Training time\"):\n",
    "                        train_time = float(re.search('Training time :\\s{1,}(.*)',line).group(1))\n",
    "                        train_time_total = train_time_total + train_time\n",
    "                    elif line.startswith(\"Testing time\"):\n",
    "                        test_time = float(re.search('Testing time :\\s{1,}(.*)',line).group(1))\n",
    "                        test_time_total = test_time_total + test_time\n",
    "                    elif line.startswith(\"[\"):\n",
    "                        para = line\n",
    "                    elif line.startswith(\"test0Indexes\"):\n",
    "                        index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "                y_pred = pd.concat([y_pred,pd.DataFrame(pred)],axis=1)\n",
    "                y_true = pd.concat([y_true,pd.DataFrame(true)],axis=1)\n",
    "                y_prob = pd.concat([y_prob,pd.DataFrame(prob)],axis=1)\n",
    "    y_pred.columns = names\n",
    "    y_true.columns = names\n",
    "    y_pred.index = index\n",
    "    y_true.index = index\n",
    "    print(para)\n",
    "    print(\"number of label:\", y_pred.shape[1])\n",
    "    print(\"training time:\",train_time_total)\n",
    "    print(\"testing time:\",test_time_total)\n",
    "    return y_pred,y_true,y_prob,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_eskdb.sh emotions_k5_e20_i5000 5 5000 2 20 /Users/jiangjunhao/Desktop/test/emotions/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# get arff files\n",
    "\n",
    "savePath = \"/Users/jiangjunhao/Desktop/test/\"+dataset+'/'\n",
    "os.mkdir(savePath)\n",
    "get_arff(data,label,savePath)\n",
    "\n",
    "resultFile = dataset+'_k5_e20_i5000'\n",
    "k = '5'\n",
    "i = '5000'\n",
    "l = '2'\n",
    "e = '20'\n",
    "\n",
    "run_eskdb(savePath, resultFile, k, l, e, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-t, /Users/jiangjunhao/Desktop/test/emotions//sad-lonely.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 550.0\n",
      "testing time: 240.0\n",
      "--- Performance ---\n",
      "coverage_error = 2.67 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.15\n",
      "hamming_loss = 0.19\n",
      "f1_macro = 0.64\n",
      "f1_micro = 0.67\n",
      "Jaccard_Index = 0.81\n",
      "zero_one_error = 0.69\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.64\n",
      "label_happy-pleased = 0.75\n",
      "label_relaxing-calm = 0.32\n",
      "label_quiet-still = 0.73\n",
      "label_sad-lonely = 0.78\n",
      "label_angry-aggresive = 0.6\n"
     ]
    }
   ],
   "source": [
    "resultPath = '/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result/'+resultFile\n",
    "y_pred,y_true,y_prob,index = get_result(resultPath)\n",
    "\n",
    "performance = evaluation(y_pred=y_pred, y_true=y_true, y_prob=y_prob)\n",
    "    \n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Chain\n",
    "\n",
    "## CC using naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    \n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "    \n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)] # create a classifier chain\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            classifier_list[i].fit(X_train,y_train.iloc[:, order[i]])\n",
    "        else:\n",
    "            X_train = pd.concat([X_train, y_train.iloc[:,order[i-1]]],axis=1) # put the previous label into attribute space\n",
    "            classifier_list[i].fit(X_train,y_train.iloc[:,order[i]])\n",
    "\n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time, order\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order):\n",
    "    y_predict = pd.DataFrame(index=X_test.index)\n",
    "    y_prob = pd.DataFrame(index=X_test.index)\n",
    "    y_true = pd.DataFrame(index=X_test.index)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index)],axis=1)\n",
    "\n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index)],axis=1)\n",
    "\n",
    "        X_test = pd.concat([X_test, pd.DataFrame(y_predict_i,index=X_test.index)],axis=1,ignore_index=True) # put the previous label into attribute space\n",
    "\n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def CC_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # training\n",
    "    print(\"--- start training ---\\n\")\n",
    "    classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    print(\"--- start testing ---\\n\")\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "    \n",
    "    # evaluation\n",
    "    y_test = y_test.iloc[:,order]\n",
    "    performance = evaluation(y_predict, y_prob, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print orders\n",
    "    print(\"\\n--- Order of the chain ---\")\n",
    "    print(label.columns[order])\n",
    "    print(\"\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))\n",
    "            \n",
    "def ECC_test(data, label, dataPath, random_state=3071980, ensemble = 5):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # ensemble\n",
    "    y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    for i in range(ensemble):\n",
    "        # training\n",
    "        #print(\"--- start training ---\\n\")\n",
    "        classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "        # print orders\n",
    "        print(\"Order of the chain:\",label.columns[order])\n",
    "\n",
    "        # testing\n",
    "        #print(\"--- start testing ---\\n\")\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "        y_predict.columns = label.columns[order]\n",
    "        y_prob.columns = label.columns[order]\n",
    "        y_predict = y_predict[label.columns]\n",
    "        y_prob = y_prob[label.columns]\n",
    "\n",
    "        y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "        y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "    y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "    y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "    # print data information\n",
    "    print(\"--- Data Information ---\")\n",
    "    print(\"dataset:\", dataPath)\n",
    "    print(\"number of label:\",n_label)\n",
    "    print(\"number of attribute:\",n_attr)\n",
    "    print(\"number of instance:\",n_instance,\"\\n\")\n",
    "    \n",
    "    # print orders\n",
    "    print(\"\\n--- Order of the chain ---\")\n",
    "    print(label.columns[order])\n",
    "    print(\"\")\n",
    "    \n",
    "    # print performance\n",
    "    print(\"--- Performance ---\")\n",
    "    for key, value in performance.items():\n",
    "        if key == \"f1_each_label\":\n",
    "            print(\"\\n- f1 for each label -\")\n",
    "            for i in range(n_label):\n",
    "                print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "        elif key == \"coverage_error\":\n",
    "            print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "        else:\n",
    "            print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'sad-lonely', 'quiet-still',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['happy-pleased', 'amazed-suprised', 'sad-lonely', 'quiet-still',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.84 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.17\n",
      "hamming_loss = 0.23\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.66\n",
      "Jaccard_Index = 0.77\n",
      "zero_one_error = 0.73\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.65\n",
      "label_happy-pleased = 0.33\n",
      "label_relaxing-calm = 0.78\n",
      "label_quiet-still = 0.76\n",
      "label_sad-lonely = 0.58\n",
      "label_angry-aggresive = 0.71\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "ECC_test(data, label, dataPath, 3071980, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([  5,   7,   8,  15,  16,  17,  21,  23,  24,  31,\n",
      "            ...\n",
      "            569, 572, 573, 574, 575, 576, 580, 584, 587, 592],\n",
      "           dtype='int64', length=297)\n",
      "--- start training ---\n",
      "\n",
      "--- start testing ---\n",
      "\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['amazed-suprised', 'happy-pleased', 'relaxing-calm', 'sad-lonely',\n",
      "       'angry-aggresive', 'quiet-still'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.73 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.17\n",
      "hamming_loss = 0.23\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.66\n",
      "Jaccard_Index = 0.77\n",
      "zero_one_error = 0.72\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.57\n",
      "label_happy-pleased = 0.38\n",
      "label_relaxing-calm = 0.77\n",
      "label_quiet-still = 0.59\n",
      "label_sad-lonely = 0.75\n",
      "label_angry-aggresive = 0.74\n"
     ]
    }
   ],
   "source": [
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# split training and test data set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# training\n",
    "print(\"--- start training ---\\n\")\n",
    "classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "# testing\n",
    "print(\"--- start testing ---\\n\")\n",
    "y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "# evaluation\n",
    "y_test = y_test.iloc[:,order]\n",
    "performance = evaluation(y_predict, y_prob, y_test)\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print orders\n",
    "print(\"\\n--- Order of the chain ---\")\n",
    "print(label.columns[order])\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble CC using naive Bayes (E = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "Order of the chain: Index(['relaxing-calm', 'quiet-still', 'amazed-suprised', 'sad-lonely',\n",
      "       'angry-aggresive', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'quiet-still', 'happy-pleased', 'angry-aggresive',\n",
      "       'relaxing-calm', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'sad-lonely', 'relaxing-calm',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'angry-aggresive', 'relaxing-calm', 'sad-lonely',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'sad-lonely', 'relaxing-calm',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'sad-lonely', 'happy-pleased', 'relaxing-calm',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'relaxing-calm', 'amazed-suprised', 'angry-aggresive',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'relaxing-calm', 'sad-lonely', 'angry-aggresive',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'sad-lonely', 'relaxing-calm',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'amazed-suprised', 'sad-lonely', 'angry-aggresive',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['relaxing-calm', 'amazed-suprised', 'sad-lonely', 'angry-aggresive',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.88 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.18\n",
      "hamming_loss = 0.25\n",
      "f1_macro = 0.6\n",
      "f1_micro = 0.64\n",
      "Jaccard_Index = 0.75\n",
      "zero_one_error = 0.73\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.63\n",
      "label_happy-pleased = 0.19\n",
      "label_relaxing-calm = 0.78\n",
      "label_quiet-still = 0.73\n",
      "label_sad-lonely = 0.55\n",
      "label_angry-aggresive = 0.7\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "ECC_test(data, label, dataPath, random_state=3071980, ensemble=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([  5,   7,   8,  15,  16,  17,  21,  23,  24,  31,\n",
      "            ...\n",
      "            569, 572, 573, 574, 575, 576, 580, 584, 587, 592],\n",
      "           dtype='int64', length=297)\n",
      "Order of the chain: Index(['relaxing-calm', 'amazed-suprised', 'quiet-still', 'angry-aggresive',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'sad-lonely', 'angry-aggresive', 'relaxing-calm',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'relaxing-calm', 'amazed-suprised', 'angry-aggresive',\n",
      "       'quiet-still', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'quiet-still', 'angry-aggresive', 'sad-lonely',\n",
      "       'amazed-suprised', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'amazed-suprised', 'quiet-still', 'angry-aggresive',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'relaxing-calm', 'amazed-suprised', 'happy-pleased',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'sad-lonely', 'relaxing-calm',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'angry-aggresive', 'happy-pleased', 'sad-lonely',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'angry-aggresive', 'happy-pleased', 'amazed-suprised',\n",
      "       'quiet-still', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'relaxing-calm', 'happy-pleased', 'sad-lonely',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['angry-aggresive', 'relaxing-calm', 'happy-pleased', 'sad-lonely',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.78 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.17\n",
      "hamming_loss = 0.24\n",
      "f1_macro = 0.63\n",
      "f1_micro = 0.65\n",
      "Jaccard_Index = 0.76\n",
      "zero_one_error = 0.73\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.56\n",
      "label_happy-pleased = 0.4\n",
      "label_relaxing-calm = 0.76\n",
      "label_quiet-still = 0.74\n",
      "label_sad-lonely = 0.57\n",
      "label_angry-aggresive = 0.75\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "ensemble=10\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# ensemble\n",
    "y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "for i in range(ensemble):\n",
    "    # training\n",
    "    #print(\"--- start training ---\\n\")\n",
    "    classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "    # print orders\n",
    "    print(\"Order of the chain:\",label.columns[order])\n",
    "\n",
    "    # testing\n",
    "    #print(\"--- start testing ---\\n\")\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "    y_predict.columns = label.columns[order]\n",
    "    y_prob.columns = label.columns[order]\n",
    "    y_predict = y_predict[label.columns]\n",
    "    y_prob = y_prob[label.columns]\n",
    "\n",
    "    y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "\n",
    "# evaluation\n",
    "performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print orders\n",
    "print(\"\\n--- Order of the chain ---\")\n",
    "print(label.columns[order])\n",
    "print(\"\")\n",
    "\n",
    "# get confusion matrix\n",
    "get_confusion_matrix(y_pred_ensemble, y_test, y_test.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble CC using naive Bayes (E = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Binary Relevance using Naive Bayes ------\n",
      "Order of the chain: Index(['happy-pleased', 'sad-lonely', 'relaxing-calm', 'quiet-still',\n",
      "       'amazed-suprised', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'relaxing-calm', 'sad-lonely', 'angry-aggresive',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'amazed-suprised', 'relaxing-calm', 'angry-aggresive',\n",
      "       'happy-pleased', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'happy-pleased', 'quiet-still',\n",
      "       'relaxing-calm', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'relaxing-calm', 'angry-aggresive', 'amazed-suprised',\n",
      "       'happy-pleased', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'amazed-suprised', 'angry-aggresive', 'sad-lonely',\n",
      "       'relaxing-calm', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'sad-lonely', 'relaxing-calm', 'angry-aggresive',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'relaxing-calm', 'angry-aggresive',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'amazed-suprised', 'sad-lonely',\n",
      "       'quiet-still', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'sad-lonely', 'amazed-suprised', 'happy-pleased',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'quiet-still', 'angry-aggresive',\n",
      "       'relaxing-calm', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'happy-pleased', 'quiet-still',\n",
      "       'relaxing-calm', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'happy-pleased', 'angry-aggresive', 'quiet-still',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'happy-pleased', 'sad-lonely',\n",
      "       'relaxing-calm', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'relaxing-calm', 'quiet-still', 'happy-pleased',\n",
      "       'sad-lonely', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'relaxing-calm', 'quiet-still',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'happy-pleased', 'angry-aggresive', 'amazed-suprised',\n",
      "       'quiet-still', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'sad-lonely', 'happy-pleased', 'angry-aggresive',\n",
      "       'relaxing-calm', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'sad-lonely', 'quiet-still', 'amazed-suprised',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'relaxing-calm', 'amazed-suprised', 'sad-lonely',\n",
      "       'angry-aggresive', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'amazed-suprised', 'happy-pleased', 'angry-aggresive',\n",
      "       'relaxing-calm', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'amazed-suprised', 'sad-lonely',\n",
      "       'quiet-still', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'relaxing-calm', 'happy-pleased', 'amazed-suprised',\n",
      "       'quiet-still', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'quiet-still', 'amazed-suprised', 'happy-pleased',\n",
      "       'angry-aggresive', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'quiet-still', 'amazed-suprised', 'sad-lonely',\n",
      "       'angry-aggresive', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'sad-lonely', 'relaxing-calm', 'angry-aggresive',\n",
      "       'happy-pleased', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'amazed-suprised', 'relaxing-calm', 'happy-pleased',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'relaxing-calm', 'sad-lonely',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'relaxing-calm', 'angry-aggresive', 'sad-lonely',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'sad-lonely', 'happy-pleased',\n",
      "       'angry-aggresive', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'quiet-still', 'happy-pleased', 'angry-aggresive',\n",
      "       'relaxing-calm', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'happy-pleased', 'sad-lonely',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'sad-lonely', 'quiet-still', 'happy-pleased',\n",
      "       'relaxing-calm', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'relaxing-calm', 'quiet-still', 'happy-pleased',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'sad-lonely', 'happy-pleased',\n",
      "       'relaxing-calm', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'quiet-still', 'sad-lonely', 'amazed-suprised',\n",
      "       'relaxing-calm', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'sad-lonely', 'relaxing-calm',\n",
      "       'angry-aggresive', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'quiet-still', 'sad-lonely', 'amazed-suprised',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'relaxing-calm', 'sad-lonely', 'amazed-suprised',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'relaxing-calm', 'angry-aggresive',\n",
      "       'sad-lonely', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'relaxing-calm', 'amazed-suprised', 'angry-aggresive',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'sad-lonely', 'amazed-suprised',\n",
      "       'quiet-still', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'quiet-still', 'relaxing-calm', 'sad-lonely',\n",
      "       'angry-aggresive', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'happy-pleased', 'quiet-still', 'relaxing-calm',\n",
      "       'sad-lonely', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'angry-aggresive', 'relaxing-calm', 'happy-pleased',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'amazed-suprised', 'sad-lonely', 'relaxing-calm',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'quiet-still', 'angry-aggresive', 'sad-lonely',\n",
      "       'amazed-suprised', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'happy-pleased', 'amazed-suprised', 'relaxing-calm',\n",
      "       'sad-lonely', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'relaxing-calm', 'happy-pleased',\n",
      "       'sad-lonely', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'amazed-suprised', 'quiet-still', 'angry-aggresive',\n",
      "       'relaxing-calm', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['sad-lonely', 'amazed-suprised', 'quiet-still', 'angry-aggresive',\n",
      "       'relaxing-calm', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.86 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.18\n",
      "hamming_loss = 0.24\n",
      "f1_macro = 0.64\n",
      "f1_micro = 0.66\n",
      "Jaccard_Index = 0.76\n",
      "zero_one_error = 0.75\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.65\n",
      "label_happy-pleased = 0.38\n",
      "label_relaxing-calm = 0.78\n",
      "label_quiet-still = 0.73\n",
      "label_sad-lonely = 0.56\n",
      "label_angry-aggresive = 0.7\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "# train - test\n",
    "print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "ECC_test(data, label, dataPath, random_state=3071980, ensemble=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test index --\n",
      "Int64Index([  5,   7,   8,  15,  16,  17,  21,  23,  24,  31,\n",
      "            ...\n",
      "            569, 572, 573, 574, 575, 576, 580, 584, 587, 592],\n",
      "           dtype='int64', length=297)\n",
      "Order of the chain: Index(['quiet-still', 'sad-lonely', 'relaxing-calm', 'happy-pleased',\n",
      "       'angry-aggresive', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'sad-lonely', 'relaxing-calm', 'happy-pleased',\n",
      "       'angry-aggresive', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'amazed-suprised', 'happy-pleased', 'angry-aggresive',\n",
      "       'quiet-still', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'angry-aggresive', 'relaxing-calm', 'amazed-suprised',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'amazed-suprised', 'relaxing-calm', 'sad-lonely',\n",
      "       'happy-pleased', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'angry-aggresive', 'sad-lonely', 'relaxing-calm',\n",
      "       'amazed-suprised', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'quiet-still', 'sad-lonely',\n",
      "       'amazed-suprised', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'quiet-still', 'relaxing-calm', 'happy-pleased',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'quiet-still', 'sad-lonely', 'relaxing-calm',\n",
      "       'angry-aggresive', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'amazed-suprised', 'sad-lonely', 'relaxing-calm',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'sad-lonely', 'relaxing-calm', 'amazed-suprised',\n",
      "       'happy-pleased', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'relaxing-calm', 'angry-aggresive',\n",
      "       'happy-pleased', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'sad-lonely', 'quiet-still', 'happy-pleased',\n",
      "       'angry-aggresive', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'relaxing-calm', 'angry-aggresive',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'relaxing-calm', 'sad-lonely',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'relaxing-calm', 'angry-aggresive', 'happy-pleased',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'happy-pleased', 'quiet-still', 'relaxing-calm',\n",
      "       'amazed-suprised', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'sad-lonely', 'happy-pleased', 'relaxing-calm',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'angry-aggresive', 'sad-lonely',\n",
      "       'happy-pleased', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'happy-pleased', 'relaxing-calm', 'quiet-still',\n",
      "       'angry-aggresive', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'sad-lonely', 'quiet-still', 'angry-aggresive',\n",
      "       'amazed-suprised', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'happy-pleased', 'sad-lonely', 'amazed-suprised',\n",
      "       'relaxing-calm', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['happy-pleased', 'quiet-still', 'angry-aggresive', 'relaxing-calm',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'angry-aggresive', 'happy-pleased', 'amazed-suprised',\n",
      "       'sad-lonely', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'happy-pleased', 'angry-aggresive', 'quiet-still',\n",
      "       'amazed-suprised', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'angry-aggresive', 'quiet-still', 'amazed-suprised',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'angry-aggresive', 'relaxing-calm', 'happy-pleased',\n",
      "       'quiet-still', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'relaxing-calm', 'happy-pleased', 'sad-lonely',\n",
      "       'angry-aggresive', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'quiet-still', 'happy-pleased', 'relaxing-calm',\n",
      "       'amazed-suprised', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'quiet-still', 'sad-lonely', 'angry-aggresive',\n",
      "       'happy-pleased', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'relaxing-calm', 'angry-aggresive', 'sad-lonely',\n",
      "       'happy-pleased', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'sad-lonely', 'happy-pleased', 'amazed-suprised',\n",
      "       'quiet-still', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'sad-lonely', 'happy-pleased', 'amazed-suprised',\n",
      "       'quiet-still', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'angry-aggresive', 'sad-lonely', 'relaxing-calm',\n",
      "       'happy-pleased', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'sad-lonely', 'amazed-suprised', 'angry-aggresive',\n",
      "       'quiet-still', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'relaxing-calm', 'angry-aggresive', 'happy-pleased',\n",
      "       'amazed-suprised', 'sad-lonely'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'amazed-suprised', 'sad-lonely', 'angry-aggresive',\n",
      "       'happy-pleased', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['quiet-still', 'angry-aggresive', 'amazed-suprised', 'relaxing-calm',\n",
      "       'sad-lonely', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'amazed-suprised', 'angry-aggresive', 'quiet-still',\n",
      "       'relaxing-calm', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'amazed-suprised', 'happy-pleased', 'quiet-still',\n",
      "       'angry-aggresive', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['angry-aggresive', 'happy-pleased', 'quiet-still', 'sad-lonely',\n",
      "       'relaxing-calm', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'angry-aggresive', 'relaxing-calm', 'quiet-still',\n",
      "       'happy-pleased', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'angry-aggresive', 'happy-pleased', 'relaxing-calm',\n",
      "       'amazed-suprised', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['sad-lonely', 'angry-aggresive', 'amazed-suprised', 'quiet-still',\n",
      "       'relaxing-calm', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'sad-lonely', 'happy-pleased', 'angry-aggresive',\n",
      "       'quiet-still', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['relaxing-calm', 'sad-lonely', 'happy-pleased', 'amazed-suprised',\n",
      "       'angry-aggresive', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'happy-pleased', 'sad-lonely', 'quiet-still',\n",
      "       'angry-aggresive', 'relaxing-calm'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'relaxing-calm', 'happy-pleased', 'sad-lonely',\n",
      "       'angry-aggresive', 'quiet-still'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'quiet-still', 'relaxing-calm', 'sad-lonely',\n",
      "       'happy-pleased', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "Order of the chain: Index(['amazed-suprised', 'sad-lonely', 'quiet-still', 'relaxing-calm',\n",
      "       'angry-aggresive', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "--- Data Information ---\n",
      "dataset: /Volumes/Samsung_T5/research/data/small_datasets/emotions/\n",
      "number of label: 6\n",
      "number of attribute: 72\n",
      "number of instance: 593 \n",
      "\n",
      "\n",
      "--- Order of the chain ---\n",
      "Index(['amazed-suprised', 'sad-lonely', 'quiet-still', 'relaxing-calm',\n",
      "       'angry-aggresive', 'happy-pleased'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Performance ---\n",
      "coverage_error = 2.79 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.18\n",
      "hamming_loss = 0.24\n",
      "f1_macro = 0.61\n",
      "f1_micro = 0.64\n",
      "Jaccard_Index = 0.76\n",
      "zero_one_error = 0.73\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.56\n",
      "label_happy-pleased = 0.29\n",
      "label_relaxing-calm = 0.76\n",
      "label_quiet-still = 0.74\n",
      "label_sad-lonely = 0.55\n",
      "label_angry-aggresive = 0.75\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "\n",
    "ensemble=50\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "X_train = data[data.index.isin(index)==False]\n",
    "X_test = data[data.index.isin(index)==True]\n",
    "y_train = label[label.index.isin(index)==False]\n",
    "y_test = label[label.index.isin(index)==True]\n",
    "\n",
    "print(\"-- test index --\")\n",
    "print(X_test.index)\n",
    "\n",
    "# ensemble\n",
    "y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "for i in range(ensemble):\n",
    "    # training\n",
    "    #print(\"--- start training ---\\n\")\n",
    "    classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "    # print orders\n",
    "    print(\"Order of the chain:\",label.columns[order])\n",
    "\n",
    "    # testing\n",
    "    #print(\"--- start testing ---\\n\")\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "    y_predict.columns = label.columns[order]\n",
    "    y_prob.columns = label.columns[order]\n",
    "    y_predict = y_predict[label.columns]\n",
    "    y_prob = y_prob[label.columns]\n",
    "\n",
    "    y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "\n",
    "# evaluation\n",
    "performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "\n",
    "\n",
    "# print data information\n",
    "print(\"--- Data Information ---\")\n",
    "print(\"dataset:\", dataPath)\n",
    "print(\"number of label:\",n_label)\n",
    "print(\"number of attribute:\",n_attr)\n",
    "print(\"number of instance:\",n_instance,\"\\n\")\n",
    "\n",
    "# print orders\n",
    "print(\"\\n--- Order of the chain ---\")\n",
    "print(label.columns[order])\n",
    "print(\"\")\n",
    "\n",
    "# get confusion matrix\n",
    "get_confusion_matrix(y_pred_ensemble, y_test, y_test.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CC using ESKDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "def csv_to_arff(X, label_i, savePath):\n",
    "    # get attributes\n",
    "    attributes=[(X.columns[i],['0', '1']) for i in range(len(X.columns))]\n",
    "    attributes.append(('label_'+label_i.name,['0', '1']))\n",
    "\n",
    "    data=[]\n",
    "    i = 0\n",
    "    while i < len(label_i):\n",
    "        attr_data = [str(j) for j in list(X.iloc[i,:])]\n",
    "        label_data = [str(label_i[i])]\n",
    "        row_data = attr_data+label_data\n",
    "        data.append(row_data) \n",
    "        i+=1\n",
    "    # set obj\n",
    "    obj = {\n",
    "       'description': u'',\n",
    "       'relation': 'relation',\n",
    "       'attributes': attributes,\n",
    "       'data': data,\n",
    "    }\n",
    "    arff_data = arff.dumps(obj)\n",
    "    w_file = open(savePath+label_i.name+\".arff\", \"w\")\n",
    "    w_file.write(arff_data)\n",
    "    w_file.close()\n",
    "\n",
    "def get_arff(X, label, savePath):\n",
    "    \n",
    "    n_label = label.shape[1]\n",
    "    # get orders\n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "    \n",
    "    #  get all arff files, one for each label\n",
    "    for i in range(n_label):\n",
    "        label_i = label.iloc[:,order[i]]\n",
    "        print(\"--Running label:\",label_i.name)\n",
    "        csv_to_arff(X, label_i, savePath)\n",
    "        \n",
    "        label_i.name = 'label_' + label_i.name\n",
    "        X = pd.concat([X, label_i], axis=1)\n",
    "    print(\"--finished getting arff files\")\n",
    "    return order\n",
    "\n",
    "def run_eskdb(label_arff, resultFile, k, l, e, i):\n",
    "    command = \"./run_ECC.sh \"+resultFile+\" \"+k+\" \"+i+\" \"+l+\" \"+e+\" \"+label_arff\n",
    "    subprocess.call(\"cd /Volumes/Samsung_T5/research/programme/research_python/\", shell=True)\n",
    "    #print(command)\n",
    "    return subprocess.call(command, shell=True)\n",
    "\n",
    "def get_result(resultPath):\n",
    "\n",
    "    y_pred = pd.DataFrame()\n",
    "    y_true = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    names = []\n",
    "    for file in os.listdir(resultPath):\n",
    "        with open(os.path.join(resultPath,file), 'r') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(file)\n",
    "            else:\n",
    "                names.append(file[:-4])\n",
    "                pred = []\n",
    "                true = []\n",
    "                prob = []\n",
    "                train_time_total = 0\n",
    "                test_time_total = 0\n",
    "                error_marco = 0\n",
    "                for line in lines:\n",
    "                    if line.startswith('pred'):\n",
    "                        pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                        true.append(int(re.search('true :\\t(.)',line).group(1)))\n",
    "                        prob.append(float(re.search('prob :\\t(.*)',line).group(1)))\n",
    "                    elif line.startswith('RSME'):\n",
    "                        rsme = float(re.search('RSME :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith('Error'):\n",
    "                        error = float(re.search('Error :\\t\\t(.*)',line).group(1))\n",
    "                    elif line.startswith(\"Training time\"):\n",
    "                        train_time = float(re.search('Training time :\\s{1,}(.*)',line).group(1))\n",
    "                        train_time_total = train_time_total + train_time\n",
    "                    elif line.startswith(\"Testing time\"):\n",
    "                        test_time = float(re.search('Testing time :\\s{1,}(.*)',line).group(1))\n",
    "                        test_time_total = test_time_total + test_time\n",
    "                    elif line.startswith(\"[\"):\n",
    "                        para = line\n",
    "                    elif line.startswith(\"test0Indexes\"):\n",
    "                        index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "                y_pred = pd.concat([y_pred,pd.DataFrame(pred)],axis=1)\n",
    "                y_true = pd.concat([y_true,pd.DataFrame(true)],axis=1)\n",
    "                y_prob = pd.concat([y_prob,pd.DataFrame(prob)],axis=1)\n",
    "    y_pred.columns = names\n",
    "    y_true.columns = names\n",
    "    y_prob.columns = names\n",
    "    print(para)\n",
    "    print(\"number of label:\", y_pred.shape[1])\n",
    "    print(\"training time:\",train_time_total)\n",
    "    print(\"testing time:\",test_time_total)\n",
    "    return y_pred,y_true,y_prob,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 459.0\n",
      "testing time: 298.0\n",
      "Index(['amazed-suprised', 'relaxing-calm', 'quiet-still', 'sad-lonely',\n",
      "       'happy-pleased', 'angry-aggresive'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Confusion matrix ---\n",
      "--- Performance ---\n",
      "coverage_error = 2.67 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.15\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.68\n",
      "f1_micro = 0.69\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.66\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.65\n",
      "label_happy-pleased = 0.78\n",
      "label_relaxing-calm = 0.77\n",
      "label_quiet-still = 0.6\n",
      "label_sad-lonely = 0.51\n",
      "label_angry-aggresive = 0.77\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "n_label = label.shape[1]\n",
    "\n",
    "resultFile = dataset+'_k5_e20_i5000_CC'\n",
    "\n",
    "# train and test on the first label\n",
    "savePath = \"/Users/jiangjunhao/Desktop/test/\"+dataset+'/'\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# get orders\n",
    "order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "\n",
    "\n",
    "## prepare data, get the arff file\n",
    "for i in range(n_label):\n",
    "    label_i = label.iloc[:,order[i]]\n",
    "    #print(\"--Running label:\",label_i.name)\n",
    "    csv_to_arff(data, label_i, savePath)\n",
    "\n",
    "    # run eskdb\n",
    "    label_arff = os.path.join(savePath,label_i.name+'.arff')\n",
    "    k = '5'\n",
    "    i = '5000'\n",
    "    l = '2'\n",
    "    e = '20'\n",
    "\n",
    "    run_eskdb(label_arff, resultFile, k, l, e, i)\n",
    "\n",
    "    result = os.path.join(\"/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result\",resultFile, label_i.name+'.txt')\n",
    "    with open(result, 'r') as f:\n",
    "        try:\n",
    "            lines = f.readlines()\n",
    "        except:\n",
    "            print(file)\n",
    "        else:\n",
    "            pred = []\n",
    "            for line in lines:\n",
    "                if line.startswith('pred'):\n",
    "                    pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                elif line.startswith(\"test0Indexes\"):\n",
    "                    index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "            label.loc[index,label_i.name] = pred\n",
    "            temp = label.loc[:,label_i.name]\n",
    "            temp.name = 'label_'+label_i.name\n",
    "            data = pd.concat([data, label.loc[:,label_i.name]],axis=1)\n",
    "\n",
    "# get result\n",
    "resultPath = '/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result/'+resultFile+'/'\n",
    "y_pred,y_true,y_prob,index = get_result(resultPath)\n",
    "performance = evaluation(y_pred=y_pred, y_true=y_true, y_prob=y_prob)\n",
    "\n",
    "# print orders:\n",
    "print(label.columns[order])\n",
    "\n",
    "# get confusion matrix\n",
    "print(\"\\n--- Confusion matrix ---\")\n",
    "get_confusion_matrix(y_pred, y_true, y_pred.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble CC using ESKDB(E=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Running label: happy-pleased\n",
      "--Running label: sad-lonely\n",
      "--Running label: relaxing-calm\n",
      "--Running label: amazed-suprised\n",
      "--Running label: quiet-still\n",
      "--Running label: angry-aggresive\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 450.0\n",
      "testing time: 234.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.849749       0.007767     0.002300    0.011501       0.310735   \n",
      "293         0.102385       0.852809     0.530466    0.411915       0.143949   \n",
      "294         0.175936       0.392429     0.011528    0.109340       0.421825   \n",
      "295         0.814646       0.039006     0.011906    0.218215       0.338874   \n",
      "296         0.137750       0.905489     0.102268    0.002421       0.609740   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.961474  \n",
      "293         0.000992  \n",
      "294         0.645188  \n",
      "295         0.824088  \n",
      "296         0.000266  \n",
      "--Running label: quiet-still\n",
      "--Running label: relaxing-calm\n",
      "--Running label: sad-lonely\n",
      "--Running label: happy-pleased\n",
      "--Running label: angry-aggresive\n",
      "--Running label: amazed-suprised\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 451.0\n",
      "testing time: 288.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.912418       0.009126     0.000287    0.004851       0.209996   \n",
      "293         0.096231       0.836070     0.486576    0.163239       0.305744   \n",
      "294         0.100986       0.522207     0.044132    0.075154       0.695436   \n",
      "295         0.730193       0.084870     0.006485    0.145819       0.435514   \n",
      "296         0.218768       0.890891     0.181328    0.009932       0.849257   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.962391  \n",
      "293         0.027196  \n",
      "294         0.032877  \n",
      "295         0.880627  \n",
      "296         0.000562  \n",
      "--Running label: happy-pleased\n",
      "--Running label: angry-aggresive\n",
      "--Running label: sad-lonely\n",
      "--Running label: relaxing-calm\n",
      "--Running label: amazed-suprised\n",
      "--Running label: quiet-still\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 398.0\n",
      "testing time: 178.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.803326       0.000973     0.000017    0.026562       0.231458   \n",
      "293         0.101667       0.794532     0.622328    0.423384       0.123570   \n",
      "294         0.350717       0.133127     0.004040    0.090794       0.424837   \n",
      "295         0.767644       0.043587     0.000529    0.075666       0.475030   \n",
      "296         0.155406       0.929421     0.022781    0.003659       0.631205   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.902742  \n",
      "293         0.064343  \n",
      "294         0.638554  \n",
      "295         0.776515  \n",
      "296         0.004820  \n",
      "--Running label: quiet-still\n",
      "--Running label: sad-lonely\n",
      "--Running label: amazed-suprised\n",
      "--Running label: happy-pleased\n",
      "--Running label: angry-aggresive\n",
      "--Running label: relaxing-calm\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 481.0\n",
      "testing time: 256.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.877716   2.818216e-07     0.009620    0.023149       0.290666   \n",
      "293         0.273100   9.612074e-01     0.467856    0.112261       0.228122   \n",
      "294         0.181283   8.519376e-01     0.060213    0.095853       0.606343   \n",
      "295         0.850422   2.194780e-03     0.006769    0.150896       0.453236   \n",
      "296         0.311561   9.935954e-01     0.258705    0.035716       0.783777   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.956053  \n",
      "293         0.051296  \n",
      "294         0.131130  \n",
      "295         0.825849  \n",
      "296         0.000675  \n",
      "--Running label: quiet-still\n",
      "--Running label: relaxing-calm\n",
      "--Running label: happy-pleased\n",
      "--Running label: angry-aggresive\n",
      "--Running label: amazed-suprised\n",
      "--Running label: sad-lonely\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 415.0\n",
      "testing time: 224.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.927876       0.003049     0.011887    0.019532       0.252175   \n",
      "293         0.058140       0.850046     0.519260    0.620431       0.028146   \n",
      "294         0.057093       0.558460     0.016831    0.007972       0.506532   \n",
      "295         0.752171       0.021529     0.007011    0.113076       0.300529   \n",
      "296         0.137664       0.956524     0.254001    0.001852       0.728926   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.942683  \n",
      "293         0.001178  \n",
      "294         0.012829  \n",
      "295         0.861719  \n",
      "296         0.000579  \n",
      "--Running label: sad-lonely\n",
      "--Running label: amazed-suprised\n",
      "--Running label: relaxing-calm\n",
      "--Running label: happy-pleased\n",
      "--Running label: angry-aggresive\n",
      "--Running label: quiet-still\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 432.0\n",
      "testing time: 233.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.819336       0.000045     0.000512    0.003836       0.224646   \n",
      "293         0.260719       0.914791     0.462832    0.304826       0.249699   \n",
      "294         0.250557       0.704507     0.065440    0.039430       0.496751   \n",
      "295         0.785647       0.006481     0.001907    0.084901       0.413577   \n",
      "296         0.252342       0.956164     0.066383    0.061241       0.703690   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.941804  \n",
      "293         0.005122  \n",
      "294         0.205654  \n",
      "295         0.919923  \n",
      "296         0.000136  \n",
      "--Running label: angry-aggresive\n",
      "--Running label: quiet-still\n",
      "--Running label: happy-pleased\n",
      "--Running label: sad-lonely\n",
      "--Running label: amazed-suprised\n",
      "--Running label: relaxing-calm\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 384.0\n",
      "testing time: 131.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.892853       0.000225     0.002136    0.061125       0.084296   \n",
      "293         0.044570       0.860938     0.716470    0.659703       0.036500   \n",
      "294         0.250905       0.699088     0.041643    0.016164       0.623928   \n",
      "295         0.802880       0.002318     0.000059    0.137151       0.152987   \n",
      "296         0.238955       0.959295     0.146898    0.002747       0.718731   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.900495  \n",
      "293         0.023355  \n",
      "294         0.329465  \n",
      "295         0.687808  \n",
      "296         0.014688  \n",
      "--Running label: angry-aggresive\n",
      "--Running label: sad-lonely\n",
      "--Running label: quiet-still\n",
      "--Running label: relaxing-calm\n",
      "--Running label: happy-pleased\n",
      "--Running label: amazed-suprised\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 404.0\n",
      "testing time: 189.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.916442       0.001210     0.000153    0.007193       0.139046   \n",
      "293         0.193940       0.874606     0.480504    0.295547       0.491151   \n",
      "294         0.101109       0.629728     0.034255    0.047977       0.671993   \n",
      "295         0.679502       0.036158     0.000539    0.022680       0.137499   \n",
      "296         0.175587       0.958073     0.160925    0.052027       0.780086   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.865839  \n",
      "293         0.038823  \n",
      "294         0.314966  \n",
      "295         0.668454  \n",
      "296         0.008385  \n",
      "--Running label: sad-lonely\n",
      "--Running label: relaxing-calm\n",
      "--Running label: angry-aggresive\n",
      "--Running label: quiet-still\n",
      "--Running label: amazed-suprised\n",
      "--Running label: happy-pleased\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 429.0\n",
      "testing time: 197.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.776380       0.002213     0.000331    0.016141       0.111374   \n",
      "293         0.118958       0.792799     0.473387    0.322065       0.500362   \n",
      "294         0.251609       0.499508     0.014550    0.049518       0.159449   \n",
      "295         0.787189       0.129054     0.003867    0.218317       0.190618   \n",
      "296         0.156807       0.908075     0.141553    0.062288       0.830057   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.840521  \n",
      "293         0.005139  \n",
      "294         0.662416  \n",
      "295         0.663164  \n",
      "296         0.001155  \n",
      "--Running label: quiet-still\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Running label: angry-aggresive\n",
      "--Running label: happy-pleased\n",
      "--Running label: relaxing-calm\n",
      "--Running label: sad-lonely\n",
      "--Running label: amazed-suprised\n",
      "._amazed-suprised.txt\n",
      "[-t, /Users/jiangjunhao/Desktop/test/emotions/angry-aggresive.arff, -S, ESKDB, -K, 5, -I, 5000, -L, 2, -E, 20, -V, -M]\n",
      "\n",
      "number of label: 6\n",
      "training time: 414.0\n",
      "testing time: 184.0\n",
      "     amazed-suprised  relaxing-calm  quiet-still  sad-lonely  happy-pleased  \\\n",
      "292         0.898242       0.004310     0.003277    0.029145       0.106669   \n",
      "293         0.015948       0.819179     0.542008    0.653643       0.023763   \n",
      "294         0.071542       0.755985     0.042273    0.006769       0.616787   \n",
      "295         0.758356       0.016345     0.015221    0.075903       0.152291   \n",
      "296         0.197321       0.973736     0.142737    0.001967       0.800303   \n",
      "\n",
      "     angry-aggresive  \n",
      "292         0.823596  \n",
      "293         0.011193  \n",
      "294         0.374005  \n",
      "295         0.728147  \n",
      "296         0.012914  \n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data, label = read_data(dataPath)\n",
    "n_label = label.shape[1]\n",
    "\n",
    "# data set information\n",
    "n_label = label.shape[1]\n",
    "n_attr = data.shape[1]\n",
    "n_instance = data.shape[0]\n",
    "avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "# ensemble\n",
    "ensemble = 10\n",
    "\n",
    "y_pred_ensemble = pd.DataFrame(np.zeros((int(label.shape[0]/2+1),label.shape[1])),columns=label.columns)\n",
    "y_prob_ensemble = pd.DataFrame(np.zeros((int(label.shape[0]/2+1),label.shape[1])),columns=label.columns)\n",
    "    \n",
    "    \n",
    "for i in range(ensemble):\n",
    "\n",
    "    # read data\n",
    "    data, label = read_data(dataPath)\n",
    "    n_label = label.shape[1]\n",
    "\n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "\n",
    "    # get orders\n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "\n",
    "    # train and test on the first label\n",
    "    savePath = \"/Users/jiangjunhao/Desktop/test/\"+dataset+'/'\n",
    "\n",
    "    ## prepare data, get the arff file\n",
    "    for i in range(n_label):\n",
    "        label_i = label.iloc[:,order[i]]\n",
    "        print(\"--Running label:\",label_i.name)\n",
    "        csv_to_arff(data, label_i, savePath)\n",
    "\n",
    "        # run eskdb\n",
    "        label_arff = os.path.join(savePath,label_i.name+'.arff')\n",
    "        k = '5'\n",
    "        i = '5000'\n",
    "        l = '2'\n",
    "        e = '20'\n",
    "\n",
    "        run_eskdb(label_arff, resultFile, k, l, e, i)\n",
    "\n",
    "        result = os.path.join(\"/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result\",resultFile, label_i.name+'.txt')\n",
    "        with open(result, 'r') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(file)\n",
    "            else:\n",
    "                pred = []\n",
    "                for line in lines:\n",
    "                    if line.startswith('pred'):\n",
    "                        pred.append(int(re.search('pred :\\t(.)',line).group(1)))\n",
    "                    elif line.startswith(\"test0Indexes\"):\n",
    "                        index = list(map(int,re.search('test0Indexes: {(.*)}',line).group(1).split(', ')))\n",
    "\n",
    "                label.loc[index,label_i.name] = pred\n",
    "                temp = label.loc[:,label_i.name]\n",
    "                temp.name = 'label_'+label_i.name\n",
    "                data = pd.concat([data, label.loc[:,label_i.name]],axis=1)\n",
    "\n",
    "    # get result\n",
    "    resultPath = '/Volumes/Samsung_T5/research/programme/ESKDB_HDP/result/'+resultFile+'/'\n",
    "    y_pred,y_true,y_prob,index = get_result(resultPath)\n",
    "    print(y_prob.tail())\n",
    "    y_pred.columns = label.columns\n",
    "    y_prob.columns = label.columns\n",
    "    \n",
    "    y_pred_ensemble = y_pred_ensemble + y_pred\n",
    "    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "    \n",
    "    \n",
    "y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "y_prob_ensemble = y_prob_ensemble / ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['quiet-still', 'angry-aggresive', 'happy-pleased', 'relaxing-calm',\n",
      "       'sad-lonely', 'amazed-suprised'],\n",
      "      dtype='object')\n",
      "\n",
      "--- Confusion matrix ---\n",
      "--- Performance ---\n",
      "coverage_error = 2.63 ( avg_label_per_instance = 1.87 )\n",
      "ranking_loss = 0.15\n",
      "hamming_loss = 0.2\n",
      "f1_macro = 0.68\n",
      "f1_micro = 0.69\n",
      "Jaccard_Index = 0.8\n",
      "zero_one_error = 0.69\n",
      "\n",
      "- f1 for each label -\n",
      "label_amazed-suprised = 0.63\n",
      "label_happy-pleased = 0.79\n",
      "label_relaxing-calm = 0.76\n",
      "label_quiet-still = 0.61\n",
      "label_sad-lonely = 0.51\n",
      "label_angry-aggresive = 0.77\n"
     ]
    }
   ],
   "source": [
    "performance = evaluation(y_pred=y_pred_ensemble, y_true=y_true, y_prob=y_prob_ensemble)\n",
    "\n",
    "# print orders:\n",
    "print(label.columns[order])\n",
    "\n",
    "# get confusion matrix\n",
    "print(\"\\n--- Confusion matrix ---\")\n",
    "get_confusion_matrix(y_pred, y_true, y_pred.columns)\n",
    "\n",
    "# print performance\n",
    "print(\"--- Performance ---\")\n",
    "for key, value in performance.items():\n",
    "    if key == \"f1_each_label\":\n",
    "        print(\"\\n- f1 for each label -\")\n",
    "        for i in range(n_label):\n",
    "            print(\"label_\"+label.columns[i],\"=\",round(value[i],2))\n",
    "    elif key == \"coverage_error\":\n",
    "        print(key,'=',round(value,2),\"( avg_label_per_instance =\",round(avg_label_per_instance,2),\")\")\n",
    "    else:\n",
    "        print(key,'=',round(value,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "**Performance of BR_naive Bayes**\n",
    "coverage_error = 13.6 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.13\n",
    "hamming_loss = 0.1\n",
    "f1_macro = 0.26\n",
    "f1_micro = 0.4\n",
    "Jaccard_Index = 0.26\n",
    "zero_one_error = 0.98\n",
    "`\n",
    "\n",
    "`\n",
    "**Performance of BR_ESKDB**\n",
    "coverage_error = 14.76 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.15\n",
    "hamming_loss = 0.08\n",
    "f1_macro = 0.15\n",
    "f1_micro = 0.33\n",
    "jaccard_index = 0.23\n",
    "zero_one_error = 0.94\n",
    "`\n",
    "\n",
    "`\n",
    "**Performance of Ensemble Classifier Chain using naive Bayes**\n",
    "coverage_error = 13.63 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.13\n",
    "hamming_loss = 0.11\n",
    "f1_macro = 0.26\n",
    "f1_micro = 0.38\n",
    "Jaccard_Index = 0.25\n",
    "zero_one_error = 0.97\n",
    "`\n",
    "\n",
    "`\n",
    "**Performance of Ensemble Classifier Chain using ESKDB(E=2)**\n",
    "coverage_error = 15.87 ( avg_label_per_instance = 3.25 )\n",
    "ranking_loss = 0.16\n",
    "hamming_loss = 0.08\n",
    "f1_macro = 0.22\n",
    "f1_micro = 0.38\n",
    "Jaccard_Index = 0.25\n",
    "zero_one_error = 0.95\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall 体现了分类模型H对正样本的识别能力，recall 越高，说明模型对正样本的识别能力越强.\n",
    "\n",
    "precision 体现了模型对负样本的区分能力，precision越高，说明模型对负样本的区分能力越强。F1-score 是两者的综合。F1-score 越高，说明分类模型越稳健。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
