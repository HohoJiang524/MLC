{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath, X_file, y_file):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,X_file))\n",
    "    label = pd.read_csv(os.path.join(dataPath,y_file))\n",
    "    return data,label\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = acc / y_true.shape[0]\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one}\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    \n",
    "    order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "    \n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)] # create a classifier chain\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            classifier_list[i].fit(X_train,y_train.iloc[:, order[i]])\n",
    "        else:\n",
    "            X_train = pd.concat([X_train, y_train.iloc[:,order[i-1]]],axis=1) # put the previous label into attribute space\n",
    "            classifier_list[i].fit(X_train,y_train.iloc[:,order[i]])\n",
    "\n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time, order\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order):\n",
    "    y_predict = pd.DataFrame(index=X_test.index)\n",
    "    y_prob = pd.DataFrame(index=X_test.index)\n",
    "    y_true = pd.DataFrame(index=X_test.index)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index)],axis=1)\n",
    "\n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index)],axis=1)\n",
    "\n",
    "        X_test = pd.concat([X_test, pd.DataFrame(y_predict_i,index=X_test.index)],axis=1,ignore_index=True) # put the previous label into attribute space\n",
    "\n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "            \n",
    "def ECC_test(data, label, dataPath, random_state=3071980, ensemble = 5):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # ensemble\n",
    "    y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    for i in range(ensemble):\n",
    "        # training\n",
    "        #print(\"--- start training ---\\n\")\n",
    "        classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "        # testing\n",
    "        #print(\"--- start testing ---\\n\")\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "        y_predict.columns = label.columns[order]\n",
    "        y_prob.columns = label.columns[order]\n",
    "        y_predict = y_predict[label.columns]\n",
    "        y_prob = y_prob[label.columns]\n",
    "\n",
    "        y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "        y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "    y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "    y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "    performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "    \n",
    "    return performance_df\n",
    "\n",
    "def ECC_test_2_fold(data, label, dataPath, random_state=3071980, ensemble = 5):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    performance_df_all = pd.DataFrame(np.zeros([7,1]))\n",
    "    \n",
    "    for j in range(2):\n",
    "        X_train, y_train = X_test, y_test\n",
    "        \n",
    "        # ensemble\n",
    "        y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "        y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "        for i in range(ensemble):\n",
    "            # training\n",
    "            #print(\"--- start training ---\\n\")\n",
    "            classifier_list, training_time, order = naiveBayes_multi_label_training(X_train, y_train)\n",
    "\n",
    "            # testing\n",
    "            #print(\"--- start testing ---\\n\")\n",
    "            y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, order)\n",
    "\n",
    "            y_predict.columns = label.columns[order]\n",
    "            y_prob.columns = label.columns[order]\n",
    "            y_predict = y_predict[label.columns]\n",
    "            y_prob = y_prob[label.columns]\n",
    "\n",
    "            y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "            y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "        y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "        y_prob_ensemble = y_prob_ensemble / ensemble \n",
    "\n",
    "        # evaluation\n",
    "        performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "        performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "        performance_df_all.index = performance_df.index\n",
    "        performance_df_all.columns = performance_df.columns\n",
    "        performance_df_all = performance_df_all + performance_df\n",
    "    \n",
    "    performance_df_all = performance_df_all / 2\n",
    "    return performance_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.314309</td>\n",
       "      <td>2.875421</td>\n",
       "      <td>1.510797</td>\n",
       "      <td>17.390129</td>\n",
       "      <td>1.389728</td>\n",
       "      <td>3.824131</td>\n",
       "      <td>4.219052</td>\n",
       "      <td>14.054667</td>\n",
       "      <td>13.936000</td>\n",
       "      <td>14.311000</td>\n",
       "      <td>12.762333</td>\n",
       "      <td>14.293333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.230073</td>\n",
       "      <td>0.182473</td>\n",
       "      <td>0.082962</td>\n",
       "      <td>0.133060</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>0.062098</td>\n",
       "      <td>0.056307</td>\n",
       "      <td>0.057106</td>\n",
       "      <td>0.060514</td>\n",
       "      <td>0.054238</td>\n",
       "      <td>0.058865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.253574</td>\n",
       "      <td>0.231762</td>\n",
       "      <td>0.197259</td>\n",
       "      <td>0.123717</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>0.117804</td>\n",
       "      <td>0.029957</td>\n",
       "      <td>0.027937</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.024838</td>\n",
       "      <td>0.028809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.384789</td>\n",
       "      <td>0.620110</td>\n",
       "      <td>0.639090</td>\n",
       "      <td>0.186216</td>\n",
       "      <td>0.485587</td>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.474961</td>\n",
       "      <td>0.247974</td>\n",
       "      <td>0.216460</td>\n",
       "      <td>0.188286</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>0.196622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.570112</td>\n",
       "      <td>0.657829</td>\n",
       "      <td>0.618065</td>\n",
       "      <td>0.402186</td>\n",
       "      <td>0.934555</td>\n",
       "      <td>0.561017</td>\n",
       "      <td>0.576928</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>0.422697</td>\n",
       "      <td>0.414194</td>\n",
       "      <td>0.431055</td>\n",
       "      <td>0.415612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.885856</td>\n",
       "      <td>0.710438</td>\n",
       "      <td>0.787375</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.658487</td>\n",
       "      <td>0.885159</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.867667</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.799333</td>\n",
       "      <td>0.886333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  8.314309  2.875421  1.510797  17.390129  1.389728  3.824131   \n",
       "ranking_loss    0.230073  0.182473  0.082962   0.133060  0.003236  0.047049   \n",
       "hamming_loss    0.253574  0.231762  0.197259   0.123717  0.005595  0.023540   \n",
       "f1_macro        0.384789  0.620110  0.639090   0.186216  0.485587  0.154630   \n",
       "f1_micro        0.570112  0.657829  0.618065   0.402186  0.934555  0.561017   \n",
       "Jaccard_Index   0.750000  0.770000  0.800000   0.880000  0.990000  0.980000   \n",
       "zero_one_error  0.885856  0.710438  0.787375   0.990599  0.117825  0.658487   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  4.219052    14.054667    13.936000    14.311000    12.762333   \n",
       "ranking_loss    0.062098     0.056307     0.057106     0.060514     0.054238   \n",
       "hamming_loss    0.117804     0.029957     0.027937     0.028604     0.024838   \n",
       "f1_macro        0.474961     0.247974     0.216460     0.188286     0.189647   \n",
       "f1_micro        0.576928     0.465083     0.422697     0.414194     0.431055   \n",
       "Jaccard_Index   0.880000     0.970000     0.970000     0.970000     0.980000   \n",
       "zero_one_error  0.885159     0.956000     0.867667     0.866000     0.799333   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error    14.293333  \n",
       "ranking_loss       0.058865  \n",
       "hamming_loss       0.028809  \n",
       "f1_macro           0.196622  \n",
       "f1_micro           0.415612  \n",
       "Jaccard_Index      0.970000  \n",
       "zero_one_error     0.886333  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_1 = pd.DataFrame()\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "\n",
    "    # train - test\n",
    "    df = ECC_test(data, label, dataPath, random_state=3071980, ensemble=1)\n",
    "    df.columns = [dataset]\n",
    "    \n",
    "    df_all_1 = pd.concat([df_all_1, df],axis=1)\n",
    "\n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "\n",
    "    # train - test\n",
    "    df = ECC_test(data, label, dataPath, random_state=3071980, ensemble=1)\n",
    "    df.columns = [dataset]\n",
    "    \n",
    "    df_all_1 = pd.concat([df_all_1, df],axis=1)\n",
    "    \n",
    "df_all_1.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/ClassifierChain_naive_bayes.csv\")\n",
    "df_all_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions\n",
      "scene\n",
      "enron\n",
      "genbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.085277</td>\n",
       "      <td>2.812795</td>\n",
       "      <td>1.512625</td>\n",
       "      <td>12.860282</td>\n",
       "      <td>1.331118</td>\n",
       "      <td>1.771984</td>\n",
       "      <td>4.019562</td>\n",
       "      <td>9.401933</td>\n",
       "      <td>8.260600</td>\n",
       "      <td>8.415567</td>\n",
       "      <td>7.816600</td>\n",
       "      <td>8.407567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.204726</td>\n",
       "      <td>0.168115</td>\n",
       "      <td>0.083603</td>\n",
       "      <td>0.087931</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.055730</td>\n",
       "      <td>0.033625</td>\n",
       "      <td>0.029344</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.028701</td>\n",
       "      <td>0.029040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.235307</td>\n",
       "      <td>0.229293</td>\n",
       "      <td>0.192760</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>0.112968</td>\n",
       "      <td>0.026829</td>\n",
       "      <td>0.023318</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>0.024045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.431348</td>\n",
       "      <td>0.648080</td>\n",
       "      <td>0.642607</td>\n",
       "      <td>0.340286</td>\n",
       "      <td>0.553365</td>\n",
       "      <td>0.321123</td>\n",
       "      <td>0.497193</td>\n",
       "      <td>0.340807</td>\n",
       "      <td>0.356302</td>\n",
       "      <td>0.340567</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>0.344566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.601635</td>\n",
       "      <td>0.668027</td>\n",
       "      <td>0.624526</td>\n",
       "      <td>0.501544</td>\n",
       "      <td>0.950593</td>\n",
       "      <td>0.733876</td>\n",
       "      <td>0.593046</td>\n",
       "      <td>0.525019</td>\n",
       "      <td>0.513630</td>\n",
       "      <td>0.514507</td>\n",
       "      <td>0.515441</td>\n",
       "      <td>0.506585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.764693</td>\n",
       "      <td>0.770707</td>\n",
       "      <td>0.807240</td>\n",
       "      <td>0.902199</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.986480</td>\n",
       "      <td>0.887032</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.976544</td>\n",
       "      <td>0.979464</td>\n",
       "      <td>0.975955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.862945</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.791362</td>\n",
       "      <td>0.967215</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0.448262</td>\n",
       "      <td>0.877948</td>\n",
       "      <td>0.947533</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.753933</td>\n",
       "      <td>0.861133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  8.085277  2.812795  1.512625  12.860282  1.331118  1.771984   \n",
       "ranking_loss    0.204726  0.168115  0.083603   0.087931  0.002091  0.010484   \n",
       "hamming_loss    0.235307  0.229293  0.192760   0.097801  0.004274  0.013520   \n",
       "f1_macro        0.431348  0.648080  0.642607   0.340286  0.553365  0.321123   \n",
       "f1_micro        0.601635  0.668027  0.624526   0.501544  0.950593  0.733876   \n",
       "Jaccard_Index   0.764693  0.770707  0.807240   0.902199  0.995726  0.986480   \n",
       "zero_one_error  0.862945  0.722222  0.791362   0.967215  0.099094  0.448262   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  4.019562     9.401933     8.260600     8.415567     7.816600   \n",
       "ranking_loss    0.055730     0.033625     0.029344     0.030343     0.028701   \n",
       "hamming_loss    0.112968     0.026829     0.023318     0.023456     0.020536   \n",
       "f1_macro        0.497193     0.340807     0.356302     0.340567     0.336662   \n",
       "f1_micro        0.593046     0.525019     0.513630     0.514507     0.515441   \n",
       "Jaccard_Index   0.887032     0.973171     0.976682     0.976544     0.979464   \n",
       "zero_one_error  0.877948     0.947533     0.837767     0.828667     0.753933   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error     8.407567  \n",
       "ranking_loss       0.029040  \n",
       "hamming_loss       0.024045  \n",
       "f1_macro           0.344566  \n",
       "f1_micro           0.506585  \n",
       "Jaccard_Index      0.975955  \n",
       "zero_one_error     0.861133  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_1_fold = pd.DataFrame()\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data  \n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        df = ECC_test_2_fold(data, label, dataPath, random_state=3071980, ensemble=1)\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    df_all_1_fold = pd.concat([df_all_1_fold, d/5],axis=1)\n",
    "\n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        df = ECC_test_2_fold(data, label, dataPath, random_state=3071980, ensemble=1)\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    df_all_1_fold = pd.concat([df_all_1_fold, d/5],axis=1)\n",
    "    \n",
    "df_all_1_fold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/ClassifierChain_naive_bayes.csv\")\n",
    "df_all_1_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "\n",
    "    # train - test\n",
    "    df = ECC_test(data, label, dataPath, random_state=3071980, ensemble=10)\n",
    "    df.columns = [dataset]\n",
    "    \n",
    "    df_all = pd.concat([df_all, df],axis=1)\n",
    "\n",
    "data_list = ['tmc2007', 'rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "\n",
    "    # train - test\n",
    "    df = ECC_test(data, label, dataPath, random_state=3071980, ensemble=10)\n",
    "    df.columns = [dataset]\n",
    "    \n",
    "    df_all = pd.concat([df_all, df],axis=1)\n",
    "    \n",
    "df_all.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/EnsembleClassifierChain_naive_bayes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 times 2 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions\n",
      "scene\n",
      "enron\n",
      "genbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.834243</td>\n",
       "      <td>2.817845</td>\n",
       "      <td>1.497924</td>\n",
       "      <td>11.575323</td>\n",
       "      <td>1.314502</td>\n",
       "      <td>1.765235</td>\n",
       "      <td>3.996944</td>\n",
       "      <td>8.548700</td>\n",
       "      <td>7.532367</td>\n",
       "      <td>7.677300</td>\n",
       "      <td>7.116467</td>\n",
       "      <td>7.701533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.167507</td>\n",
       "      <td>0.080375</td>\n",
       "      <td>0.076747</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.029843</td>\n",
       "      <td>0.025817</td>\n",
       "      <td>0.026770</td>\n",
       "      <td>0.025019</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.231673</td>\n",
       "      <td>0.228620</td>\n",
       "      <td>0.194477</td>\n",
       "      <td>0.097920</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.113594</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.019913</td>\n",
       "      <td>0.023224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.429116</td>\n",
       "      <td>0.653563</td>\n",
       "      <td>0.641782</td>\n",
       "      <td>0.339263</td>\n",
       "      <td>0.560672</td>\n",
       "      <td>0.323638</td>\n",
       "      <td>0.496086</td>\n",
       "      <td>0.345292</td>\n",
       "      <td>0.379203</td>\n",
       "      <td>0.364055</td>\n",
       "      <td>0.362358</td>\n",
       "      <td>0.366712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.607744</td>\n",
       "      <td>0.671188</td>\n",
       "      <td>0.622727</td>\n",
       "      <td>0.501604</td>\n",
       "      <td>0.953876</td>\n",
       "      <td>0.733506</td>\n",
       "      <td>0.592886</td>\n",
       "      <td>0.532414</td>\n",
       "      <td>0.530172</td>\n",
       "      <td>0.531616</td>\n",
       "      <td>0.533935</td>\n",
       "      <td>0.524146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.768327</td>\n",
       "      <td>0.771380</td>\n",
       "      <td>0.805523</td>\n",
       "      <td>0.902080</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.986399</td>\n",
       "      <td>0.886406</td>\n",
       "      <td>0.973384</td>\n",
       "      <td>0.977287</td>\n",
       "      <td>0.977242</td>\n",
       "      <td>0.980087</td>\n",
       "      <td>0.976776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.717845</td>\n",
       "      <td>0.793688</td>\n",
       "      <td>0.968508</td>\n",
       "      <td>0.090937</td>\n",
       "      <td>0.451738</td>\n",
       "      <td>0.878780</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.850733</td>\n",
       "      <td>0.839733</td>\n",
       "      <td>0.765933</td>\n",
       "      <td>0.866600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  7.834243  2.817845  1.497924  11.575323  1.314502  1.765235   \n",
       "ranking_loss    0.194215  0.167507  0.080375   0.076747  0.001802  0.010274   \n",
       "hamming_loss    0.231673  0.228620  0.194477   0.097920  0.004006  0.013601   \n",
       "f1_macro        0.429116  0.653563  0.641782   0.339263  0.560672  0.323638   \n",
       "f1_micro        0.607744  0.671188  0.622727   0.501604  0.953876  0.733506   \n",
       "Jaccard_Index   0.768327  0.771380  0.805523   0.902080  0.995994  0.986399   \n",
       "zero_one_error  0.864847  0.717845  0.793688   0.968508  0.090937  0.451738   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  3.996944     8.548700     7.532367     7.677300     7.116467   \n",
       "ranking_loss    0.054764     0.029843     0.025817     0.026770     0.025019   \n",
       "hamming_loss    0.113594     0.026616     0.022713     0.022758     0.019913   \n",
       "f1_macro        0.496086     0.345292     0.379203     0.364055     0.362358   \n",
       "f1_micro        0.592886     0.532414     0.530172     0.531616     0.533935   \n",
       "Jaccard_Index   0.886406     0.973384     0.977287     0.977242     0.980087   \n",
       "zero_one_error  0.878780     0.954000     0.850733     0.839733     0.765933   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error     7.701533  \n",
       "ranking_loss       0.025863  \n",
       "hamming_loss       0.023224  \n",
       "f1_macro           0.366712  \n",
       "f1_micro           0.524146  \n",
       "Jaccard_Index      0.976776  \n",
       "zero_one_error     0.866600  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2_fold = pd.DataFrame()\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data  \n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        df = ECC_test_2_fold(data, label, dataPath, random_state=3071980, ensemble=10)\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    df_all_2_fold = pd.concat([df_all_2_fold, d/5],axis=1)\n",
    "\n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        df = ECC_test_2_fold(data, label, dataPath, random_state=3071980, ensemble=10)\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    df_all_2_fold = pd.concat([df_all_2_fold, d/5],axis=1)\n",
    "    \n",
    "df_all_2_fold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/EnsembleClassifierChain_naive_bayes.csv\")\n",
    "df_all_2_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
