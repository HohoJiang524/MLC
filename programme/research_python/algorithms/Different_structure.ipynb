{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from pomegranate import BayesianNetwork\n",
    "import pomegranate\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "#Python program to print topological sorting of a DAG \n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to represent a graph \n",
    "class Graph: \n",
    "    def __init__(self,vertices): \n",
    "        self.graph = defaultdict(list) #dictionary containing adjacency List \n",
    "        self.V = vertices #No. of vertices \n",
    "  \n",
    "    # function to add an edge to graph \n",
    "    def addEdge(self,u,v): \n",
    "        self.graph[u].extend(v) \n",
    "  \n",
    "    # A recursive function used by topologicalSort \n",
    "    def topologicalSortUtil(self,v,visited,stack): \n",
    "  \n",
    "        # Mark the current node as visited. \n",
    "        visited[v] = True\n",
    "  \n",
    "        # Recur for all the vertices adjacent to this vertex \n",
    "        for i in self.graph[v]: \n",
    "            if visited[i] == False: \n",
    "                self.topologicalSortUtil(i,visited,stack) \n",
    "  \n",
    "        # Push current vertex to stack which stores result \n",
    "        stack.insert(0,v) \n",
    "  \n",
    "    # The function to do Topological Sort. It uses recursive  \n",
    "    # topologicalSortUtil() \n",
    "    def topologicalSort(self): \n",
    "        # Mark all the vertices as not visited \n",
    "        visited = [False]*self.V \n",
    "        stack =[] \n",
    "  \n",
    "        # Call the recursive helper function to store Topological \n",
    "        # Sort starting from all vertices one by one \n",
    "        for i in range(self.V): \n",
    "            if visited[i] == False: \n",
    "                self.topologicalSortUtil(i,visited,stack) \n",
    "  \n",
    "        # Print contents of the stack \n",
    "        return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath, X_file, y_file):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,X_file))\n",
    "    label = pd.read_csv(os.path.join(dataPath,y_file))\n",
    "    return data,label\n",
    "\n",
    "def get_structure(model, labels):\n",
    "    dic = {}\n",
    "    for item, attr in zip(model.structure, labels):\n",
    "        if item == ():\n",
    "            dic[attr] = {}\n",
    "        else:\n",
    "            dic[attr] = set(labels[list(item)])\n",
    "    return dic\n",
    "\n",
    "def get_order(model, labels):\n",
    "    \n",
    "    g = Graph(len(labels))\n",
    "    for item, i in zip(model.structure, range(len(labels))):\n",
    "        if item == ():\n",
    "            pass\n",
    "        else:\n",
    "            g.addEdge(i, list(item))\n",
    "    \n",
    "    # get order\n",
    "    a = g.topologicalSort()\n",
    "    a.reverse()\n",
    "\n",
    "    return labels[a]\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = acc / y_true.shape[0]\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one}\n",
    "    return performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BR for getting error matrix\n",
    "def naiveBayes_multi_label_training_BR(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training_BR(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list)\n",
    "    \n",
    "    y_predict.columns = label.columns\n",
    "    return y_predict, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCC with different Bayesian network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training_order(X_train, y_train, bayes_net, order):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    \n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)] # create a classifier chain\n",
    "    \n",
    "    learned_label = []\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            l = order[i]\n",
    "            classifier_list[i].fit(X_train, y_train.loc[:, l])\n",
    "            learned_label.append(l)\n",
    "            \n",
    "        else:\n",
    "            l = order[i]\n",
    "            par = [x for x in bayes_net[l] if x in learned_label]\n",
    "            X = pd.concat([X_train, y_train.loc[:,par]],axis=1) # put the previous label into attribute space\n",
    "            classifier_list[i].fit(X, y_train.loc[:, l])\n",
    "            learned_label.append(l)\n",
    "\n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, learned_label\n",
    "\n",
    "def naiveBayes_multi_label_testing_order(X_test, n_label, classifier_list, bayes_net, learned_label):\n",
    "    y_predict = pd.DataFrame(index=X_test.index)\n",
    "    y_prob = pd.DataFrame(index=X_test.index)\n",
    "    y_true = pd.DataFrame(index=X_test.index)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    predicted_list = []\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            l = learned_label[i]\n",
    "            y_predict_i = classifier_list[i].predict(X_test)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            predicted_list.append(l)\n",
    "        \n",
    "        else:\n",
    "            l = learned_label[i]\n",
    "            par = [p for p in bayes_net[l] if p in predicted_list]\n",
    "            if len(par) != 0:\n",
    "                X = pd.concat([X_test, y_predict.loc[:,par]],axis=1) # put the previous label into attribute space\n",
    "            else:\n",
    "                X= X_test\n",
    "            y_predict_i = classifier_list[i].predict(X)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X)[:,1]\n",
    "            \n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "  \n",
    "            predicted_list.append(l)            \n",
    "        \n",
    "    return y_predict, y_prob\n",
    "\n",
    "def BCC_test_structure(data, label, dataPath, random_state=3071980, ensemble = 5, structure=\"random\"):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    if structure==\"DAG\":\n",
    "        model = BayesianNetwork.from_samples(label, algorithm='exact-dp')\n",
    "        bayes_net = get_structure(model, label.columns)\n",
    "        order = get_order(model, label.columns)\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # ensemble\n",
    "    y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    \n",
    "    for i in range(ensemble):\n",
    "        if order_method==\"tree\":\n",
    "            if len(label.columns) <= ensemble:\n",
    "                root_index = i\n",
    "            else:\n",
    "                root_index = random.randint(0,len(label.columns))\n",
    "            model = BayesianNetwork.from_samples(label, algorithm='chow-liu', root=root_index)\n",
    "            bayes_net = get_structure(model, label.columns)\n",
    "            order = get_order(model, label.columns)\n",
    "\n",
    "        # training\n",
    "        #print(\"--- start training ---\\n\")\n",
    "        classifier_list, learned_label = naiveBayes_multi_label_training_order(X_train, y_train, bayes_net, order)\n",
    "\n",
    "        # testing\n",
    "        #print(\"--- start testing ---\\n\")\n",
    "        y_predict, y_prob = naiveBayes_multi_label_testing_order(X_test, n_label, classifier_list, bayes_net, learned_label)\n",
    "\n",
    "        y_predict = y_predict[label.columns]\n",
    "        y_prob = y_prob[label.columns]\n",
    "\n",
    "        y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "        y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "        \n",
    "    y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "    y_prob_ensemble = y_prob_ensemble / ensemble\n",
    "    y_pred_ensemble = y_pred_ensemble.fillna(0)\n",
    "    y_prob_ensemble = y_prob_ensemble.fillna(0)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "    performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "    \n",
    "    return performance_df\n",
    "\n",
    "\n",
    "def BCC_test_structure_twofold(data, label, dataPath, random_state=3071980, ensemble = 5, structure=\"random\"):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    \n",
    "    # get order\n",
    "    if structure==\"DAG\":\n",
    "        model = BayesianNetwork.from_samples(label, algorithm='greedy')\n",
    "        bayes_net = get_structure(model, label.columns)\n",
    "        order = get_order(model, label.columns)\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    performance_df_all = pd.DataFrame(np.zeros([7,1]))\n",
    "    for j in range(2):\n",
    "        X_train, y_train = X_test, y_test\n",
    "    # ensemble\n",
    "        y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "        y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "        for i in range(ensemble):\n",
    "            if structure==\"tree\":\n",
    "                if len(label.columns) <= ensemble:\n",
    "                    root_index = i\n",
    "                else:\n",
    "                    root_index = random.randint(0,len(label.columns)-1)\n",
    "                model = BayesianNetwork.from_samples(label, algorithm='chow-liu', root=root_index)\n",
    "                bayes_net = get_structure(model, label.columns)\n",
    "                order = get_order(model, label.columns)\n",
    "                \n",
    "                \n",
    "            # training\n",
    "            #print(\"--- start training ---\\n\")\n",
    "            classifier_list, learned_label = naiveBayes_multi_label_training_order(X_train, y_train, bayes_net, order)\n",
    "\n",
    "            # testing\n",
    "            #print(\"--- start testing ---\\n\")\n",
    "            y_predict, y_prob = naiveBayes_multi_label_testing_order(X_test, n_label, classifier_list, bayes_net, learned_label)\n",
    "\n",
    "            y_predict = y_predict[label.columns]\n",
    "            y_prob = y_prob[label.columns]\n",
    "\n",
    "            y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "            y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "        \n",
    "        y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "        y_prob_ensemble = y_prob_ensemble / ensemble\n",
    "        y_pred_ensemble = y_pred_ensemble.fillna(0)\n",
    "        y_prob_ensemble = y_prob_ensemble.fillna(0)\n",
    "\n",
    "        # evaluation\n",
    "        performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "        performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "        \n",
    "        performance_df_all.index = performance_df.index\n",
    "        performance_df_all.columns = performance_df.columns\n",
    "        \n",
    "        performance_df_all = performance_df_all + performance_df\n",
    "        \n",
    "    performance_df_all = performance_df_all / 2\n",
    "    return performance_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n",
      "medical\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.822498</td>\n",
       "      <td>2.753535</td>\n",
       "      <td>1.502159</td>\n",
       "      <td>12.073090</td>\n",
       "      <td>1.389728</td>\n",
       "      <td>1.888753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.198750</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>0.082875</td>\n",
       "      <td>0.079046</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.240683</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.203128</td>\n",
       "      <td>0.093003</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.422559</td>\n",
       "      <td>0.642690</td>\n",
       "      <td>0.626591</td>\n",
       "      <td>0.378793</td>\n",
       "      <td>0.504426</td>\n",
       "      <td>0.275167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672793</td>\n",
       "      <td>0.607796</td>\n",
       "      <td>0.517522</td>\n",
       "      <td>0.944995</td>\n",
       "      <td>0.725833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.759317</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.796872</td>\n",
       "      <td>0.906997</td>\n",
       "      <td>0.995189</td>\n",
       "      <td>0.985880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.706397</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>0.964512</td>\n",
       "      <td>0.107553</td>\n",
       "      <td>0.470757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical\n",
       "coverage_error  7.822498  2.753535  1.502159  12.073090  1.389728  1.888753\n",
       "ranking_loss    0.198750  0.164368  0.082875   0.079046  0.002847  0.012165\n",
       "hamming_loss    0.240683  0.217284  0.203128   0.093003  0.004811  0.014120\n",
       "f1_macro        0.422559  0.642690  0.626591   0.378793  0.504426  0.275167\n",
       "f1_micro        0.594736  0.672793  0.607796   0.517522  0.944995  0.725833\n",
       "Jaccard_Index   0.759317  0.782716  0.796872   0.906997  0.995189  0.985880\n",
       "zero_one_error  0.862862  0.706397  0.803654   0.964512  0.107553  0.470757"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCC_tree= pd.DataFrame()\n",
    "\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    if label.shape[1] > 30:\n",
    "        ensemble = 30\n",
    "    else:\n",
    "        ensemble = label.shape[1]\n",
    "    for s in seed:\n",
    "        df = BCC_test_structure_twofold(data, label, dataPath, random_state=s, ensemble = ensemble, structure=\"tree\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    BCC_tree = pd.concat([BCC_tree, d/5],axis=1)\n",
    "\n",
    "BCC_tree.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BCC_tree.csv\")\n",
    "BCC_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.822498</td>\n",
       "      <td>2.753535</td>\n",
       "      <td>1.502159</td>\n",
       "      <td>12.073090</td>\n",
       "      <td>1.389728</td>\n",
       "      <td>1.888753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.198750</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>0.082875</td>\n",
       "      <td>0.079046</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.240683</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.203128</td>\n",
       "      <td>0.093003</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.014120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.422559</td>\n",
       "      <td>0.642690</td>\n",
       "      <td>0.626591</td>\n",
       "      <td>0.378793</td>\n",
       "      <td>0.504426</td>\n",
       "      <td>0.275167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672793</td>\n",
       "      <td>0.607796</td>\n",
       "      <td>0.517522</td>\n",
       "      <td>0.944995</td>\n",
       "      <td>0.725833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.759317</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.796872</td>\n",
       "      <td>0.906997</td>\n",
       "      <td>0.995189</td>\n",
       "      <td>0.985880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.706397</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>0.964512</td>\n",
       "      <td>0.107553</td>\n",
       "      <td>0.470757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical\n",
       "coverage_error  7.822498  2.753535  1.502159  12.073090  1.389728  1.888753\n",
       "ranking_loss    0.198750  0.164368  0.082875   0.079046  0.002847  0.012165\n",
       "hamming_loss    0.240683  0.217284  0.203128   0.093003  0.004811  0.014120\n",
       "f1_macro        0.422559  0.642690  0.626591   0.378793  0.504426  0.275167\n",
       "f1_micro        0.594736  0.672793  0.607796   0.517522  0.944995  0.725833\n",
       "Jaccard_Index   0.759317  0.782716  0.796872   0.906997  0.995189  0.985880\n",
       "zero_one_error  0.862862  0.706397  0.803654   0.964512  0.107553  0.470757"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCC_tree = pd.read_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BCC_tree.csv\", index_col=0)\n",
    "BCC_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmc2007\n",
      "rcv1subset1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.822498</td>\n",
       "      <td>2.753535</td>\n",
       "      <td>1.502159</td>\n",
       "      <td>12.073090</td>\n",
       "      <td>1.389728</td>\n",
       "      <td>1.888753</td>\n",
       "      <td>3.965142</td>\n",
       "      <td>8.843567</td>\n",
       "      <td>7.666133</td>\n",
       "      <td>7.675400</td>\n",
       "      <td>7.259567</td>\n",
       "      <td>7.696333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.198750</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>0.082875</td>\n",
       "      <td>0.079046</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.053674</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.026246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.240683</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.203128</td>\n",
       "      <td>0.093003</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.112906</td>\n",
       "      <td>0.028498</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>0.027366</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.027240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.422559</td>\n",
       "      <td>0.642690</td>\n",
       "      <td>0.626591</td>\n",
       "      <td>0.378793</td>\n",
       "      <td>0.504426</td>\n",
       "      <td>0.275167</td>\n",
       "      <td>0.495739</td>\n",
       "      <td>0.339552</td>\n",
       "      <td>0.329761</td>\n",
       "      <td>0.316706</td>\n",
       "      <td>0.269549</td>\n",
       "      <td>0.304158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.594736</td>\n",
       "      <td>0.672793</td>\n",
       "      <td>0.607796</td>\n",
       "      <td>0.517522</td>\n",
       "      <td>0.944995</td>\n",
       "      <td>0.725833</td>\n",
       "      <td>0.595701</td>\n",
       "      <td>0.511235</td>\n",
       "      <td>0.494076</td>\n",
       "      <td>0.491553</td>\n",
       "      <td>0.463382</td>\n",
       "      <td>0.490171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.759317</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.796872</td>\n",
       "      <td>0.906997</td>\n",
       "      <td>0.995189</td>\n",
       "      <td>0.985880</td>\n",
       "      <td>0.887094</td>\n",
       "      <td>0.971502</td>\n",
       "      <td>0.972948</td>\n",
       "      <td>0.972634</td>\n",
       "      <td>0.973249</td>\n",
       "      <td>0.972760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.706397</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>0.964512</td>\n",
       "      <td>0.107553</td>\n",
       "      <td>0.470757</td>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.954767</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.864133</td>\n",
       "      <td>0.798167</td>\n",
       "      <td>0.892167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  7.822498  2.753535  1.502159  12.073090  1.389728  1.888753   \n",
       "ranking_loss    0.198750  0.164368  0.082875   0.079046  0.002847  0.012165   \n",
       "hamming_loss    0.240683  0.217284  0.203128   0.093003  0.004811  0.014120   \n",
       "f1_macro        0.422559  0.642690  0.626591   0.378793  0.504426  0.275167   \n",
       "f1_micro        0.594736  0.672793  0.607796   0.517522  0.944995  0.725833   \n",
       "Jaccard_Index   0.759317  0.782716  0.796872   0.906997  0.995189  0.985880   \n",
       "zero_one_error  0.862862  0.706397  0.803654   0.964512  0.107553  0.470757   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  3.965142     8.843567     7.666133     7.675400     7.259567   \n",
       "ranking_loss    0.053674     0.031038     0.026412     0.026597     0.025732   \n",
       "hamming_loss    0.112906     0.028498     0.027052     0.027366     0.026751   \n",
       "f1_macro        0.495739     0.339552     0.329761     0.316706     0.269549   \n",
       "f1_micro        0.595701     0.511235     0.494076     0.491553     0.463382   \n",
       "Jaccard_Index   0.887094     0.971502     0.972948     0.972634     0.973249   \n",
       "zero_one_error  0.875857     0.954767     0.884800     0.864133     0.798167   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error     7.696333  \n",
       "ranking_loss       0.026246  \n",
       "hamming_loss       0.027240  \n",
       "f1_macro           0.304158  \n",
       "f1_micro           0.490171  \n",
       "Jaccard_Index      0.972760  \n",
       "zero_one_error     0.892167  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    if label.shape[1] > 30:\n",
    "        ensemble = 30\n",
    "    else:\n",
    "        ensemble = label.shape[1]\n",
    "        \n",
    "    for s in seed:\n",
    "        df = BCC_test_structure_twofold(data, label, dataPath, random_state=s, ensemble = ensemble, structure=\"tree\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    BCC_tree = pd.concat([BCC_tree, d/5],axis=1)\n",
    "    \n",
    "BCC_tree.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BCC_tree.csv\")\n",
    "BCC_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.848304</td>\n",
       "      <td>2.776431</td>\n",
       "      <td>1.525914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.196679</td>\n",
       "      <td>0.169306</td>\n",
       "      <td>0.087787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.230249</td>\n",
       "      <td>0.221212</td>\n",
       "      <td>0.200831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.411008</td>\n",
       "      <td>0.651435</td>\n",
       "      <td>0.629346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.600733</td>\n",
       "      <td>0.673136</td>\n",
       "      <td>0.609666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.769751</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.799169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.843176</td>\n",
       "      <td>0.709764</td>\n",
       "      <td>0.794518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene\n",
       "coverage_error  7.848304  2.776431  1.525914\n",
       "ranking_loss    0.196679  0.169306  0.087787\n",
       "hamming_loss    0.230249  0.221212  0.200831\n",
       "f1_macro        0.411008  0.651435  0.629346\n",
       "f1_micro        0.600733  0.673136  0.609666\n",
       "Jaccard_Index   0.769751  0.778788  0.799169\n",
       "zero_one_error  0.843176  0.709764  0.794518"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCC_dag= pd.DataFrame()\n",
    "\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        df = BCC_test_structure_twofold(data, label, dataPath, random_state = s, ensemble = 1, structure=\"DAG\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    BCC_dag = pd.concat([BCC_dag, d/5],axis=1)\n",
    "\n",
    "BCC_dag.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BCC_dag.csv\")\n",
    "BCC_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        df = BCC_test_structure_twofold(data, label, dataPath, random_state = s, ensemble = 1, structure=\"DAG\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    BCC_dag = pd.concat([BCC_dag, d/5],axis=1)\n",
    "    \n",
    "BCC_dag.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BCC_dag.csv\")\n",
    "BCC_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron\n"
     ]
    }
   ],
   "source": [
    "data_list = [\"enron\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNetwork.from_samples(label, algorithm='greedy',max_parents=2)\n",
    "bayes_net = get_structure(model, label.columns)\n",
    "order = get_order(model, label.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
