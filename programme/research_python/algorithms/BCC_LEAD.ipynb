{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BR for getting error matrix\n",
    "def naiveBayes_multi_label_training_BR(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training_BR(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list)\n",
    "    \n",
    "    y_predict.columns = label.columns\n",
    "    return y_predict, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath, X_file, y_file):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,X_file))\n",
    "    label = pd.read_csv(os.path.join(dataPath,y_file))\n",
    "    return data,label\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = acc / y_true.shape[0]\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one}\n",
    "    return performance\n",
    "            \n",
    "def build_BN(labelFile, labelName, savePng):\n",
    "    cmd = \"\"\"cd /Volumes/Samsung_T5/research/programme/Chordalysis/ \n",
    "    java -Xmx1g -classpath bin:lib/core/commons-math3-3.2.jar:lib/core/jayes.jar:lib/core/jgrapht-jdk1.6.jar:lib/extra/jgraphx.jar:lib/loader/weka.jar demo.Run %s 0.05 %s false\n",
    "    \"\"\" % (labelFile,savePng)\n",
    "\n",
    "    p = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE)\n",
    "    out,err = p.communicate()  \n",
    "    for line in out.splitlines():  \n",
    "        if line.decode(\"utf-8\").startswith('['):\n",
    "            graph_set = [i for i in map(lambda x: x.split(','), line.decode(\"utf-8\").replace(' ',',').strip('[[\\,]]').split(',]['))]\n",
    "\n",
    "    dic = {}\n",
    "    for l in labelName:\n",
    "        s = set()\n",
    "        for i in map(lambda x: set(x) if l in x else None, graph_set):\n",
    "            if i != None:\n",
    "                s.update(i)\n",
    "        s.remove(l)       \n",
    "        dic[l] = s\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train, bayes_net, root_name):\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    \n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)] # create a classifier chain\n",
    "    \n",
    "    learned_label = []\n",
    "    \n",
    "    i = 0\n",
    "    inde_node = 0\n",
    "    \n",
    "    for node, par in bayes_net.items():\n",
    "        if par == set():\n",
    "            l = node\n",
    "            classifier_list[i].fit(X_train,y_train.loc[:, l])\n",
    "            i += 1\n",
    "            learned_label.append(l)\n",
    "            inde_node += 1\n",
    "            \n",
    "    while True:\n",
    "        if i == inde_node:\n",
    "            l = root_name\n",
    "            classifier_list[i].fit(X_train,y_train.loc[:, l])\n",
    "            i += 1\n",
    "            learned_label.append(l)\n",
    "            children = bayes_net[l]\n",
    "            \n",
    "        else:\n",
    "            children_sub = []\n",
    "            for child in children:\n",
    "                par = [p for p in bayes_net[child] if p in learned_label]\n",
    "                X = pd.concat([X_train, y_train.loc[:,par]],axis=1) # put the previous label into attribute space\n",
    "                classifier_list[i].fit(X,y_train.loc[:,child])\n",
    "                i += 1\n",
    "                learned_label.append(child)\n",
    "                children_sub.extend([p for p in bayes_net[child] if p not in learned_label])\n",
    "            children = [p for p in set(children_sub) if p not in learned_label]\n",
    "                \n",
    "        if i >= n_label:\n",
    "            break\n",
    "    \n",
    "    return classifier_list, learned_label\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list, bayes_net, learned_label):\n",
    "    y_predict = pd.DataFrame(index=X_test.index)\n",
    "    y_prob = pd.DataFrame(index=X_test.index)\n",
    "    y_true = pd.DataFrame(index=X_test.index)\n",
    "        \n",
    "    predicted_list = []\n",
    "    i = 0\n",
    "    \n",
    "    inde_node = 0\n",
    "    for node, par in bayes_net.items():\n",
    "        if par == set():\n",
    "            l = learned_label[i]\n",
    "            y_predict_i = classifier_list[i].predict(X_test)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "            \n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            \n",
    "            predicted_list.append(l)\n",
    "            \n",
    "            i += 1\n",
    "            inde_node += 1\n",
    "            \n",
    "    while True:\n",
    "        if i == inde_node:\n",
    "            l = learned_label[i]\n",
    "            y_predict_i = classifier_list[i].predict(X_test)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "            \n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            \n",
    "            predicted_list.append(l)\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "        else:\n",
    "            l = learned_label[i]\n",
    "            par = [p for p in bayes_net[l] if p in predicted_list]\n",
    "            \n",
    "            if len(par) != 0:\n",
    "                X = pd.concat([X_test, y_predict.loc[:,par]],axis=1) # put the previous label into attribute space\n",
    "            else:\n",
    "                X= X_test\n",
    "            y_predict_i = classifier_list[i].predict(X)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X)[:,1]\n",
    "            \n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "  \n",
    "            i += 1\n",
    "            predicted_list.append(l)\n",
    "        \n",
    "        if i >= n_label:\n",
    "            break\n",
    "            \n",
    "    return y_predict, y_prob\n",
    "\n",
    "def BCC_test(data, label, dataPath, bayes_net, random_state=3071980, ensemble = 5, root = None):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # ensemble\n",
    "    y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    \n",
    "    node_list = []\n",
    "    for node, par in bayes_net.items():\n",
    "        if par != set():\n",
    "            node_list.append(node)\n",
    "    \n",
    "    en = 0\n",
    "    for i in range(ensemble):\n",
    "        if root != None:\n",
    "            root_name = root\n",
    "        else:\n",
    "            root_name = label.columns[i]\n",
    "            if root_name not in node_list:\n",
    "                print(root_name)\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                # training\n",
    "                #print(\"--- start training ---\\n\")\n",
    "                classifier_list, learned_label = naiveBayes_multi_label_training(X_train, y_train, bayes_net, root_name)\n",
    "\n",
    "                # testing\n",
    "                #print(\"--- start testing ---\\n\")\n",
    "                y_predict, y_prob = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, bayes_net, learned_label)\n",
    "\n",
    "                y_predict = y_predict[label.columns]\n",
    "                y_prob = y_prob[label.columns]\n",
    "\n",
    "                y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "                y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "                en += 1\n",
    "        \n",
    "    y_pred_ensemble = (((y_pred_ensemble / en) >= 0.5)*1).astype('int')\n",
    "    y_prob_ensemble = y_prob_ensemble / en \n",
    "    y_pred_ensemble = y_pred_ensemble.fillna(0)\n",
    "    y_prob_ensemble = y_prob_ensemble.fillna(0)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "    performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "    \n",
    "    return performance_df\n",
    "\n",
    "def BCC_test_2_fold(data, label, dataPath, bayes_net, random_state=3071980, ensemble = 5, root = None):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    performance_df_all = pd.DataFrame(np.zeros([7,1]))\n",
    "    for j in range(2):\n",
    "        X_train, y_train = X_test, y_test\n",
    "        \n",
    "        # ensemble\n",
    "        y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "        y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "        node_list = []\n",
    "        for node, par in bayes_net.items():\n",
    "            if par != set():\n",
    "                node_list.append(node)\n",
    "\n",
    "        en = 0\n",
    "        for i in range(ensemble):\n",
    "            if root != None:\n",
    "                root_name = root\n",
    "            else:\n",
    "                root_name = label.columns[i]\n",
    "                if root_name not in node_list:\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    # training\n",
    "                    #print(\"--- start training ---\\n\")\n",
    "                    classifier_list, learned_label = naiveBayes_multi_label_training(X_train, y_train, bayes_net, root_name)\n",
    "\n",
    "                    # testing\n",
    "                    #print(\"--- start testing ---\\n\")\n",
    "                    y_predict, y_prob = naiveBayes_multi_label_testing(X_test, n_label, classifier_list, bayes_net, learned_label)\n",
    "\n",
    "                    y_predict = y_predict[label.columns]\n",
    "                    y_prob = y_prob[label.columns]\n",
    "\n",
    "                    y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "                    y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "                    en += 1\n",
    "\n",
    "        y_pred_ensemble = (((y_pred_ensemble / en) >= 0.5)*1).astype('int')\n",
    "        y_prob_ensemble = y_prob_ensemble / en \n",
    "        y_pred_ensemble = y_pred_ensemble.fillna(0)\n",
    "        y_prob_ensemble = y_prob_ensemble.fillna(0)\n",
    "\n",
    "        # evaluation\n",
    "        performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "        performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "        \n",
    "        performance_df_all.index = performance_df.index\n",
    "        performance_df_all.columns = performance_df.columns\n",
    "        \n",
    "        performance_df_all = performance_df_all + performance_df\n",
    "        \n",
    "    performance_df_all = performance_df_all / 2\n",
    "    return performance_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "emotions\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "scene\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "enron\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "D.D16\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "D.D15\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "D.D18\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "C.C13\n",
      "ensemble: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "PDOC00014\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "PDOC00660\n",
      "ensemble: 25\n",
      "PDOC00653\n",
      "ensemble: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "Class-2-786_09\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "Class-5-786_2\n",
      "ensemble: 6\n",
      "Class-6-V72_5\n",
      "ensemble: 7\n",
      "Class-7-511_9\n",
      "ensemble: 8\n",
      "Class-8-596_8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "Class-14-789_00\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "Class-16-462\n",
      "ensemble: 17\n",
      "Class-17-592_0\n",
      "ensemble: 18\n",
      "Class-18-786_59\n",
      "ensemble: 19\n",
      "Class-19-785_6\n",
      "ensemble: 20\n",
      "Class-20-V67_09\n",
      "ensemble: 21\n",
      "Class-21-795_5\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "Class-26-V42_0\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "Class-29-783_0\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "Class-42-599_7\n",
      "ensemble: 43\n",
      "ensemble: 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.094293</td>\n",
       "      <td>2.851852</td>\n",
       "      <td>1.510797</td>\n",
       "      <td>17.144536</td>\n",
       "      <td>1.462236</td>\n",
       "      <td>3.803681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.214029</td>\n",
       "      <td>0.174888</td>\n",
       "      <td>0.082879</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.046311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.243885</td>\n",
       "      <td>0.230079</td>\n",
       "      <td>0.204734</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.025721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.383105</td>\n",
       "      <td>0.620216</td>\n",
       "      <td>0.631126</td>\n",
       "      <td>0.188882</td>\n",
       "      <td>0.476872</td>\n",
       "      <td>0.157944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.583955</td>\n",
       "      <td>0.657763</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.417118</td>\n",
       "      <td>0.928947</td>\n",
       "      <td>0.536066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.795266</td>\n",
       "      <td>0.885551</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.974279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.873449</td>\n",
       "      <td>0.713805</td>\n",
       "      <td>0.793189</td>\n",
       "      <td>0.989424</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.664622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical\n",
       "coverage_error  8.094293  2.851852  1.510797  17.144536  1.462236  3.803681\n",
       "ranking_loss    0.214029  0.174888  0.082879   0.131462  0.004686  0.046311\n",
       "hamming_loss    0.243885  0.230079  0.204734   0.114449  0.006042  0.025721\n",
       "f1_macro        0.383105  0.620216  0.631126   0.188882  0.476872  0.157944\n",
       "f1_micro        0.583955  0.657763  0.610687   0.417118  0.928947  0.536066\n",
       "Jaccard_Index   0.756115  0.769921  0.795266   0.885551  0.993958  0.974279\n",
       "zero_one_error  0.873449  0.713805  0.793189   0.989424  0.129909  0.664622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_1 = pd.DataFrame()\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    print(\"learn structure\")\n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "    \n",
    "    print(\"BCC test\")\n",
    "    df = BCC_test(data, label, dataPath, bayes_net, 3071980, label.shape[1])\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_1 = pd.concat([df_all_1, df],axis=1)\n",
    "\n",
    "df_all_1.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/BayesianClassifierChain_naive_bayes.csv\")\n",
    "df_all_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmc2007\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "rcv1subset1\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcv1subset2\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcv1subset3\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "Class89\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n",
      "rcv1subset4\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "Class27\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "Class81\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n",
      "rcv1subset5\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "Class70\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.094293</td>\n",
       "      <td>2.851852</td>\n",
       "      <td>1.510797</td>\n",
       "      <td>17.144536</td>\n",
       "      <td>1.462236</td>\n",
       "      <td>3.803681</td>\n",
       "      <td>4.154008</td>\n",
       "      <td>13.701000</td>\n",
       "      <td>13.546333</td>\n",
       "      <td>13.694333</td>\n",
       "      <td>12.373667</td>\n",
       "      <td>14.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.214029</td>\n",
       "      <td>0.174888</td>\n",
       "      <td>0.082879</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.046311</td>\n",
       "      <td>0.060175</td>\n",
       "      <td>0.054673</td>\n",
       "      <td>0.055343</td>\n",
       "      <td>0.056344</td>\n",
       "      <td>0.051297</td>\n",
       "      <td>0.058726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.243885</td>\n",
       "      <td>0.230079</td>\n",
       "      <td>0.204734</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.025721</td>\n",
       "      <td>0.115913</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.035244</td>\n",
       "      <td>0.036030</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.038789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.383105</td>\n",
       "      <td>0.620216</td>\n",
       "      <td>0.631126</td>\n",
       "      <td>0.188882</td>\n",
       "      <td>0.476872</td>\n",
       "      <td>0.157944</td>\n",
       "      <td>0.478522</td>\n",
       "      <td>0.231094</td>\n",
       "      <td>0.210592</td>\n",
       "      <td>0.191668</td>\n",
       "      <td>0.175994</td>\n",
       "      <td>0.188055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.583955</td>\n",
       "      <td>0.657763</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.417118</td>\n",
       "      <td>0.928947</td>\n",
       "      <td>0.536066</td>\n",
       "      <td>0.583241</td>\n",
       "      <td>0.438599</td>\n",
       "      <td>0.389876</td>\n",
       "      <td>0.383185</td>\n",
       "      <td>0.377821</td>\n",
       "      <td>0.366381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.795266</td>\n",
       "      <td>0.885551</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.974279</td>\n",
       "      <td>0.884087</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.964756</td>\n",
       "      <td>0.963970</td>\n",
       "      <td>0.966967</td>\n",
       "      <td>0.961211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.873449</td>\n",
       "      <td>0.713805</td>\n",
       "      <td>0.793189</td>\n",
       "      <td>0.989424</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.664622</td>\n",
       "      <td>0.883340</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  8.094293  2.851852  1.510797  17.144536  1.462236  3.803681   \n",
       "ranking_loss    0.214029  0.174888  0.082879   0.131462  0.004686  0.046311   \n",
       "hamming_loss    0.243885  0.230079  0.204734   0.114449  0.006042  0.025721   \n",
       "f1_macro        0.383105  0.620216  0.631126   0.188882  0.476872  0.157944   \n",
       "f1_micro        0.583955  0.657763  0.610687   0.417118  0.928947  0.536066   \n",
       "Jaccard_Index   0.756115  0.769921  0.795266   0.885551  0.993958  0.974279   \n",
       "zero_one_error  0.873449  0.713805  0.793189   0.989424  0.129909  0.664622   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  4.154008    13.701000    13.546333    13.694333    12.373667   \n",
       "ranking_loss    0.060175     0.054673     0.055343     0.056344     0.051297   \n",
       "hamming_loss    0.115913     0.032967     0.035244     0.036030     0.033033   \n",
       "f1_macro        0.478522     0.231094     0.210592     0.191668     0.175994   \n",
       "f1_micro        0.583241     0.438599     0.389876     0.383185     0.377821   \n",
       "Jaccard_Index   0.884087     0.967033     0.964756     0.963970     0.966967   \n",
       "zero_one_error  0.883340     0.961333     0.894667     0.894667     0.815000   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error    14.248000  \n",
       "ranking_loss       0.058726  \n",
       "hamming_loss       0.038789  \n",
       "f1_macro           0.188055  \n",
       "f1_micro           0.366381  \n",
       "Jaccard_Index      0.961211  \n",
       "zero_one_error     0.912000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    print(\"learn structure\")\n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "    \n",
    "    print(\"BCC test\")\n",
    "    df = BCC_test(data, label, dataPath, bayes_net, 3071980, label.shape[1])\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_1 = pd.concat([df_all_1, df],axis=1)\n",
    "\n",
    "    \n",
    "df_all_1.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/BayesianClassifierChain_naive_bayes.csv\")\n",
    "df_all_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 times 2-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n",
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.802812</td>\n",
       "      <td>2.753535</td>\n",
       "      <td>1.488538</td>\n",
       "      <td>12.071915</td>\n",
       "      <td>1.358308</td>\n",
       "      <td>1.877710</td>\n",
       "      <td>3.979564</td>\n",
       "      <td>8.805133</td>\n",
       "      <td>7.695667</td>\n",
       "      <td>7.696733</td>\n",
       "      <td>7.283800</td>\n",
       "      <td>7.785933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.196125</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0.078935</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>0.030883</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.025777</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.232884</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.198726</td>\n",
       "      <td>0.092757</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.112740</td>\n",
       "      <td>0.028131</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>0.026969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.426581</td>\n",
       "      <td>0.642690</td>\n",
       "      <td>0.631035</td>\n",
       "      <td>0.378736</td>\n",
       "      <td>0.504426</td>\n",
       "      <td>0.275150</td>\n",
       "      <td>0.496631</td>\n",
       "      <td>0.339901</td>\n",
       "      <td>0.329695</td>\n",
       "      <td>0.318412</td>\n",
       "      <td>0.270732</td>\n",
       "      <td>0.304354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.603068</td>\n",
       "      <td>0.672793</td>\n",
       "      <td>0.612512</td>\n",
       "      <td>0.518102</td>\n",
       "      <td>0.944995</td>\n",
       "      <td>0.725644</td>\n",
       "      <td>0.595921</td>\n",
       "      <td>0.510375</td>\n",
       "      <td>0.491632</td>\n",
       "      <td>0.494747</td>\n",
       "      <td>0.467463</td>\n",
       "      <td>0.492696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.767116</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.801274</td>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.995189</td>\n",
       "      <td>0.985867</td>\n",
       "      <td>0.887260</td>\n",
       "      <td>0.971869</td>\n",
       "      <td>0.973267</td>\n",
       "      <td>0.973074</td>\n",
       "      <td>0.973634</td>\n",
       "      <td>0.973031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.851282</td>\n",
       "      <td>0.706397</td>\n",
       "      <td>0.798505</td>\n",
       "      <td>0.964512</td>\n",
       "      <td>0.107553</td>\n",
       "      <td>0.470757</td>\n",
       "      <td>0.874444</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.863533</td>\n",
       "      <td>0.797933</td>\n",
       "      <td>0.887267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  7.802812  2.753535  1.488538  12.071915  1.358308  1.877710   \n",
       "ranking_loss    0.196125  0.164368  0.080126   0.078935  0.002219  0.012031   \n",
       "hamming_loss    0.232884  0.217284  0.198726   0.092757  0.004811  0.014133   \n",
       "f1_macro        0.426581  0.642690  0.631035   0.378736  0.504426  0.275150   \n",
       "f1_micro        0.603068  0.672793  0.612512   0.518102  0.944995  0.725644   \n",
       "Jaccard_Index   0.767116  0.782716  0.801274   0.907243  0.995189  0.985867   \n",
       "zero_one_error  0.851282  0.706397  0.798505   0.964512  0.107553  0.470757   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  3.979564     8.805133     7.695667     7.696733     7.283800   \n",
       "ranking_loss    0.054211     0.030883     0.026532     0.026616     0.025777   \n",
       "hamming_loss    0.112740     0.028131     0.026733     0.026926     0.026366   \n",
       "f1_macro        0.496631     0.339901     0.329695     0.318412     0.270732   \n",
       "f1_micro        0.595921     0.510375     0.491632     0.494747     0.467463   \n",
       "Jaccard_Index   0.887260     0.971869     0.973267     0.973074     0.973634   \n",
       "zero_one_error  0.874444     0.953667     0.878000     0.863533     0.797933   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error     7.785933  \n",
       "ranking_loss       0.026631  \n",
       "hamming_loss       0.026969  \n",
       "f1_macro           0.304354  \n",
       "f1_micro           0.492696  \n",
       "Jaccard_Index      0.973031  \n",
       "zero_one_error     0.887267  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_1_twofold= pd.DataFrame()\n",
    "\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        labelFile = dataPath+\"y.csv\"\n",
    "        savePng = dataPath+\"/bayes_net.png\"\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "        df = BCC_test_2_fold(data, label, dataPath, bayes_net, s, label.shape[1])\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    df_all_1_twofold = pd.concat([df_all_1_twofold, d/5],axis=1)\n",
    "\n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        labelFile = dataPath+\"y.csv\"\n",
    "        savePng = dataPath+\"/bayes_net.png\"\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "        df = BCC_test_2_fold(data, label, dataPath, bayes_net, s, label.shape[1])\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "    df_all_1_twofold = pd.concat([df_all_1_twofold, d/5],axis=1)\n",
    "    \n",
    "df_all_1_twofold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BayesianClassifierChain_naive_bayes.csv\")\n",
    "df_all_1_twofold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "emotions\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "scene\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "enron\n",
      "learn structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC test\n",
      "ensemble: 0\n",
      "A.A8\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "D.D18\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "D.D17\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "genbase\n",
      "learn structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "medical\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.120761</td>\n",
       "      <td>2.838384</td>\n",
       "      <td>1.510797</td>\n",
       "      <td>17.195065</td>\n",
       "      <td>1.374622</td>\n",
       "      <td>3.777096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.210724</td>\n",
       "      <td>0.172316</td>\n",
       "      <td>0.083211</td>\n",
       "      <td>0.131091</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.046129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.242054</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>0.213178</td>\n",
       "      <td>0.111633</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.025721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.376699</td>\n",
       "      <td>0.634074</td>\n",
       "      <td>0.619488</td>\n",
       "      <td>0.187949</td>\n",
       "      <td>0.491257</td>\n",
       "      <td>0.164070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.584272</td>\n",
       "      <td>0.650278</td>\n",
       "      <td>0.600622</td>\n",
       "      <td>0.421730</td>\n",
       "      <td>0.930355</td>\n",
       "      <td>0.537582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.757946</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.786822</td>\n",
       "      <td>0.888367</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.974279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.870141</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.988249</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.668712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical\n",
       "coverage_error  8.120761  2.838384  1.510797  17.195065  1.374622  3.777096\n",
       "ranking_loss    0.210724  0.172316  0.083211   0.131091  0.002929  0.046129\n",
       "hamming_loss    0.242054  0.247475  0.213178   0.111633  0.005930  0.025721\n",
       "f1_macro        0.376699  0.634074  0.619488   0.187949  0.491257  0.164070\n",
       "f1_micro        0.584272  0.650278  0.600622   0.421730  0.930355  0.537582\n",
       "Jaccard_Index   0.757946  0.752525  0.786822   0.888367  0.994070  0.974279\n",
       "zero_one_error  0.870141  0.781145  0.805648   0.988249  0.132931  0.668712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2 = pd.DataFrame()\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    y_predict, y_test = BR_test(data, label, dataPath,3071980)\n",
    "\n",
    "    error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_test), columns=y_test.columns)\n",
    "\n",
    "    labelFile = dataPath+\"error_matrix.csv\"\n",
    "    savePng = dataPath+\"/bayes_net_error_matrix.png\"\n",
    "    error_matrix.to_csv(os.path.join(dataPath,labelFile),index=False)\n",
    "    less_error_label = (error_matrix!=0).sum().idxmin()\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "\n",
    "    df = BCC_test(data, label, dataPath, bayes_net, 3071980, label.shape[1])\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_2 = pd.concat([df_all_2, df],axis=1)\n",
    "    \n",
    "df_all_2.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/LEAD_naive_bayes.csv\")\n",
    "df_all_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmc2007\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "rcv1subset1\n",
      "learn structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "Class50\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n",
      "rcv1subset2\n",
      "learn structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n",
      "rcv1subset3\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n",
      "rcv1subset4\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n",
      "rcv1subset5\n",
      "learn structure\n",
      "BCC test\n",
      "ensemble: 0\n",
      "ensemble: 1\n",
      "ensemble: 2\n",
      "ensemble: 3\n",
      "ensemble: 4\n",
      "ensemble: 5\n",
      "ensemble: 6\n",
      "ensemble: 7\n",
      "ensemble: 8\n",
      "ensemble: 9\n",
      "ensemble: 10\n",
      "ensemble: 11\n",
      "ensemble: 12\n",
      "ensemble: 13\n",
      "ensemble: 14\n",
      "ensemble: 15\n",
      "ensemble: 16\n",
      "ensemble: 17\n",
      "ensemble: 18\n",
      "ensemble: 19\n",
      "ensemble: 20\n",
      "ensemble: 21\n",
      "ensemble: 22\n",
      "ensemble: 23\n",
      "ensemble: 24\n",
      "ensemble: 25\n",
      "ensemble: 26\n",
      "ensemble: 27\n",
      "ensemble: 28\n",
      "ensemble: 29\n",
      "ensemble: 30\n",
      "ensemble: 31\n",
      "ensemble: 32\n",
      "ensemble: 33\n",
      "ensemble: 34\n",
      "ensemble: 35\n",
      "ensemble: 36\n",
      "ensemble: 37\n",
      "ensemble: 38\n",
      "ensemble: 39\n",
      "ensemble: 40\n",
      "ensemble: 41\n",
      "ensemble: 42\n",
      "ensemble: 43\n",
      "ensemble: 44\n",
      "ensemble: 45\n",
      "ensemble: 46\n",
      "ensemble: 47\n",
      "ensemble: 48\n",
      "ensemble: 49\n",
      "ensemble: 50\n",
      "ensemble: 51\n",
      "ensemble: 52\n",
      "ensemble: 53\n",
      "ensemble: 54\n",
      "ensemble: 55\n",
      "ensemble: 56\n",
      "ensemble: 57\n",
      "ensemble: 58\n",
      "ensemble: 59\n",
      "ensemble: 60\n",
      "ensemble: 61\n",
      "ensemble: 62\n",
      "ensemble: 63\n",
      "ensemble: 64\n",
      "ensemble: 65\n",
      "ensemble: 66\n",
      "ensemble: 67\n",
      "ensemble: 68\n",
      "ensemble: 69\n",
      "Class70\n",
      "ensemble: 70\n",
      "ensemble: 71\n",
      "ensemble: 72\n",
      "ensemble: 73\n",
      "ensemble: 74\n",
      "ensemble: 75\n",
      "ensemble: 76\n",
      "ensemble: 77\n",
      "ensemble: 78\n",
      "ensemble: 79\n",
      "ensemble: 80\n",
      "ensemble: 81\n",
      "ensemble: 82\n",
      "ensemble: 83\n",
      "ensemble: 84\n",
      "ensemble: 85\n",
      "ensemble: 86\n",
      "ensemble: 87\n",
      "ensemble: 88\n",
      "ensemble: 89\n",
      "ensemble: 90\n",
      "ensemble: 91\n",
      "ensemble: 92\n",
      "ensemble: 93\n",
      "ensemble: 94\n",
      "ensemble: 95\n",
      "ensemble: 96\n",
      "ensemble: 97\n",
      "ensemble: 98\n",
      "ensemble: 99\n",
      "ensemble: 100\n"
     ]
    }
   ],
   "source": [
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    print(\"learn structure\")\n",
    "    y_predict, y_test = BR_test(data, label, dataPath,3071980)\n",
    "\n",
    "    error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_test), columns=y_test.columns)\n",
    "\n",
    "    labelFile = dataPath+\"error_matrix.csv\"\n",
    "    savePng = dataPath+\"/bayes_net_error_matrix.png\"\n",
    "    error_matrix.to_csv(os.path.join(dataPath,labelFile),index=False)\n",
    "    less_error_label = (error_matrix!=0).sum().idxmin()\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "\n",
    "    print(\"BCC test\")\n",
    "    df = BCC_test(data, label, dataPath, bayes_net, 3071980, label.shape[1])\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_2 = pd.concat([df_all_2, df],axis=1)\n",
    "    \n",
    "df_all_2.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/LEAD_naive_bayes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 times 2 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.807113</td>\n",
       "      <td>2.758249</td>\n",
       "      <td>1.497674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.196283</td>\n",
       "      <td>0.165960</td>\n",
       "      <td>0.081957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.234090</td>\n",
       "      <td>0.221998</td>\n",
       "      <td>0.211489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.414332</td>\n",
       "      <td>0.631359</td>\n",
       "      <td>0.616057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.597466</td>\n",
       "      <td>0.666152</td>\n",
       "      <td>0.598532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.765910</td>\n",
       "      <td>0.778002</td>\n",
       "      <td>0.788511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.858561</td>\n",
       "      <td>0.708418</td>\n",
       "      <td>0.811794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene\n",
       "coverage_error  7.807113  2.758249  1.497674\n",
       "ranking_loss    0.196283  0.165960  0.081957\n",
       "hamming_loss    0.234090  0.221998  0.211489\n",
       "f1_macro        0.414332  0.631359  0.616057\n",
       "f1_micro        0.597466  0.666152  0.598532\n",
       "Jaccard_Index   0.765910  0.778002  0.788511\n",
       "zero_one_error  0.858561  0.708418  0.811794"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2_2fold = pd.DataFrame()\n",
    "\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        y_predict, y_test = BR_test(data, label, dataPath,s)\n",
    "\n",
    "        error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_test), columns=y_test.columns)\n",
    "\n",
    "        labelFile = dataPath+\"error_matrix.csv\"\n",
    "        savePng = dataPath+\"/bayes_net_error_matrix.png\"\n",
    "        error_matrix.to_csv(os.path.join(dataPath,labelFile),index=False)\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "\n",
    "        df = BCC_test_2_fold(data, label, dataPath, bayes_net, s, label.shape[1])\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "        \n",
    "\n",
    "    df_all_2_2fold = pd.concat([df_all_2_2fold, d/5],axis=1)\n",
    "df_all_2_2fold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/LEAD_naive_bayes.csv\")\n",
    "\n",
    "\n",
    "df_all_2_2fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dea41b344408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbayes_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_BN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavePng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCC_test_2_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a8103b2355ff>\u001b[0m in \u001b[0;36mBCC_test_2_fold\u001b[0;34m(data, label, dataPath, bayes_net, random_state, ensemble, root)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m#print(\"--- start training ---\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mclassifier_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearned_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaiveBayes_multi_label_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0;31m# testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a8103b2355ff>\u001b[0m in \u001b[0;36mnaiveBayes_multi_label_training\u001b[0;34m(X_train, y_train, bayes_net, root_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mlearned_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mchildren_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbayes_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearned_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren_sub\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearned_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_list = [\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        y_predict, y_test = BR_test(data, label, dataPath,s)\n",
    "\n",
    "        error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_test), columns=y_test.columns)\n",
    "\n",
    "        labelFile = dataPath+\"error_matrix.csv\"\n",
    "        savePng = dataPath+\"/bayes_net_error_matrix.png\"\n",
    "        error_matrix.to_csv(os.path.join(dataPath,labelFile),index=False)\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "\n",
    "        df = BCC_test_2_fold(data, label, dataPath, bayes_net, s, label.shape[1])\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "        \n",
    "\n",
    "    df_all_2_2fold = pd.concat([df_all_2_2fold, d/5],axis=1)\n",
    "df_all_2_2fold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/LEAD_naive_bayes.csv\")\n",
    "\n",
    "\n",
    "df_all_2_2fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        y_predict, y_test = BR_test(data, label, dataPath,s)\n",
    "\n",
    "        error_matrix = pd.DataFrame(np.array(y_predict) - np.array(y_test), columns=y_test.columns)\n",
    "\n",
    "        labelFile = dataPath+\"error_matrix.csv\"\n",
    "        savePng = dataPath+\"/bayes_net_error_matrix.png\"\n",
    "        error_matrix.to_csv(os.path.join(dataPath,labelFile),index=False)\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "\n",
    "        df = BCC_test_2_fold(data, label, dataPath, bayes_net, s, label.shape[1])\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "        \n",
    "\n",
    "    df_all_2_2fold = pd.concat([df_all_2_2fold, d/5],axis=1)\n",
    "    \n",
    "df_all_2_2fold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/LEAD_naive_bayes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# different orders of chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BR for getting error matrix\n",
    "def naiveBayes_multi_label_training_BR(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training_BR(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing_BR(X_test, n_label, classifier_list)\n",
    "    \n",
    "    y_predict.columns = label.columns\n",
    "    return y_predict, y_test\n",
    "\n",
    "def naiveBayes_multi_label_training_order(X_train, y_train, bayes_net, order):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    \n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)] # create a classifier chain\n",
    "    \n",
    "    learned_label = []\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            l = order[i]\n",
    "            classifier_list[i].fit(X_train, y_train.loc[:, l])\n",
    "            learned_label.append(l)\n",
    "            \n",
    "        else:\n",
    "            l = order[i]\n",
    "            par = [x for x in bayes_net[l] if x in learned_label]\n",
    "            X = pd.concat([X_train, y_train.loc[:,par]],axis=1) # put the previous label into attribute space\n",
    "            classifier_list[i].fit(X, y_train.loc[:, l])\n",
    "            learned_label.append(l)\n",
    "\n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, learned_label\n",
    "\n",
    "def naiveBayes_multi_label_testing_order(X_test, n_label, classifier_list, bayes_net, learned_label):\n",
    "    y_predict = pd.DataFrame(index=X_test.index)\n",
    "    y_prob = pd.DataFrame(index=X_test.index)\n",
    "    y_true = pd.DataFrame(index=X_test.index)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    predicted_list = []\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        if i == 0:\n",
    "            l = learned_label[i]\n",
    "            y_predict_i = classifier_list[i].predict(X_test)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            predicted_list.append(l)\n",
    "        \n",
    "        else:\n",
    "            l = learned_label[i]\n",
    "            par = [p for p in bayes_net[l] if p in predicted_list]\n",
    "            if len(par) != 0:\n",
    "                X = pd.concat([X_test, y_predict.loc[:,par]],axis=1) # put the previous label into attribute space\n",
    "            else:\n",
    "                X= X_test\n",
    "            y_predict_i = classifier_list[i].predict(X)\n",
    "            y_predict_prob_i = classifier_list[i].predict_proba(X)[:,1]\n",
    "            \n",
    "            y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i,index=X_test.index,columns=[l])],axis=1)\n",
    "            y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i,index=X_test.index,columns=[l])],axis=1)\n",
    "  \n",
    "            predicted_list.append(l)            \n",
    "        \n",
    "    return y_predict, y_prob\n",
    "\n",
    "def BCC_test_order(data, label, dataPath, bayes_net, random_state=3071980, ensemble = 5, order_method=\"random\"):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # get order\n",
    "    if order_method==\"best_prediction\":\n",
    "        y_predict, y_test = BR_test(data, label, dataPath,3071980)\n",
    "        acc = (y_predict.values == y_test.values).mean(axis = 0)\n",
    "        order = list(label.columns[np.argsort(-acc)])\n",
    "    \n",
    "    elif order_method==\"largest_edges\":\n",
    "        a = [(x,len(y)) for x,y in bayes_net.items()]\n",
    "        a_sort = sorted(a, key=lambda x:x[1], reverse=True)\n",
    "        order = [x[0] for x in a_sort]\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # ensemble\n",
    "    y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "    \n",
    "    for i in range(ensemble):\n",
    "        if order_method==\"random\":\n",
    "            order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "\n",
    "        # training\n",
    "        #print(\"--- start training ---\\n\")\n",
    "        classifier_list, learned_label = naiveBayes_multi_label_training_order(X_train, y_train, bayes_net, order)\n",
    "\n",
    "        # testing\n",
    "        #print(\"--- start testing ---\\n\")\n",
    "        y_predict, y_prob = naiveBayes_multi_label_testing_order(X_test, n_label, classifier_list, bayes_net, learned_label)\n",
    "\n",
    "        y_predict = y_predict[label.columns]\n",
    "        y_prob = y_prob[label.columns]\n",
    "\n",
    "        y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "        y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "        \n",
    "    y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "    y_prob_ensemble = y_prob_ensemble / ensemble\n",
    "    y_pred_ensemble = y_pred_ensemble.fillna(0)\n",
    "    y_prob_ensemble = y_prob_ensemble.fillna(0)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "    performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "    \n",
    "    return performance_df\n",
    "\n",
    "\n",
    "def BCC_test_order_twofold(data, label, dataPath, bayes_net, random_state=3071980, ensemble = 5, order_method=\"random\"):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # get order\n",
    "    if order_method==\"best_prediction\":\n",
    "        y_predict, y_test = BR_test(data, label, dataPath,3071980)\n",
    "        acc = (y_predict.values == y_test.values).mean(axis = 0)\n",
    "        order = list(label.columns[np.argsort(-acc)])\n",
    "    \n",
    "    elif order_method==\"largest_edges\":\n",
    "        a = [(x,len(y)) for x,y in bayes_net.items()]\n",
    "        a_sort = sorted(a, key=lambda x:x[1], reverse=True)\n",
    "        order = [x[0] for x in a_sort]\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    performance_df_all = pd.DataFrame(np.zeros([7,1]))\n",
    "    for j in range(2):\n",
    "        X_train, y_train = X_test, y_test\n",
    "    # ensemble\n",
    "        y_pred_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "        y_prob_ensemble = pd.DataFrame(np.zeros(y_test.shape),columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "        for i in range(ensemble):\n",
    "            if order_method==\"random\":\n",
    "                order = random.sample(list(range(n_label)),n_label) # get orders\n",
    "\n",
    "            # training\n",
    "            #print(\"--- start training ---\\n\")\n",
    "            classifier_list, learned_label = naiveBayes_multi_label_training_order(X_train, y_train, bayes_net, order)\n",
    "\n",
    "            # testing\n",
    "            #print(\"--- start testing ---\\n\")\n",
    "            y_predict, y_prob = naiveBayes_multi_label_testing_order(X_test, n_label, classifier_list, bayes_net, learned_label)\n",
    "\n",
    "            y_predict = y_predict[label.columns]\n",
    "            y_prob = y_prob[label.columns]\n",
    "\n",
    "            y_pred_ensemble = y_pred_ensemble + y_predict\n",
    "            y_prob_ensemble = y_prob_ensemble + y_prob\n",
    "\n",
    "        \n",
    "        y_pred_ensemble = (((y_pred_ensemble / ensemble) >= 0.5)*1).astype('int')\n",
    "        y_prob_ensemble = y_prob_ensemble / ensemble\n",
    "        y_pred_ensemble = y_pred_ensemble.fillna(0)\n",
    "        y_prob_ensemble = y_prob_ensemble.fillna(0)\n",
    "\n",
    "        # evaluation\n",
    "        performance = evaluation(y_pred_ensemble, y_prob_ensemble, y_test)\n",
    "    \n",
    "        performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "        \n",
    "        performance_df_all.index = performance_df.index\n",
    "        performance_df_all.columns = performance_df.columns\n",
    "        \n",
    "        performance_df_all = performance_df_all + performance_df\n",
    "        \n",
    "    performance_df_all = performance_df_all / 2\n",
    "    return performance_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.196030</td>\n",
       "      <td>2.865320</td>\n",
       "      <td>1.538206</td>\n",
       "      <td>17.457109</td>\n",
       "      <td>1.398792</td>\n",
       "      <td>3.760736</td>\n",
       "      <td>4.171283</td>\n",
       "      <td>13.853667</td>\n",
       "      <td>13.870333</td>\n",
       "      <td>13.902000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>14.270333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.216811</td>\n",
       "      <td>0.178853</td>\n",
       "      <td>0.088464</td>\n",
       "      <td>0.132640</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.060312</td>\n",
       "      <td>0.055099</td>\n",
       "      <td>0.055898</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>0.058010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.241108</td>\n",
       "      <td>0.231762</td>\n",
       "      <td>0.203904</td>\n",
       "      <td>0.112498</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.115773</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.035056</td>\n",
       "      <td>0.033066</td>\n",
       "      <td>0.038535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.382511</td>\n",
       "      <td>0.631798</td>\n",
       "      <td>0.627739</td>\n",
       "      <td>0.189732</td>\n",
       "      <td>0.473191</td>\n",
       "      <td>0.159631</td>\n",
       "      <td>0.480735</td>\n",
       "      <td>0.231007</td>\n",
       "      <td>0.203404</td>\n",
       "      <td>0.187474</td>\n",
       "      <td>0.170644</td>\n",
       "      <td>0.179251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.587069</td>\n",
       "      <td>0.657829</td>\n",
       "      <td>0.610626</td>\n",
       "      <td>0.421173</td>\n",
       "      <td>0.926121</td>\n",
       "      <td>0.528980</td>\n",
       "      <td>0.582532</td>\n",
       "      <td>0.435217</td>\n",
       "      <td>0.377602</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.364962</td>\n",
       "      <td>0.354775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.758892</td>\n",
       "      <td>0.768238</td>\n",
       "      <td>0.796096</td>\n",
       "      <td>0.887502</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.973779</td>\n",
       "      <td>0.884227</td>\n",
       "      <td>0.967502</td>\n",
       "      <td>0.965370</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.966934</td>\n",
       "      <td>0.961465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.864351</td>\n",
       "      <td>0.750842</td>\n",
       "      <td>0.791528</td>\n",
       "      <td>0.988249</td>\n",
       "      <td>0.135952</td>\n",
       "      <td>0.668712</td>\n",
       "      <td>0.882221</td>\n",
       "      <td>0.970333</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.877667</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  8.196030  2.865320  1.538206  17.457109  1.398792  3.760736   \n",
       "ranking_loss    0.216811  0.178853  0.088464   0.132640  0.003454  0.045918   \n",
       "hamming_loss    0.241108  0.231762  0.203904   0.112498  0.006266  0.026221   \n",
       "f1_macro        0.382511  0.631798  0.627739   0.189732  0.473191  0.159631   \n",
       "f1_micro        0.587069  0.657829  0.610626   0.421173  0.926121  0.528980   \n",
       "Jaccard_Index   0.758892  0.768238  0.796096   0.887502  0.993734  0.973779   \n",
       "zero_one_error  0.864351  0.750842  0.791528   0.988249  0.135952  0.668712   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  4.171283    13.853667    13.870333    13.902000    12.250000   \n",
       "ranking_loss    0.060312     0.055099     0.055898     0.056682     0.050152   \n",
       "hamming_loss    0.115773     0.032498     0.034630     0.035056     0.033066   \n",
       "f1_macro        0.480735     0.231007     0.203404     0.187474     0.170644   \n",
       "f1_micro        0.582532     0.435217     0.377602     0.380208     0.364962   \n",
       "Jaccard_Index   0.884227     0.967502     0.965370     0.964944     0.966934   \n",
       "zero_one_error  0.882221     0.970333     0.897000     0.877667     0.816667   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error    14.270333  \n",
       "ranking_loss       0.058010  \n",
       "hamming_loss       0.038535  \n",
       "f1_macro           0.179251  \n",
       "f1_micro           0.354775  \n",
       "Jaccard_Index      0.961465  \n",
       "zero_one_error     0.914000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_3 = pd.DataFrame()\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "    \n",
    "    df = BCC_test_order(data, label, dataPath, bayes_net, 3071980, 1, order_method=\"best_prediction\")\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_3 = pd.concat([df_all_3, df],axis=1)\n",
    "    \n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "    \n",
    "    df = BCC_test_order(data, label, dataPath, bayes_net, 3071980, 1, order_method=\"best_prediction\")\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_3 = pd.concat([df_all_3, df],axis=1)\n",
    "\n",
    "\n",
    "df_all_3.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/BayesianClassifierChain_best_prediction.csv\")\n",
    "df_all_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>8.229115</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>1.529900</td>\n",
       "      <td>17.139835</td>\n",
       "      <td>1.465257</td>\n",
       "      <td>3.787321</td>\n",
       "      <td>4.170443</td>\n",
       "      <td>13.860667</td>\n",
       "      <td>13.608667</td>\n",
       "      <td>13.812667</td>\n",
       "      <td>12.636333</td>\n",
       "      <td>14.229333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.219101</td>\n",
       "      <td>0.182005</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.131616</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.046038</td>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.055406</td>\n",
       "      <td>0.055727</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.052921</td>\n",
       "      <td>0.058546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.240754</td>\n",
       "      <td>0.228956</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.113984</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.025721</td>\n",
       "      <td>0.116504</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.035347</td>\n",
       "      <td>0.036007</td>\n",
       "      <td>0.032736</td>\n",
       "      <td>0.038581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.380726</td>\n",
       "      <td>0.620771</td>\n",
       "      <td>0.637587</td>\n",
       "      <td>0.188612</td>\n",
       "      <td>0.473191</td>\n",
       "      <td>0.157944</td>\n",
       "      <td>0.477964</td>\n",
       "      <td>0.231615</td>\n",
       "      <td>0.210076</td>\n",
       "      <td>0.192876</td>\n",
       "      <td>0.180666</td>\n",
       "      <td>0.187544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.579940</td>\n",
       "      <td>0.658291</td>\n",
       "      <td>0.616205</td>\n",
       "      <td>0.417318</td>\n",
       "      <td>0.926121</td>\n",
       "      <td>0.536066</td>\n",
       "      <td>0.580990</td>\n",
       "      <td>0.437868</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.381589</td>\n",
       "      <td>0.383798</td>\n",
       "      <td>0.367219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.759246</td>\n",
       "      <td>0.771044</td>\n",
       "      <td>0.800664</td>\n",
       "      <td>0.886016</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.974279</td>\n",
       "      <td>0.883496</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.964653</td>\n",
       "      <td>0.963993</td>\n",
       "      <td>0.967264</td>\n",
       "      <td>0.961419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.788206</td>\n",
       "      <td>0.989424</td>\n",
       "      <td>0.135952</td>\n",
       "      <td>0.664622</td>\n",
       "      <td>0.884739</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.811667</td>\n",
       "      <td>0.913000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  8.229115  2.888889  1.529900  17.139835  1.465257  3.787321   \n",
       "ranking_loss    0.219101  0.182005  0.086741   0.131616  0.004705  0.046038   \n",
       "hamming_loss    0.240754  0.228956  0.199336   0.113984  0.006266  0.025721   \n",
       "f1_macro        0.380726  0.620771  0.637587   0.188612  0.473191  0.157944   \n",
       "f1_micro        0.579940  0.658291  0.616205   0.417318  0.926121  0.536066   \n",
       "Jaccard_Index   0.759246  0.771044  0.800664   0.886016  0.993734  0.974279   \n",
       "zero_one_error  0.860215  0.717172  0.788206   0.989424  0.135952  0.664622   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  4.170443    13.860667    13.608667    13.812667    12.636333   \n",
       "ranking_loss    0.060937     0.055406     0.055727     0.057057     0.052921   \n",
       "hamming_loss    0.116504     0.033040     0.035347     0.036007     0.032736   \n",
       "f1_macro        0.477964     0.231615     0.210076     0.192876     0.180666   \n",
       "f1_micro        0.580990     0.437868     0.388000     0.381589     0.383798   \n",
       "Jaccard_Index   0.883496     0.966960     0.964653     0.963993     0.967264   \n",
       "zero_one_error  0.884739     0.966000     0.896667     0.890000     0.811667   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error    14.229333  \n",
       "ranking_loss       0.058546  \n",
       "hamming_loss       0.038581  \n",
       "f1_macro           0.187544  \n",
       "f1_micro           0.367219  \n",
       "Jaccard_Index      0.961419  \n",
       "zero_one_error     0.913000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_4 = pd.DataFrame()\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\",]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "    \n",
    "    df = BCC_test_order(data, label, dataPath, bayes_net, 3071980, 1, order_method=\"largest_edges\")\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_4 = pd.concat([df_all_4, df],axis=1)\n",
    "    \n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "    \n",
    "    df = BCC_test_order(data, label, dataPath, bayes_net, 3071980, 1, order_method=\"largest_edges\")\n",
    "    df.columns = [dataset]\n",
    "\n",
    "    df_all_4 = pd.concat([df_all_4, df],axis=1)\n",
    "\n",
    "\n",
    "df_all_4.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/BayesianClassifierChain_largest_edges.csv\")\n",
    "df_all_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 times 2 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n",
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.900579</td>\n",
       "      <td>2.756229</td>\n",
       "      <td>1.526910</td>\n",
       "      <td>12.247239</td>\n",
       "      <td>1.325680</td>\n",
       "      <td>1.861350</td>\n",
       "      <td>3.992474</td>\n",
       "      <td>8.794600</td>\n",
       "      <td>7.939600</td>\n",
       "      <td>7.955133</td>\n",
       "      <td>7.240533</td>\n",
       "      <td>7.837333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.197997</td>\n",
       "      <td>0.167563</td>\n",
       "      <td>0.088103</td>\n",
       "      <td>0.078855</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>0.054149</td>\n",
       "      <td>0.030923</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>0.027741</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.026757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.214366</td>\n",
       "      <td>0.204097</td>\n",
       "      <td>0.092349</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.112231</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.026954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.425463</td>\n",
       "      <td>0.642672</td>\n",
       "      <td>0.621628</td>\n",
       "      <td>0.377857</td>\n",
       "      <td>0.503626</td>\n",
       "      <td>0.278517</td>\n",
       "      <td>0.499024</td>\n",
       "      <td>0.329935</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>0.307629</td>\n",
       "      <td>0.260168</td>\n",
       "      <td>0.292653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.611755</td>\n",
       "      <td>0.674031</td>\n",
       "      <td>0.605983</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.944079</td>\n",
       "      <td>0.731639</td>\n",
       "      <td>0.596110</td>\n",
       "      <td>0.502243</td>\n",
       "      <td>0.479331</td>\n",
       "      <td>0.487235</td>\n",
       "      <td>0.449833</td>\n",
       "      <td>0.477700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.795903</td>\n",
       "      <td>0.907651</td>\n",
       "      <td>0.995121</td>\n",
       "      <td>0.986249</td>\n",
       "      <td>0.887769</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.973588</td>\n",
       "      <td>0.973710</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.973046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.841853</td>\n",
       "      <td>0.721886</td>\n",
       "      <td>0.793854</td>\n",
       "      <td>0.962867</td>\n",
       "      <td>0.110574</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.870737</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.879667</td>\n",
       "      <td>0.850800</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.891600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  7.900579  2.756229  1.526910  12.247239  1.325680  1.861350   \n",
       "ranking_loss    0.197997  0.167563  0.088103   0.078855  0.001563  0.011625   \n",
       "hamming_loss    0.227083  0.214366  0.204097   0.092349  0.004879  0.013751   \n",
       "f1_macro        0.425463  0.642672  0.621628   0.377857  0.503626  0.278517   \n",
       "f1_micro        0.611755  0.674031  0.605983   0.521008  0.944079  0.731639   \n",
       "Jaccard_Index   0.772917  0.785634  0.795903   0.907651  0.995121  0.986249   \n",
       "zero_one_error  0.841853  0.721886  0.793854   0.962867  0.110574  0.466667   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  3.992474     8.794600     7.939600     7.955133     7.240533   \n",
       "ranking_loss    0.054149     0.030923     0.027268     0.027741     0.025862   \n",
       "hamming_loss    0.112231     0.028045     0.026412     0.026290     0.026786   \n",
       "f1_macro        0.499024     0.329935     0.319179     0.307629     0.260168   \n",
       "f1_micro        0.596110     0.502243     0.479331     0.487235     0.449833   \n",
       "Jaccard_Index   0.887769     0.971955     0.973588     0.973710     0.973214   \n",
       "zero_one_error  0.870737     0.959000     0.879667     0.850800     0.802933   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error     7.837333  \n",
       "ranking_loss       0.026757  \n",
       "hamming_loss       0.026954  \n",
       "f1_macro           0.292653  \n",
       "f1_micro           0.477700  \n",
       "Jaccard_Index      0.973046  \n",
       "zero_one_error     0.891600  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_3_twofold = pd.DataFrame()\n",
    "seed = [1234,2234,12345,12346,1234567]\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "        df = BCC_test_order_twofold(data, label, dataPath, bayes_net, s, 1, order_method=\"best_prediction\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "\n",
    "    df_all_3_twofold = pd.concat([df_all_3_twofold, d/5],axis=1)\n",
    "    \n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "        df = BCC_test_order_twofold(data, label, dataPath, bayes_net, s, 1, order_method=\"best_prediction\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "\n",
    "    df_all_3_twofold = pd.concat([df_all_3_twofold, d/5],axis=1)\n",
    "\n",
    "\n",
    "df_all_3_twofold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BayesianClassifierChain_best_prediction.csv\")\n",
    "df_all_3_twofold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "emotions\n",
      "scene\n",
      "enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genbase\n",
      "medical\n",
      "tmc2007\n",
      "rcv1subset1\n",
      "rcv1subset2\n",
      "rcv1subset3\n",
      "rcv1subset4\n",
      "rcv1subset5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeast</th>\n",
       "      <th>emotions</th>\n",
       "      <th>scene</th>\n",
       "      <th>enron</th>\n",
       "      <th>genbase</th>\n",
       "      <th>medical</th>\n",
       "      <th>tmc2007</th>\n",
       "      <th>rcv1subset1</th>\n",
       "      <th>rcv1subset2</th>\n",
       "      <th>rcv1subset3</th>\n",
       "      <th>rcv1subset4</th>\n",
       "      <th>rcv1subset5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coverage_error</th>\n",
       "      <td>7.908354</td>\n",
       "      <td>2.767003</td>\n",
       "      <td>1.523920</td>\n",
       "      <td>12.078496</td>\n",
       "      <td>1.367372</td>\n",
       "      <td>1.876074</td>\n",
       "      <td>3.988586</td>\n",
       "      <td>8.969400</td>\n",
       "      <td>7.766800</td>\n",
       "      <td>7.816533</td>\n",
       "      <td>7.428600</td>\n",
       "      <td>7.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_loss</th>\n",
       "      <td>0.202651</td>\n",
       "      <td>0.166631</td>\n",
       "      <td>0.087443</td>\n",
       "      <td>0.079084</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>0.031511</td>\n",
       "      <td>0.026992</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>0.026602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.232731</td>\n",
       "      <td>0.215713</td>\n",
       "      <td>0.198782</td>\n",
       "      <td>0.092637</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.112941</td>\n",
       "      <td>0.028143</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.408855</td>\n",
       "      <td>0.643596</td>\n",
       "      <td>0.632083</td>\n",
       "      <td>0.378851</td>\n",
       "      <td>0.503859</td>\n",
       "      <td>0.275172</td>\n",
       "      <td>0.496238</td>\n",
       "      <td>0.340018</td>\n",
       "      <td>0.330757</td>\n",
       "      <td>0.318640</td>\n",
       "      <td>0.272458</td>\n",
       "      <td>0.303122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.592752</td>\n",
       "      <td>0.673806</td>\n",
       "      <td>0.612737</td>\n",
       "      <td>0.518382</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.725898</td>\n",
       "      <td>0.594558</td>\n",
       "      <td>0.509039</td>\n",
       "      <td>0.492226</td>\n",
       "      <td>0.494038</td>\n",
       "      <td>0.467363</td>\n",
       "      <td>0.493221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard_Index</th>\n",
       "      <td>0.767269</td>\n",
       "      <td>0.784287</td>\n",
       "      <td>0.801218</td>\n",
       "      <td>0.907363</td>\n",
       "      <td>0.995166</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>0.887059</td>\n",
       "      <td>0.971857</td>\n",
       "      <td>0.973243</td>\n",
       "      <td>0.973059</td>\n",
       "      <td>0.973668</td>\n",
       "      <td>0.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_error</th>\n",
       "      <td>0.849628</td>\n",
       "      <td>0.700337</td>\n",
       "      <td>0.791362</td>\n",
       "      <td>0.964747</td>\n",
       "      <td>0.109366</td>\n",
       "      <td>0.470757</td>\n",
       "      <td>0.875591</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.877667</td>\n",
       "      <td>0.860467</td>\n",
       "      <td>0.799933</td>\n",
       "      <td>0.886400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   yeast  emotions     scene      enron   genbase   medical  \\\n",
       "coverage_error  7.908354  2.767003  1.523920  12.078496  1.367372  1.876074   \n",
       "ranking_loss    0.202651  0.166631  0.087443   0.079084  0.002381  0.012064   \n",
       "hamming_loss    0.232731  0.215713  0.198782   0.092637  0.004834  0.014115   \n",
       "f1_macro        0.408855  0.643596  0.632083   0.378851  0.503859  0.275172   \n",
       "f1_micro        0.592752  0.673806  0.612737   0.518382  0.944615  0.725898   \n",
       "Jaccard_Index   0.767269  0.784287  0.801218   0.907363  0.995166  0.985885   \n",
       "zero_one_error  0.849628  0.700337  0.791362   0.964747  0.109366  0.470757   \n",
       "\n",
       "                 tmc2007  rcv1subset1  rcv1subset2  rcv1subset3  rcv1subset4  \\\n",
       "coverage_error  3.988586     8.969400     7.766800     7.816533     7.428600   \n",
       "ranking_loss    0.054633     0.031511     0.026992     0.027338     0.026572   \n",
       "hamming_loss    0.112941     0.028143     0.026757     0.026941     0.026332   \n",
       "f1_macro        0.496238     0.340018     0.330757     0.318640     0.272458   \n",
       "f1_micro        0.594558     0.509039     0.492226     0.494038     0.467363   \n",
       "Jaccard_Index   0.887059     0.971857     0.973243     0.973059     0.973668   \n",
       "zero_one_error  0.875591     0.948000     0.877667     0.860467     0.799933   \n",
       "\n",
       "                rcv1subset5  \n",
       "coverage_error     7.754800  \n",
       "ranking_loss       0.026602  \n",
       "hamming_loss       0.026900  \n",
       "f1_macro           0.303122  \n",
       "f1_micro           0.493221  \n",
       "Jaccard_Index      0.973100  \n",
       "zero_one_error     0.886400  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_4_twofold = pd.DataFrame()\n",
    "\n",
    "data_list = [\"yeast\",\"emotions\",\"scene\",\"enron\",\"genbase\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "    \n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "        df = BCC_test_order_twofold(data, label, dataPath, bayes_net, s, 1, order_method=\"largest_edges\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "\n",
    "    df_all_4_twofold = pd.concat([df_all_4_twofold, d/5],axis=1)\n",
    "    \n",
    "data_list = ['tmc2007','rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "    \n",
    "    labelFile = dataPath+\"y.csv\"\n",
    "    savePng = dataPath+\"/bayes_net.png\"\n",
    "\n",
    "    d = pd.DataFrame(np.zeros([7,1]))\n",
    "    for s in seed:\n",
    "        bayes_net = build_BN(labelFile, label.columns, savePng)\n",
    "        df = BCC_test_order_twofold(data, label, dataPath, bayes_net, s, 1, order_method=\"largest_edges\")\n",
    "        df.columns = [dataset]\n",
    "        d.columns = [dataset]\n",
    "        d.index = df.index\n",
    "        d = d + df\n",
    "\n",
    "    df_all_4_twofold = pd.concat([df_all_4_twofold, d/5],axis=1)\n",
    "\n",
    "\n",
    "df_all_4_twofold.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/twofold/BayesianClassifierChain_largest_edges.csv\")\n",
    "df_all_4_twofold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
