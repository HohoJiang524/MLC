{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import arff\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataPath, X_file, y_file):\n",
    "    # input: '/Volumes/Samsung_T5/research/data/ABC_news_data/obesity/'\n",
    "    # read data\n",
    "    data = pd.read_csv(os.path.join(dataPath,X_file))\n",
    "    label = pd.read_csv(os.path.join(dataPath,y_file))\n",
    "    return data,label\n",
    "\n",
    "def evaluation(y_pred, y_prob, y_true):\n",
    "    \n",
    "    coverage = coverage_error(y_true, y_prob)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    ranking_loss = label_ranking_loss(y_true, y_prob) \n",
    "    \n",
    "    f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = metrics.f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        acc += jaccard_similarity_score(y_true.iloc[i,:], y_pred.iloc[i,:]) # jaccard_similarity_score\n",
    "    acc = round(acc / y_true.shape[0],2)\n",
    "    \n",
    "    zero_one = zero_one_loss(y_true, y_pred) # 0-1 error \n",
    "    \n",
    "    performance = {\"coverage_error\":coverage,\n",
    "                   \"ranking_loss\":ranking_loss,\n",
    "                   \"hamming_loss\":hamming,\n",
    "                   \"f1_macro\":f1_macro,\n",
    "                   \"f1_micro\":f1_micro,\n",
    "                   \"Jaccard_Index\":acc,\n",
    "                   \"zero_one_error\":zero_one}\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_multi_label_training(X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    n_label = y_train.shape[1]\n",
    "    classifier_list = [MultinomialNB() for i in range(n_label)]\n",
    "    for i in range(n_label):\n",
    "        classifier_list[i].fit(X_train,y_train.iloc[:,i])\n",
    "    \n",
    "    end = time.time()\n",
    "    training_time = end-start\n",
    "    \n",
    "    return classifier_list, training_time\n",
    "\n",
    "def naiveBayes_multi_label_testing(X_test, n_label, classifier_list):\n",
    "    y_predict = pd.DataFrame()\n",
    "    y_prob = pd.DataFrame()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(n_label):\n",
    "        y_predict_i = classifier_list[i].predict(X_test)\n",
    "        y_predict = pd.concat([y_predict, pd.DataFrame(y_predict_i)],axis=1)\n",
    "        \n",
    "        y_predict_prob_i = classifier_list[i].predict_proba(X_test)[:,1]\n",
    "        y_prob = pd.concat([y_prob, pd.DataFrame(y_predict_prob_i)],axis=1)\n",
    "        \n",
    "    end = time.time()\n",
    "    testing_time = end-start\n",
    "        \n",
    "    return y_predict, y_prob, testing_time\n",
    "\n",
    "def BR_test(data, label, dataPath, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # split training and test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    print(\"-- test index --\")\n",
    "    print(X_test.index)\n",
    "    \n",
    "    # training\n",
    "    classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "    \n",
    "    # testing\n",
    "    y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "    \n",
    "    # evaluation\n",
    "    performance = evaluation(y_predict, y_prob, y_test)\n",
    "    \n",
    "    performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "    \n",
    "    return performance_df\n",
    "            \n",
    "# two fold cross-validation\n",
    "def two_fold_BR_test(data, label, dataPath, n_iter=5, random_state=3071980):\n",
    "    \n",
    "    # data set information\n",
    "    n_label = label.shape[1]\n",
    "    n_attr = data.shape[1]\n",
    "    n_instance = data.shape[0]\n",
    "    avg_label_per_instance = label.sum(axis=1).mean()\n",
    "    \n",
    "    # 2-fold cross validatiom\n",
    "    KF=KFold(n_splits=2, shuffle=True, random_state=random_state)\n",
    "    i = 0\n",
    "    \n",
    "    performance = {}\n",
    "    for train_index,test_index in KF.split(data):\n",
    "        i += 1\n",
    "        \n",
    "        X_train,X_test=data.iloc[train_index,:],data.iloc[test_index,:]\n",
    "        y_train,y_test=label.iloc[train_index,:],label.iloc[test_index,:]\n",
    "        \n",
    "        print(\"--- kfold time=\"+str(i)+\" ---\")\n",
    "        # training\n",
    "        classifier_list, training_time = naiveBayes_multi_label_training(X_train, y_train)\n",
    "        # testing\n",
    "        y_predict, y_prob, testing_time = naiveBayes_multi_label_testing(X_test, n_label, classifier_list)\n",
    "        \n",
    "        # evaluation\n",
    "        if performance == {}:\n",
    "            performance = evaluation(y_predict, y_prob, y_test)\n",
    "        else:\n",
    "            performance_i = evaluation(y_predict, y_prob, y_test)\n",
    "            for key, value in performance_i.items():\n",
    "                performance[key] = (performance[key] + value)/2\n",
    "            else:\n",
    "                performance[key] = value\n",
    "    \n",
    "    performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "    \n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([1922, 2019, 1276, 2123,  700, 1114,   28, 2386,  406, 1129,\n",
      "            ...\n",
      "            1424,  627,  805, 1659, 1850,  988, 2373,  293, 2012,  531],\n",
      "           dtype='int64', length=1209)\n",
      "enron\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([ 996,  964,  846,  734, 1275, 1610, 1483, 1084,  113, 1168,\n",
      "            ...\n",
      "            1673, 1040,  639, 1227,  954,  566,  541,  707,  532,  202],\n",
      "           dtype='int64', length=851)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n",
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([178, 264,  79, 405, 208, 219, 589,  28,  93,  23,\n",
      "            ...\n",
      "            408, 413, 568, 297, 313,  43, 259, 552, 424, 166],\n",
      "           dtype='int64', length=297)\n",
      "genbase\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([537, 405, 549, 196, 321, 493, 458, 127, 113, 390,\n",
      "            ...\n",
      "            475, 420, 325,  12, 586, 560, 635, 588,  53, 246],\n",
      "           dtype='int64', length=331)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangjunhao/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([ 454, 1014,  590, 2047, 1794,  611,  345,  484, 1202,  101,\n",
      "            ...\n",
      "            2311, 1993,  593,   41, 1415, 1623,  404,  661,  252, 2012],\n",
      "           dtype='int64', length=1204)\n",
      "medical\n",
      "------ Binary Relevance using Naive Bayes ------\n",
      "-- test index --\n",
      "Int64Index([843, 914, 822, 933, 510, 267, 520, 329, 820, 491,\n",
      "            ...\n",
      "            139, 800, 884, 697, 709, 952,  94, 850,  75, 798],\n",
      "           dtype='int64', length=489)\n",
      "rcv1subset1\n",
      "-- test index --\n",
      "Int64Index([1718, 3386,  593, 5318,  431, 5926, 4997, 4959, 1332, 5838,\n",
      "            ...\n",
      "            5003, 5033, 2254, 1444, 5457, 1144, 4496,  838, 2001,  592],\n",
      "           dtype='int64', length=3000)\n",
      "rcv1subset2\n",
      "-- test index --\n",
      "Int64Index([1718, 3386,  593, 5318,  431, 5926, 4997, 4959, 1332, 5838,\n",
      "            ...\n",
      "            5003, 5033, 2254, 1444, 5457, 1144, 4496,  838, 2001,  592],\n",
      "           dtype='int64', length=3000)\n",
      "rcv1subset3\n",
      "-- test index --\n",
      "Int64Index([1718, 3386,  593, 5318,  431, 5926, 4997, 4959, 1332, 5838,\n",
      "            ...\n",
      "            5003, 5033, 2254, 1444, 5457, 1144, 4496,  838, 2001,  592],\n",
      "           dtype='int64', length=3000)\n",
      "rcv1subset4\n",
      "-- test index --\n",
      "Int64Index([1718, 3386,  593, 5318,  431, 5926, 4997, 4959, 1332, 5838,\n",
      "            ...\n",
      "            5003, 5033, 2254, 1444, 5457, 1144, 4496,  838, 2001,  592],\n",
      "           dtype='int64', length=3000)\n",
      "rcv1subset5\n",
      "-- test index --\n",
      "Int64Index([1718, 3386,  593, 5318,  431, 5926, 4997, 4959, 1332, 5838,\n",
      "            ...\n",
      "            5003, 5033, 2254, 1444, 5457, 1144, 4496,  838, 2001,  592],\n",
      "           dtype='int64', length=3000)\n",
      "tmc2007\n",
      "-- test index --\n",
      "Int64Index([ 4174, 14774, 27345, 24198,  7620,  9105, 16444, 14258,  5860,\n",
      "             6466,\n",
      "            ...\n",
      "            22854, 21726, 19136, 19805,  2811,   320, 10660, 12340,  5334,\n",
      "             1665],\n",
      "           dtype='int64', length=14298)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "data_list = [\"yeast\",\"enron\",\"emotions\",\"genbase\",\"scene\",\"medical\"]\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/small_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "\n",
    "    # train - test\n",
    "    print(\"------ Binary Relevance using Naive Bayes ------\")\n",
    "    df = BR_test(data, label, dataPath,307190)\n",
    "    df.columns = [dataset]\n",
    "    \n",
    "    df_all = pd.concat([df_all, df],axis=1)\n",
    "\n",
    "data_list = ['rcv1subset1','rcv1subset2','rcv1subset3','rcv1subset4','rcv1subset5','tmc2007']\n",
    "for dataset in data_list:\n",
    "    print(dataset)\n",
    "    dataPath = '/Volumes/Samsung_T5/research/data/large_datasets/'+dataset+\"/\"\n",
    "    X_file = \"X_dis_1500.csv\"\n",
    "    y_file = \"y.csv\"\n",
    "    data, label = read_data(dataPath, X_file, y_file) # read data\n",
    "\n",
    "    # train - test\n",
    "    df = BR_test(data, label, dataPath,307190)\n",
    "    df.columns = [dataset]\n",
    "    \n",
    "    df_all = pd.concat([df_all, df],axis=1)\n",
    "    \n",
    "df_all.to_csv(\"/Users/jiangjunhao/Desktop/results_algorithms/binary_relevance_naive_bayes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
